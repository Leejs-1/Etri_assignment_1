{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 데이터 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'wordcloud'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-d07413c9abd2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m#import seaborn as sns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mwordcloud\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mWordCloud\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mDATA_PATH\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'./DATA/'\u001b[0m \u001b[0;31m#데이터경로 설정\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'wordcloud'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from wordcloud import WordCloud\n",
    "\n",
    "DATA_PATH = './DATA/' #데이터경로 설정\n",
    "print('파일 크기: ')\n",
    "for file in os.listdir(DATA_PATH):\n",
    "    if 'txt' in file:\n",
    "        print(file.ljust(30)+str(round(os.path.getsize(DATA_PATH+ file) / 100000,2))+'MB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train 데이터 총 개수:  150000\n"
     ]
    }
   ],
   "source": [
    "train_data = pd.read_table(DATA_PATH + 'ratings_train.txt')\n",
    "test_data = pd.read_table(DATA_PATH + 'ratings_test.txt')\n",
    "print('train 데이터 총 개수: ', len(train_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>document</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9976970</td>\n",
       "      <td>아 더빙.. 진짜 짜증나네요 목소리</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3819312</td>\n",
       "      <td>흠...포스터보고 초딩영화줄....오버연기조차 가볍지 않구나</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10265843</td>\n",
       "      <td>너무재밓었다그래서보는것을추천한다</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9045019</td>\n",
       "      <td>교도소 이야기구먼 ..솔직히 재미는 없다..평점 조정</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6483659</td>\n",
       "      <td>사이몬페그의 익살스런 연기가 돋보였던 영화!스파이더맨에서 늙어보이기만 했던 커스틴 ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id                                           document  label\n",
       "0   9976970                                아 더빙.. 진짜 짜증나네요 목소리      0\n",
       "1   3819312                  흠...포스터보고 초딩영화줄....오버연기조차 가볍지 않구나      1\n",
       "2  10265843                                  너무재밓었다그래서보는것을추천한다      0\n",
       "3   9045019                      교도소 이야기구먼 ..솔직히 재미는 없다..평점 조정      0\n",
       "4   6483659  사이몬페그의 익살스런 연기가 돋보였던 영화!스파이더맨에서 늙어보이기만 했던 커스틴 ...      1"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('test 데이터 총 개수: ', len(test_data)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>document</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9976970</td>\n",
       "      <td>아 더빙.. 진짜 짜증나네요 목소리</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3819312</td>\n",
       "      <td>흠...포스터보고 초딩영화줄....오버연기조차 가볍지 않구나</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10265843</td>\n",
       "      <td>너무재밓었다그래서보는것을추천한다</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9045019</td>\n",
       "      <td>교도소 이야기구먼 ..솔직히 재미는 없다..평점 조정</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6483659</td>\n",
       "      <td>사이몬페그의 익살스런 연기가 돋보였던 영화!스파이더맨에서 늙어보이기만 했던 커스틴 ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id                                           document  label\n",
       "0   9976970                                아 더빙.. 진짜 짜증나네요 목소리      0\n",
       "1   3819312                  흠...포스터보고 초딩영화줄....오버연기조차 가볍지 않구나      1\n",
       "2  10265843                                  너무재밓었다그래서보는것을추천한다      0\n",
       "3   9045019                      교도소 이야기구먼 ..솔직히 재미는 없다..평점 조정      0\n",
       "4   6483659  사이몬페그의 익살스런 연기가 돋보였던 영화!스파이더맨에서 늙어보이기만 했던 커스틴 ...      1"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#트레인 파일 불러오기\n",
    "train_data = pd.read_csv(DATA_PATH + 'ratings_train.txt',header = 0, delimiter = '\\t', quoting=3)\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "학습데이터 전체 개수: 150000\n"
     ]
    }
   ],
   "source": [
    "print('학습데이터 전체 개수: {}'.format(len(train_data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    19\n",
       "1    33\n",
       "2    17\n",
       "3    29\n",
       "4    61\n",
       "Name: document, dtype: int64"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#리뷰 전체길이 확인\n",
    "train_length = train_data['document'].astype(str).apply(len)\n",
    "train_length.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "리뷰 길이 최댓값: 158\n",
      "리뷰 길이 최솟값: 1\n",
      "리뷰 길이 평균값: 35.24\n",
      "리뷰 길이 표준편차: 29.58\n",
      "리뷰 길이 중간값: 27.0\n",
      "리뷰 길이 제1사분위: 16.0\n",
      "리뷰 길이 제3사분위: 42.0\n"
     ]
    }
   ],
   "source": [
    "#리뷰 통계 정보\n",
    "print('리뷰 길이 최댓값: {}'.format(np.max(train_length)))\n",
    "print('리뷰 길이 최솟값: {}'.format(np.min(train_length)))\n",
    "print('리뷰 길이 평균값: {:.2f}'.format(np.mean(train_length)))\n",
    "print('리뷰 길이 표준편차: {:.2f}'.format(np.std(train_length)))\n",
    "print('리뷰 길이 중간값: {}'.format(np.median(train_length)))\n",
    "print('리뷰 길이 제1사분위: {}'.format(np.percentile(train_length,25)))\n",
    "print('리뷰 길이 제3사분위: {}'.format(np.percentile(train_length,75)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['아 더빙.. 진짜 짜증나네요 목소리',\n",
       " '흠...포스터보고 초딩영화줄....오버연기조차 가볍지 않구나',\n",
       " '너무재밓었다그래서보는것을추천한다',\n",
       " '교도소 이야기구먼 ..솔직히 재미는 없다..평점 조정',\n",
       " '사이몬페그의 익살스런 연기가 돋보였던 영화!스파이더맨에서 늙어보이기만 했던 커스틴 던스트가 너무나도 이뻐보였다',\n",
       " '막 걸음마 뗀 3세부터 초등학교 1학년생인 8살용영화.ㅋㅋㅋ...별반개도 아까움.',\n",
       " '원작의 긴장감을 제대로 살려내지못했다.',\n",
       " '별 반개도 아깝다 욕나온다 이응경 길용우 연기생활이몇년인지..정말 발로해도 그것보단 낫겟다 납치.감금만반복반복..이드라마는 가족도없다 연기못하는사람만모엿네',\n",
       " '액션이 없는데도 재미 있는 몇안되는 영화',\n",
       " '왜케 평점이 낮은건데? 꽤 볼만한데.. 헐리우드식 화려함에만 너무 길들여져 있나?',\n",
       " '걍인피니트가짱이다.진짜짱이다♥',\n",
       " '볼때마다 눈물나서 죽겠다90년대의 향수자극!!허진호는 감성절제멜로의 달인이다~',\n",
       " '울면서 손들고 횡단보도 건널때 뛰쳐나올뻔 이범수 연기 드럽게못해',\n",
       " '담백하고 깔끔해서 좋다. 신문기사로만 보다 보면 자꾸 잊어버린다. 그들도 사람이었다는 것을.',\n",
       " '취향은 존중한다지만 진짜 내생에 극장에서 본 영화중 가장 노잼 노감동임 스토리도 어거지고 감동도 어거지',\n",
       " 'ㄱ냥 매번 긴장되고 재밋음ㅠㅠ',\n",
       " '참 사람들 웃긴게 바스코가 이기면 락스코라고 까고바비가 이기면 아이돌이라고 깐다.그냥 까고싶어서 안달난것처럼 보인다',\n",
       " '굿바이 레닌 표절인것은 이해하는데 왜 뒤로 갈수록 재미없어지냐',\n",
       " '이건 정말 깨알 캐스팅과 질퍽하지않은 산뜻한 내용구성이 잘 버무러진 깨알일드!!♥',\n",
       " '약탈자를 위한 변명, 이라. 저놈들은 착한놈들 절대 아닌걸요.',\n",
       " '나름 심오한 뜻도 있는 듯. 그냥 학생이 선생과 놀아나는 영화는 절대 아님',\n",
       " '보면서 웃지 않는 건 불가능하다',\n",
       " '재미없다 지루하고. 같은 음식 영화인데도 바베트의 만찬하고 넘 차이남....바베트의 만찬은 이야기도 있고 음식 보는재미도 있는데 ; 이건 볼게없다 음식도 별로 안나오고, 핀란드 풍경이라도 구경할랫는데 그것도 별로 안나옴 ㅡㅡ',\n",
       " '절대 평범한 영화가 아닌 수작이라는걸 말씀드립니다.',\n",
       " '주제는 좋은데 중반부터 지루하다',\n",
       " '다 짤랐을꺼야. 그래서 납득할 수 없었던거야.. 그럴꺼야.. 꼭 그랬던걸꺼야..',\n",
       " 'kl2g 고추를 털어버려야 할텐데',\n",
       " '카밀라벨 발연기',\n",
       " '재밋는뎅',\n",
       " '센스있는 연출력..탁월한 캐스팅..90년대의 향수.. 그래서 9점..',\n",
       " '엄포스의 위력을 다시 한번 깨닫게 해준 적.남 꽃검사님도 연기 정말 좋았어요! 완전 명품드라마!',\n",
       " '졸쓰레기 진부하고말도안됌ㅋㅋ 아..시간아까워',\n",
       " '재밌는데 별점이 왜이리 낮은고',\n",
       " '1%라도 기대했던 내가 죄인입니다 죄인입니다....',\n",
       " '아직도 이 드라마는 내인생의 최고!',\n",
       " '패션에 대한 열정! 안나 윈투어!',\n",
       " '키이라 나이틀리가 연기하고자 했던건 대체 정신장애일까 틱장애일까',\n",
       " '허허...원작가 정신나간 유령이라... 재미있겠네요!',\n",
       " '포스터는 있어보이는데 관객은 114명이네',\n",
       " '이 영화가 왜 이렇게 저평가 받는지 모르겠다',\n",
       " '단순하면서 은은한 매력의 영화',\n",
       " \"'다 알바생인가 내용도 없고 무서운거도 없고 웃긴거도 하나도 없음 완전 별싱거운 영화.ㅇ.ㅇ내ㅇ시간 넘 아까움 .. . 완전 낚임\",\n",
       " '오게두어라! 서리한이 굶주렸다!',\n",
       " '정말 맘에 들어요. 그래서 또 보고싶은데 또 보는 방법이 없네? >.. ㅜㅡ',\n",
       " '윤제문이라는 멋진 배우를 발견하게 됐어요. 소소한 일탈이 잔잔한 미소를 머금게 합니다. 음악은 조금 아쉽네요ㅠㅠ 8점 주고 싶은데 평점 올리고 싶어 10점 줄게요^^',\n",
       " '평점에속지마시길시간낭비 돈낭비임',\n",
       " '리얼리티가 뛰어나긴 한데 큰 공감은 안간다. 이민기캐릭터는 정신의학상 분노조절장애 초기 증상일거다. 툭하면 사람패고 욕하고 물건 파손하고.. 조금 오바였음. 극 초반엔 신선했는데 가면 갈수록 이민기 정신상태 공감불가.',\n",
       " '마이너스는 왜없냐 ㅋ 뮤비 보고 영화수준 딱 알만하더군 ㅉㅉ 북한에서 이런거 만들라고 돈 대주던?',\n",
       " '난 우리영화를 사랑합니다....^^;',\n",
       " '데너리스 타르 가르엔...나도 용의주인이 되고 싶다...누이랑,근친상간이나 하고 다닐지라도,소설 속에선 제일 멋진 놈이 자이메 라니스터였는데,드라마속에선,드래곤(용)이 제일 멋지네(웃음)감독님 토르-2 다크 월드는 말아 잡수셨을지라도,기본 선방은 했음',\n",
       " '영화가 사람의 영혼을 어루만져 줄 수도 있군요 거친 세상사를 잠시 잊고 동화같은 영화에 행복했네요',\n",
       " '야 세르게이! 작은고추의 매운맛을 보여주마! 포퐁저그 콩진호가 간다',\n",
       " '이렇게 가슴시리게 본 드라마가 또 있을까? 감동 그 자체!',\n",
       " '난또 저 꼬마애가 무슨 원한이 깊길래.,. 했더니 OO 그냥 혼자 나대다 OO걸 어쩌라고.',\n",
       " '재미있어요',\n",
       " '전 좋아요',\n",
       " '최고',\n",
       " '너무 충격적이엇다. 기분을 완전히 푹 꺼지게 하는 느낌... 활력이라고는 하나도 없는 너무나도 무거운....지독하고 차갑고 무자비하다. 그저 일본인들의 상상력은 정말 대단한거 같다는 생각이 든다.',\n",
       " '심심한영화.',\n",
       " '백봉기 언제나오나요?',\n",
       " '보는내내 그대로 들어맞는 예측 카리스마 없는 악역',\n",
       " '불알이 나와서 당황...아무튼 영화가 중간에 끝나는 느낌',\n",
       " '평범함속에 녹아든 평범한 일상. 조금 밋밋한게 흠.',\n",
       " '보던거라 계속보고있는데 전개도 느리고 주인공인 은희는 한두컷 나오면서 소극적인모습에 짜증이 ㅜㅜ 맨날 언제끝나나 기대만하고있어요 전개좀 빨리빨리 ㅜㅜ',\n",
       " '사랑하고싶게하는,가슴속온감정을헤집어놓는영화예요정말최고.',\n",
       " '많은 사람들이 이 다큐를 보고 우리나라 슬픈 현대사의 한 단면에 대해 깊이 생각하고 사죄하고 바로 잡기 위해 노력했으면 합니다. 말로만 듣던 보도연맹, 그 민간인 학살이 이정도 일 줄이야. 이건 명백한 살인입니다. 살인자들은 다 어디있나요?',\n",
       " '예전 작품 캐릭터, 에피소드 재탕 삼탕 사골우려먹듯 우리고 내용은 산으로 가고 시청률은 아예안나오고 이제 70회중반인데 120부작이라니 ...',\n",
       " '김남길의 백점짜리 연기력과 초반 몰입도에도 불구하고 지루하고 손예진 ㅈㅈ',\n",
       " '재밌네 비슷한 영화를 안보신 분들한테는 재미있을 듯',\n",
       " '노래실력으로뽑는게 맞냐? 박시환이 mama나가면 진짜 망신이다',\n",
       " '아 일본영화 다이런건가?? 유치하다',\n",
       " '이틀만에 다 봤어요 재밌어요 근데 차 안에 물건 넣어 조작하려고 하면 차 안이 열려있다던지 집 안이 활짝 열려서 아무나 들어간다던가 문자를 조작하려고하면 비번이 안 걸려있고 ㅋㅋㅋ 그런 건 억지스러웠는데 그래도 내용 자체는 좋았어요',\n",
       " '졸작',\n",
       " '재밋네요 달팽이가 빨라서 더 재밌었어요',\n",
       " '어설픈 전개 어이없는 결말',\n",
       " '부패한 로마노프 왕조를 기리는 뭣같은 영화... 온몸으로 항거했던 러시아 민중들이 그저 폭도냐',\n",
       " '내용전개는 무난한 편이였구 잘 보았습니다 ^^',\n",
       " '매우 실망.....',\n",
       " '한국영화 흥행코드: 갈등-갈등-계~에속 갈등-화해-감동- 평점 10점 남발- 흥행 뻔하지 뭐...',\n",
       " '아햏햏 아햏햏 아햏햏.',\n",
       " '뭐냐..시작하고 3분만에 나왔다. 리플릿 사진 보며 불안하더니만..',\n",
       " '단연 최고라고 할수있지',\n",
       " '감독이 럼먹고 영화를 만들었나보다.. 관객에게 뭘 말하는지도 모르겠고, 엉망진창 개진창이다.',\n",
       " '이건 뭐냐? 우뢰매냐? ;;;',\n",
       " '정말쓰레기영화입니다',\n",
       " '진정 위대한 영화 최고임',\n",
       " '별루 였다..',\n",
       " '내일이 기대되는 `',\n",
       " '근데 조미가 막문위 좋아한건가요??',\n",
       " 'ㅋㅋㅋ 진짜 골깜..ㅋㅋ 눈 부라릴때 쓰러짐..ㅋㅋ',\n",
       " '성룡영화중 최악인듯 ㅋㅋ',\n",
       " '골때리네ㅋㅋㅋㅋ 걸스데이 이혜리 잘 되라!',\n",
       " '서기가이뻐서',\n",
       " '완전 재밌어요ㅋㅋㅋㅋㅋ백인공주귀여움ㅋㅋㅋㅋㅋㅋ',\n",
       " '인상적인 영화였다',\n",
       " '어내스트와 셀레스틴 완전 강추에요~ 정말 재밌습니다^^',\n",
       " '재미있는영화입니다.',\n",
       " '클라라볼라고화신본거아닌데',\n",
       " '진짜 보면서 너무 슬펐던 영화다',\n",
       " '설정이 재밌고 새로운 에피소드 내에서 메인 스토리도 차차 나오는게 재밌음',\n",
       " '신카이 마코토의 작화와,미유와 하나카나가 연기를 잘해줘서 더대박이였다.',\n",
       " '재미없음 진심 1이훨나 캐스팅두못한듯',\n",
       " '잔잔한게 생각보다 볼만한 영화인거 같습니다 ㅋ',\n",
       " '감독님들 고은님 쓰면 영화안봅니다 .',\n",
       " '무섭지도 않았고 스토리도 ..ㅡㅡ',\n",
       " '영화속 억지스럽고 노골적인 술광고를 좀 은은하고 센스있게 했으면 어땠을까?',\n",
       " '킬링타임',\n",
       " '크리스마스하면 떠오르는영화',\n",
       " \"재미있게 봤습니다. 매력적인 행복이네요, '-' ㅎㅎㅎ.\",\n",
       " '음악에 완전히 빠져서 볼 수 있었던 영화. 쫌 산만하긴 하던데;;',\n",
       " '태어나서 처음으로 영화보다 중간에 나왔습니다,,,,불륜이 로맨스냐,,',\n",
       " '왕짜증.....아주 전개를 짬뽕으로 믹스했구나...음향만 무섭게하네..하아',\n",
       " '솔직히 난 별루더라 시간낭비느낌',\n",
       " '대박',\n",
       " '시청률 기준이 되는 패널가구들 머하는거지 명작드라마 다 망치네 ㅡㅡ 내가 다 서운하다...',\n",
       " '내용이 이상해;',\n",
       " '몬스터 주식회사 3D 재밌게 봤다',\n",
       " '내용전개가 너무나 느리다........',\n",
       " '소재는 흥미를 끌지만 이야기 전개가 투박해서 몰입이 안되는군',\n",
       " '절대 보지마라 쓰레기 영화',\n",
       " '중국인 특유의 과장, 허풍... 있어보이려고 안간힘 쓴 노력은 가상하나, 고증과 현실감 떨어지는 설정이 거북스럽다... 도대체 그들은 왜 이렇게까지 스스로를 과대포장하는 것인지...',\n",
       " '그냥 불법체류자 때려잡는 영화면 좋았을텐데...무슨 우상화를 만든다고 미국의 따뜻한 설정...이건 뭥미??',\n",
       " '2년의 삶속에 주인공의 생애가 전부 드러난 듯 하다.',\n",
       " '별점10점가자',\n",
       " '별로다.',\n",
       " '본지 꽤 지난 후에 남기지만...재미있었음',\n",
       " '아니 이게 왜 9점대 일까...;;;',\n",
       " '10년이 지나 다시 보게된 영화 .. 다시봐도 그 순수한 사랑에 감동 ㅠㅠ 숀펜의 연기또한 甲',\n",
       " '올레에 공짜로있길래 봤음 ㅋㅋ 헐 ... 스토리가 문제가아니라 연기자들이 전혀 배역이랑 어울리지않음 그리고 상대배우들하고 다 따로 노는거같음~~ 이건 연기자들도 문제있음 보아는 진심 완전 별로임 라미란하고 아들이 젤 볼만했음',\n",
       " '너무 욕심이 많았던 영화. 어느 한 쪽만이라도 제대로 보여줬다면......',\n",
       " '아 빵점~',\n",
       " '베댓이 말을 아주 잘써놨네',\n",
       " '아주 모자라진 않다.',\n",
       " '영화 도둑들이나 뫼비우스 하고 같은 나라에서 만들어졌다는게 믿어지냐..?',\n",
       " '온몸이.. 찌릿..짜릿. 나두 용기를 가져야지!!',\n",
       " '정말재미있고 교훈적인 영화이네요!',\n",
       " '당시의 상황과 주제를 주입식이 아닌 긴장감있고 재밌게 전하는 작품',\n",
       " '케이블에서 그만 나와줬으면 - -',\n",
       " '다르덴,이냐리투,차이밍량이 하나도 안섞인채 짬뽕 그릇에 담겨있다.',\n",
       " '여군 잼없음 뭐하는건지 ...ㅡㅡ잼없음 엠비씨 다잼없음 질린다이제',\n",
       " '좋구나',\n",
       " '한석규, 김혜수 연기만 돋보인 영화. 어딘지 모르게 많이 어설픈 영화.',\n",
       " '솔직히 에볼라바이러스가 떠들석해서 보게된영화인데 작품성이나 어떤면에서도 20여년전 영화라고보기엔 믿기힘들정도로 정말 잘만들었다고본다 마지막후반부가 살짝 아쉽긴하지만 이정도면 수작이라고본다 시간이 아깝지않은영화',\n",
       " '볼만해;',\n",
       " '재미있다고 허풍 떨지 마세요',\n",
       " '용가리 진짜짱짱맨이다ㅋ',\n",
       " '이 영화를 이제서야 보다니.. 감히 내 인생 최고의 영화중 하나로 꼽을 수 있을만한 작품. 어떻게 살아야할지 나를 위한 고민을 한번 더 하게 되는 시간. 그리고 모건 프리먼은 나이가 들어도 여전히 섹시하다.',\n",
       " '작가가별로다 내용이진짜별로임.. 맨날그냥기대하고 재방송하면 혹시나하고봐줘도 답없다진짜..',\n",
       " '명작도 이런 명작이 있을까 싶다. 보고 또 봐도 여운이 남는 영화.',\n",
       " '아~ 진짜 조금만 더 손 좀 보면 왠만한 상업 영화 못지 않게 퀄리티 쩔게 만들어 질 수 있었는데 아쉽네요 그래도 충분히 재미있었습니다 개인적으로 조금만 더 잔인하게 더 자극적으로 노출씬도 화끈하게 했더라면 어땠을까 하는 국산영화라 많이 아낀 듯 보임',\n",
       " '그만좀 끌고 이제 끝내라. 지겹다 지겨워.',\n",
       " '아',\n",
       " '역시 드니로의 연기는 일품 나도 맥스가 샘을 죽이길 바랬다',\n",
       " '나름 괜찮은 작품입니다',\n",
       " '너무 좋은 영화',\n",
       " '정말 실망 스러웟음..',\n",
       " '배우들은 지네들 안뜨니까 이런영화 찍을껀데??? 왜 안뜨는지 진짜 모르는거야? 면상 딱 보면 알겠구만... 왜 지네 자신들은 모를까?',\n",
       " '어린이가 좋아할듯...내어릴적 동심은 멀리 떠낫나보다.',\n",
       " '무술인이 왜 총을드나?',\n",
       " '10점',\n",
       " '크리스토퍼왈츠와 타란티노의 조합이란 ㅠㅠ',\n",
       " '한국에선유명한편은아니지만 외국에선 상상초월한 유명한 영화입니다.',\n",
       " '오랜만에 재밋는영화봤네요',\n",
       " '종방되어 아쉬워요. 오늘막방도 잘봤어요.방송대본이 꽤 완성도있다는 느낌받았고요. 요즘 드라마들의 막장에 지쳐있었는데 수백향은 정말 바른드라마였던듯해요.악역들도 그리 심하게 어이없지도 않았고요..MBC화이팅!!',\n",
       " '평점조절위원회에서 나왔습니다(웃음)김혜선은 @내일이 오면@의 김순정,순정이 역할이 제일이다.팜므파탈로써,그 정도까지 잘해낼 줄은,정말 의외였어...연기20년 한사람에게 요즘 사극에서 벌어지고 있는,그녀에 대한 연기논란은 왠지 코미디의한장면 같음(웃음)',\n",
       " '\"\"\"영화 끝나갈때쯤에 멍하다가 다보고나면 한마디 나올거임 \"\"\"\"ㅈ같다.\"\"\"\"\"\"\"',\n",
       " '공유 존잘!!!ㅎㅎㅎ',\n",
       " '상쾌발랄한 영화다. 말하기 껄끄런 성이란 소재를 유쾌하게 해설했다.',\n",
       " '소파에 죽 치고 앉아 지켜 볼 이유가 없는 작품.',\n",
       " '로큰롤!!!!!!!!!!!!!!',\n",
       " '주된 타겟이 어린이니 일반적인 논리가 통하지 않는 건 알겠다. 하지만 게임은 흥미롭지 않고, 요원이라는 주인공이 너무 무능력해서 별로 재미없다. CG 배경도 거슬린다.',\n",
       " '뮤지컬 영화인데 사운드 녹음 엉망, 남주는 춤도 못추고, 내용은 뻔할뻔, 주인공들 목소리도 너무 안어울리고 어제 CGV에서 뛰어 나가려다 참았습니다.진심 말리고 싶습니다. 영국의 저예산 DVD용 영화뮤지컬영화 아닙니다. 맘마미아 1/10도 안됨',\n",
       " '어린나이에 봤음에도 꽤나 좋아했던 로맨틱코미디',\n",
       " '게이물인줄 모르고 봤네...',\n",
       " '알바는꺼저라',\n",
       " '이 영화 머임????내가 왜 받아 봤을까? 그것이 알고싶다....이 영화는 배우들과 스텝들이 감독의 꼭두각시였음.',\n",
       " '4대2라니....최악',\n",
       " '정말 아름다운 영화 입니다',\n",
       " '자극적인 것에 익숙해진 현대인이 봐도 눈을 떼기 힘든 연출력.',\n",
       " '뻑~뻑~잘 읽어볼걸 나도 당했음',\n",
       " '정말 짜증의 극치를 보여주는영화. 굉장히 언밸러스한 느낌. 뚱뚱하고 못생긴 남자애의 발연기를 시종일관 봐야하는게 고역인듯. 간간히 흘러나오는 잔잔한 클래식풍의 음악조차도 듣기싫어 짜증날정도로 상당히 싫은영화.',\n",
       " '감동감동ㅜㅜ, 정말 최고네요!!!!',\n",
       " '별점 주기도 아깝네요 얼마나 내용이 진부한지 욕 밖에 안나오네요보고 재밌다고 하는 사람 초딩들인가요 죄송해요 너무 화가나서.아무 것도 볼게 없습니다 보지 마세요 그냥 티비판짜집기 한거 같네요',\n",
       " '나 왠만해서 짜증안내는데...-_-',\n",
       " '돼지피먹고 닭목따는 장면에선 우웩~ 역시 무당은 아무나 하는게 아니다.',\n",
       " '버려',\n",
       " '유치하고 지루하고 잠이 왔다',\n",
       " '3류풍 판타지 3점만 가져가',\n",
       " '윤종신 복귀는 좋았지만 이하늘은 도대체 왜 뽑혔는지 알수가없다. 참가자 실력을 따지기 전에 심사위원 인격과 실력부터 쌓고 오시길^^ 어하어허 그만좀 하고요',\n",
       " '광장한 작품 옛날것도 보고 싶다',\n",
       " '내 생의 최고의 영화',\n",
       " '어린시절 너무 무섭고 재미있게 봤던 추억의 판타지영화.절대 나쁜짓은 금물.지옥가요..',\n",
       " '기존 멜로영화 형식을 탈피하려고 하였으나 감정의 절제가 지나쳐 너무 담백한 영화',\n",
       " '난 사랑비 서준에게 쏙 빠져버렸네. 1.2.3초만에 쏙ㅋㅋ난 절대잊지도않고후회도안할거야',\n",
       " '이영화를보니까 교훈을 주네요! 나도 남은인생을 화려하게 살아야겟다.. 말밖에 안나오네요..',\n",
       " '나름 추억에 젖어들고 좋았음ㅋㅋ아무생각없이 가볍게 보고오기 추천요~',\n",
       " '단순한 싸이코물을 벗어난',\n",
       " '이게 14년도에 만들어진건가요? 아니면 예전에 만든거 다시개봉한건가요?ㅠ너무 허접해요 ㅠ',\n",
       " '넘 사랑스러운 영화다 ㅠㅠ 1보고 2 연이어 봤다~!! 넘 귀여워 ㅠㅠ♥♥',\n",
       " '청춘 영화만이 줄 수 있는 감성이 넘쳐난다. 이 순간 지나가면 다시 돌아오지 않을테지만, 그 순간만큼은 무한할 젊음이 줄 수 있는 그런 감성.',\n",
       " 'TV용 건담 시리즈 중에서 아직까지도 최고봉',\n",
       " '개콘은 요즘 갈수록 코너들이 다노잼이고 웃음이안난다',\n",
       " '사다코의 한이 서린 우물펀치ㅜㅜ 감동',\n",
       " '후세와 사랑하게된 결정적 계기 그시간이 표현되지 않았으며 시람의 생명을 빼앗아야만하는이유등을 시노가 출현하는 연극으 로 더 알려주었으면 하는 생각이든다. 또한 시노가 얼마나 본능을절제히면서 시랑을 하려고 노력하는지를 더 보여줬다면 좋았을뻔했다',\n",
       " '새벽시간에 하는 일본 영화들은 전부 개졸작이다.일본영화원래 다이래??',\n",
       " '강수연의 나가있어~!그리고 최정원의 신음신~',\n",
       " '아..정말 김혜성 너무 예쁘네요 이현진도 웃는 거 정말...하....',\n",
       " '가발 쓰고 싶다',\n",
       " '화려한여정이인상깊어요ㅋㅋ재밋어요ㅋㅋ배두나연기정말잘해요ㅋ',\n",
       " '10대들을 위한 성적 호기심 영화?',\n",
       " '감동적인 영화',\n",
       " '이건 말이 필요 없다 그냥 닥치고 봐라',\n",
       " '각기 다른 사람들의 재밌고 멋진 사랑영화',\n",
       " '역시 미국드라마의 파워. 정말 알수없는 그 미묘함까지 사로잡아버렸다 최고!!',\n",
       " '너무너무 훈훈하네요^^',\n",
       " '이거 응답하라에서 은지원원도 스스로 욕하지 않앗나? ㅋㅋㅋㅋ',\n",
       " '아 너무 웃기고 배꼽 빠질뻔했네^^ 내 컴에 이 영화 있는데^^',\n",
       " '구성이 상당히 부실한 영화. 역시 네이버 평점은 믿을수 없다.',\n",
       " '장끌로드의 몰락을 가져온 오우삼 헐리우드 작품중 가장 재미없었던 졸작',\n",
       " '언제적 영웅본색 연출인지 현실성 제로인 영화',\n",
       " '작은거 하나에도 설레어했던 학창시절 그때 그느낌을 다시 느껴볼수있는시간이었다. 장면 하나 하나 대사 하나 하나 배경음악 하나 하나 버릴게 없는 드라마.',\n",
       " '진심 재미 없는데 너무 평점 높아서 화남;',\n",
       " '더럽게 재미없다 어떤 형태로도 와 닿지 않는 허무하고 완벽히 지루한 영화고 영양가 하나도 없는 영화다',\n",
       " '이승기 정말 연기 잘하는.. 조연들도 연기 정말 잘하고',\n",
       " '현실은 꿈, 꿈은 현실',\n",
       " '오늘 현충일특집프로로 보게되었습니다 1963년도의 매우 훌륭한 작품입니다',\n",
       " '판의미로와 동급 trash of the trash',\n",
       " '제대하고 보니까 더 재밌네요 ㅋㅋㅋㅋ',\n",
       " '영화를 보는것만으로도 마음의 휴가를 다녀온 느낌.소박하지고 잔잔하지만 지루하지않은..그래서 다시 보고싶은 영화.햇살가득한 비이의 부엌과 요리도 인상적',\n",
       " '코믹한건 좋았는데 짜임새가 너무 허술하다',\n",
       " '1996년 그때 당시에는 우리 나라에 이런 판타지 로맨스가 없었다... 아직도 신현준의 황장군 연기는 음... 괜찮네... ㅎㅎ....한석규의 전성시대가 열린 영화.... 이때 한석규한테 뿅 갔었다~~♥',\n",
       " '일단 재생하면 괴물같은 서스펜스 귀신같은 흡입력',\n",
       " \"하..진짜 댓글보고 한번쯤볼만한 영화인거같아서봤지만 기가찬다..이게무슨버킷리스트인가! 죽기직전에 소원들어주기? 내가보기엔 죽기직전에 막 살자 인거같다. 감동도없고.. 진짜 '버킷리스트' 란 영화에 발톱에 때만큼도 못따라가는쓰레기영화.. 완존실망..\",\n",
       " '이시간좀...밝고긍정적인드라마보고싶어서..보긴보는데....오버하는연기들이거슬리네요...연기인게너무표나요....홍혜정역이그나마도후련기도하고시원하고.....나머진다들답답하네요...낼월요일인데...해피한것만보고싶네요....',\n",
       " '정치인의 모순인가, 정치범의 모순인가....',\n",
       " '어떻게 이런 상상을 대단하다.',\n",
       " '좀 어렵기도 하고, 전쟁에 대한 묘사가... 잘 모르겠다.',\n",
       " '일본에서10주년 극장판만드는데 우리나라에선 10주년으로 재개봉하니이건 좀 ㅄ 아님?',\n",
       " '한대희가 개그콘서트본다고 내전화끊음개그콘서트 없애주세요 ㅡㅡ',\n",
       " '한물 간 동서양 두 배우의 싸움판.',\n",
       " '푸하하하 이거 기대 안했지만.. 역시나 구만..ㅋ',\n",
       " '세계최초의 반공 애니매이션이라는 역사적 가치가 있다.',\n",
       " '감각적인..시각으로...바라보는..색다른...느낌의...사랑...문학적이',\n",
       " '엄마는 무고한 지 딸을 감옥살이 시켜시켜? 이해 안돼요',\n",
       " '이영화는.제발 책을보세여.감독이 미친겁니다.이따위로 만들어놓고.화가 날정도 ㅡㅡ',\n",
       " '신나는 흑인음악과 아이스 큐브 뿐 남는게 없다',\n",
       " '드럽게 재미없네 시간이 돈이다? 내 시간은 어쩔건데',\n",
       " \"그저 한마디뿐 '알리시아'\",\n",
       " '진짜 생생하게 느낄 수 있었다',\n",
       " '재밌는데 평점이 이상하다 싶을 정도로 낮다.',\n",
       " '옥소리 프로필 사진에 1점남기고 갑니다 ㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋ완전 대박이다 진짜 아우 짜증나!',\n",
       " '드라마 너무 재밓당',\n",
       " '아진짜너무좋아요ㅜㅜ짱짱!!!',\n",
       " '연기 굿',\n",
       " '이런 영화 다시는 안나오겠지..그때 시절을 잘나타내주었던거같아요 ㅎㅎ',\n",
       " '중간정도 부터 봤는데도 꽤나 대단하군요...',\n",
       " '콩은 까야 제맛 콩은 까야 제맛',\n",
       " '이적의 소설. 재미없다.',\n",
       " '액션영화가 아니다.범죄 느와르 영화다. 허나 범죄 느와르 영화로서도 실패작.......',\n",
       " '뭔가알수없는매력에빠져드는 영화',\n",
       " '모녀를 토막살해한 살인자가 부성애라니.... 말이되나... 감동받은 사람들 본인들이 피해자가 되도 감동받았다고 할수있을까... 진심 묻고싶습니다...',\n",
       " '재밌는데 평점이 왜 이렇게 구리지',\n",
       " '아 OOO기.. 이걸 본 내눈이 아깝다 ㅡㅡ 진짜 아놔 진짜 OOO기명작이네요',\n",
       " '필름값이 아깝다..재미 더럽게없다..2점부터 점수준것들 매미 OO',\n",
       " '또보고 싶은데 어디서 보죠???',\n",
       " '영화 재미있드만.. ㅎㅎ',\n",
       " '남주인공 연기력 안습이네요... 혀짧은 소리 듣기도 너무 힘들었네요 매니저역활분이 남주인공하는게 훨 좋았겠다는 생각이 들정도... 영화 자체는 적당히 볼 만 합니다 ^^',\n",
       " '3점이 딱.... 액션,스릴러인데 액션과 스릴이 없다.',\n",
       " '완전 스토리도 엉망이구, 완전 비추..ㅜ',\n",
       " 'OOO영화 뭘전달하려는지모르겠네 오글거리고',\n",
       " '좋은영화',\n",
       " '......더빙이 이상해요.....할머니는 월래익숙한 ㄷㅔ.....',\n",
       " '이게 2편이 나왔어???',\n",
       " '모든게 2%씩 다 부족했다...아니..50%씩...',\n",
       " \"정말 말 그대로 '쇼'하는 영화..\",\n",
       " '12년 전에 봐서 기억이 나질 않지만 진개가(천카이거) 감독 이름 세 자는 기억해 두었던.',\n",
       " '정은지 언니!! 연기 잘하구..노래도 잘부르시고! 마지막회 웃으면서 즐겁게! 봤습니다! 트로트의 연인!♥',\n",
       " '이게 웃겨?',\n",
       " '망함',\n",
       " '아이의 시선으로 보는 전쟁.., 보는 내내 가슴이 먹먹했다는...',\n",
       " '사람들이 재미없다고 해서 레알 기대 안했는데 생각보다 볼만함. 근데 여자애랑 복순이랑 다투는 장면? 그건 굳이 없어도 됐다고 생각함 몰입도 겁나 없애고, 어색해보였음',\n",
       " '설정이 연속극같은 느낌이 든다. 하지만 배우들의 연기가 뛰어나다.',\n",
       " '여주인공 인터뷰할때 지루해죽는줄알았음 ㅡㅡ 그냥저냥 킬링타임용 스릴러',\n",
       " '전미 박스 오피스1위 ㅋㅋ 그냥 몰아주기 하는건가 어떻게 이런영화가 1위를 하지 옛날 80~90년대 우뢰매수준의 물폭탄싸움이네 ㅋㅋ 손에서 빔나가나 손에서 물폭탄 나가나 다를게 뭐지?',\n",
       " '감독이 여자다보니 기량이 많이 딸리네',\n",
       " '또 보고 또 울.었.다..',\n",
       " '이런 영화는 하나의 개연성만 없어도 허무하게 만들어 버린다. 조디포스터의 이쁜 모습만 남을 영화.',\n",
       " '굳굳',\n",
       " '스토리도 말이 안되고 개막장 사랑이야기도 아니예요 이걸보고계신다면 당신의 시간과돈을 아낀거예요^.^휴 그래도 본다면 호구',\n",
       " '네놈을 살려두기엔 쌀이 아까워! 세기의 명대사',\n",
       " '평점이 너무 높다. 전혀 재미있지 않았다. 쓸데없이 말만 많음. 이런 류의 영화는 조연들의 뒷받침이 중요한데 조연들의 내용자체가 전혀 없음. 또한 여배우도 별로 매력 없었다. 이틀전에 저스트고위드잇의 애니스톤을 보고 이 영화를 봐서 그런가. 실망했음',\n",
       " '맛깔 나는 드라마.',\n",
       " '시베리아인가 거기가서 훈련할때나오는 ost 개작살',\n",
       " '이건 시종일관 질~~질왜? 제목이 야경꾼 일지냐고 지금 10회가 넘어가는데 즉 2달이 넘어가는데. 앞에서 누군가가 얘기 하더만 이거 100부작이냐고 그러다 또 한 순간에 모든걸 훅진짜 지루함의 지존',\n",
       " '나이들수록 이해가 가는 영화',\n",
       " 'ㅠㅠ 슬픔',\n",
       " '장면 개연성도 없고 아역은 연기도 못하고 무슨 추노에 나오는 민폐언년 외국판인줄....초반만 그럴싸한 저급영화',\n",
       " '이 영화 정말 별루예요. 결말이 이상해요....',\n",
       " '딱히 재미는 없네요 킁;;',\n",
       " '송강호는 정말 연기를 하기위해 태어났고 그로인해 우리는 즐거움을 느낀다 역시 송강호는 연기파다.',\n",
       " '일본영화 수입 금지 시절에도 비디오 테이프로 돌려봤던 불후의 명작 아 그립다',\n",
       " '살인을 소재로 한 영화가 이토록 재밌을 줄이야. 살인에 대한 감독의 해석이 정말 재치있다. 대 배우님들의 10여년전 모습도 새롭웠고. ㅋ. 정말 유쾌하고 재밌다.',\n",
       " '누미 라파스 신봉선 닮아서 안 본다',\n",
       " '케이블에서 그만 좀 재탕해라.',\n",
       " '멋졌다. 정말이지, 멋지다는 말 이외엔 할 말이 없다.',\n",
       " '98년에 어떻게 이런영화가 만들어졌는지 의문.. 당대 최고의 영화 지금봐도 퀄에서 결코 떨어지지 않아요',\n",
       " '지금 이거 티비로 돈내고 보고있는 내가한심하다',\n",
       " '쓰레기 연예인 재기의 장~~그러나...',\n",
       " '굿 좋아',\n",
       " '많은 감동을 준 드라마이다.',\n",
       " '발로만든영화. 지진나서 주인공 넘어지는데 뒤로 사람들 유유히 걸어다니고 있음. 발CG + 발연기 + 발시나리오.... 내용도 정말 뭐같음 ㅋㅋㅋ',\n",
       " '적당히 해야지 언제 끝나는것인가?',\n",
       " '잊을 수 없는 안개낀 워터루 다리와 마스코트.',\n",
       " '곤사토시 감독... 2010년 안타깝게 돌아가셔서 가슴이 먹먹합니다.. 정말 천재적인 감독인데 암으로 가시다니.. ㅠㅠ 이제와서 다시봐도 모든 작품이 대작...',\n",
       " '많은생각을 하게 됐습니다. 예뼈지고 싶은 맘은 있었지만 과하면 독이겠네요. ^^',\n",
       " '아 츠무구만 없어지면 별 5개줄게',\n",
       " '어릴땐 조폭영화로 알다가 나이가들수록 이게 인생이구나 하고 뭉클해지는 영화.세상을 살아가면 갈수록 와닿는게 많아지네요...세상은 비정하지만 비정함마져도 따뜻해지는게 친구라고...',\n",
       " '영상이 너무나도 멋지다.',\n",
       " '비디오가 있어서 봤는데 1997년도인줄모를정도로 잘만들었습니다 긴장감도있고',\n",
       " '처ㅝ주',\n",
       " '2009년에 만들어진것치곤 재밌음 영화가 길어서 좀 다듬었으면 ..소재도 좋고 몰입감도 기대이상 매끄럽지 못한 부분도 있지만 연기는 둘 다 잘한듯',\n",
       " '철지난 조폭 코미디와 뼈대 있는 가문의 이야기를 섞었지만, 둘 다 지루하다. 박정아를 비롯해 배우들은 보기 민망한 연기를 펼치고, 기억에 남는 건 하나도 없다.',\n",
       " '군더더기 없이 잘 진행되는데 재미도 없는게 문제',\n",
       " '심심해서봤는데 재밌네요 탑연기 못할줄알았는데배우포스나고 잘하군요',\n",
       " '고다미 괜찮음',\n",
       " '아 지대짜증 아빠랑 봣는데 민망해 죽는줄',\n",
       " '0점은 못주냐??',\n",
       " '빠순이 영화 ㅋㅋㅋㅋㅋㅋㅋ 훈훈하긔 재밋쎠',\n",
       " '최악의 애니메이션.. 지루하고 재미없고 스토리마저 진부하다',\n",
       " '좋은 의도와는 다르게 불쾌한 표현법',\n",
       " '줄리아로버츠 귀여운연인은 이거보다 5년전꺼다 ...',\n",
       " '신선하네..,,..,,..',\n",
       " '예술가로써의 한 사람의 인생과당시 시대적 상황을 질 느낄 수 있었던 명작',\n",
       " '관객수가 너무 아쉬운 영화...베테랑보다도 더 류승완감독의 역작이고 더 강한악역이다',\n",
       " '한창 핵펭귄이 남북 거짓평화로 전국민을 속이던때 만들어진 영화',\n",
       " '지금 티비에서 하는데.. 못 보겠다..',\n",
       " '여자애 한명이잘 못해서몇명이죽는거야ㅋㅋ답도없다ㅋ',\n",
       " '성룡의 헐리웃작 중 단연 최고지 ㅋㅋㅋ',\n",
       " '안습',\n",
       " '감독의 의도를 전혀 알아차리지 못했다.',\n",
       " '하나님이가정을온전히만든다. 진리이신분이만든영화. 눈으로만보지말고마음으로봐라.',\n",
       " '2편도 나름 흥미진진한데 핀헤드가 죽은게 좀 아쉬운 점이랄까?',\n",
       " '국산 코미디영화중에서 난 신라의달밤이 제일좋았음뭔가 푸근하고 따뜻함..',\n",
       " '최악이다 영화보다가 잠오긴첨임 지루해둑을뻔',\n",
       " '탄탄한 !~배우들 될고 ~머하는 건지~~~~~~~~~~~',\n",
       " '영화가 점점 끝을 달려갈수록 몰입도가 더 높아진 영화는 이번이 처음이네요.',\n",
       " '결국 감독 자신이 하고 싶은 의견을 지존파 핑계삼아 하려고 한듯. 지존파 살인은 정당화하고 정부탓이 였다는.사회탓이라는.',\n",
       " '사실여부를 떠나,알고왔던 아더와 너무 매칭이 안돼더라.원탁기사중 실제 검술 최고수는 랜슬롯으로 알고 있는데,트리스탄보다 못하고,싸우는 검술은 마치 중국검술 흉내낸거 같은게;; 그리고 란슬롯이 실제는 쌍검였나?너무 매칭이 안대 하튼 ㅋ기네비어역도 미스.',\n",
       " '대한민국 영화 수준의 평균치를 하락시키기에 충분한 C급 영상물',\n",
       " '0점은 없나??',\n",
       " '재밌는데',\n",
       " '재미없다... 기대 완전 했는데.... 완전 못함!!! 실망....',\n",
       " '종착역 없는 인생의 대유. 트레비스는 단지 흘러간다.',\n",
       " '돈과 시간이 아까운 영화',\n",
       " '네러티브는 하나도 없는 예쁜 음악 동영상. 취미로 영화만드는 것은 이걸로 끝나길 . 잘하는 음악에 올인하길.',\n",
       " '배우들의 연기는 좋았는데.. 뭘 말 하려는 건지?',\n",
       " '학위위조성범죄자 문제자들만 모아서 영화찍음 왜그랬으까 제작비 아끼려구 패자부활전 하냐?',\n",
       " '솔직히',\n",
       " '완전재미있어요.애들도보기에알맞는듯',\n",
       " '잔인하기도 하고 무서웠어요ㅠ탑은 멋있더라구요~~',\n",
       " '무섭지도 않고 기분만 나쁘고 쩝',\n",
       " '군더더기 없는 깔끔한 그러나 강한 메세지 전달. 뜻밖의 참좋은 영화..!',\n",
       " '이 영화는 최고다. 그냥 최고야 그런 줄 알아',\n",
       " '그랜드 부다페스트 호텔과 시리즈 같네.. 캐스팅이 아까워~',\n",
       " '빨리감기해서 봤음...투자비는 많이 들었을 것 같은데...영화사 망했네~ㅎ',\n",
       " '도대체 뭐가 재밌다는건지 모르겠네요 무슨 아이언맨 시리즈의 개그도 뛰어넘는다 하는데 어디서 웃어야할지도 모르겠고 내용도 뭔지 뜬금없는 히어로놀이는 또 뭔지.. 왜이렇게 평점이 높은지 모르겠습니다',\n",
       " '왜 극을 끌어가는 중심있는 캐릭터가 있어야 하는지 알게 된영화 살인마와 대적하는 그리고 사건을 해결하는 인물이 없고 그리고 왜 마지막에 다 탈출 해놓고 나서 잡히고 죽임을 당하는지 이해할수가 없다. 대체 조달환 정유미는 왜 나옴?',\n",
       " '진 짜 리얼 개 쓰레기 영화 . 다 보고 나면 정말 찝찝해지는 영화 절대보지마',\n",
       " '비록 로봇이지만 점차 인간의 감정을 가지고 자신에 대해 고민하면서 결국 인간이 되어 죽는 앤드류의 모습내가 봤던 영화 중에서도 최고의 감동을 선사한 영화',\n",
       " '영구와땡칠이시리즈는 레전드영화다',\n",
       " '초딩 때 친척형이 비디오로 빌려와서 봤던 기억이 난다...너무 재미 없었다 근데 나중에 우연히 다시보니 재밌더라 그 땐 왜 그렇게 재미가 없었을까?? 98년이면 내가 초등학교 2학년 때니까...사촌형이 당시 나름 최신 비디오를 빌려온거 같다',\n",
       " '지루할만큼 고요하고 서글픈 시선속에 머문 깊은 성찰과 사색.',\n",
       " '영화 진짜 보고 .. 펑펑울었습니다 , 너무슬픈거같아요 .. ㅜㅜㅜ !',\n",
       " '누가 더 혀짧은가 내기하면 박빙일것같다',\n",
       " '애 둘 딸린 심은하의 그 눈부신 미모, 아름다운 영상, 메인 주제가',\n",
       " '3기 나오겠죠 ? 아직 안풀린 이야기들이 많은데 극장판은 정말 시간가는줄도 모르고 봤네요 역시 싸패..',\n",
       " '개노잼;; 뭔가 스토리도 부족하고 다이상함 진짜;',\n",
       " '답없네, 뭐하는건지..',\n",
       " '절망과 슬픔 속에서도 자신을 챙겨야만하는 삶의 잔인함을 거부한 비참함에 대하여',\n",
       " '페이스 허거 같음ㅋㅋㅋㅋㅋ',\n",
       " '시간이 흘러도 퇴색되지 않는 맛이 있는 영화',\n",
       " '진짜 어마어마한 여운을 주는 멜로 영화에요.ㅎ',\n",
       " '소피마르소와의 말같지도 않은 불륜이 내용 다 망침. 물론 실제 역사에는 그런 똥같은 이야기는 전혀 없었음.(주인공 죽을때 공주는 10살이었음)한마디.만약 미국인과 맞서 싸우는 아메리칸 원주민의 자유 투쟁기였으면 절대 아카데미상 못 받았음.',\n",
       " '훈훈하고 따뜻한 부정을 느낄수잇엇음',\n",
       " '잼',\n",
       " '전 정말 재미있게 봤습니다',\n",
       " '어딘가에서 일어나고 일일것같은 느낌이 강하다.우베볼이 이런 영화를 만드는 이유는 누군가 실제로 따라 했으면 하고 바라는것 같은데 정장 월가 있는 애들이 보면 웃겠지...',\n",
       " '림프비즈킷의 OST만 10점. 개봉 당시 극장에서 봤는데 영화내내 오우삼 쥑이고 싶었던ㅋㅋ',\n",
       " '견자단 대박!!엽문 시리즈는 계속된다.',\n",
       " '정말 오월의 멜로는 정말로 보고보고 또봐도 계속 보고싶은 영화순위 1순위다하,,,늦은 밤이라 그런지 야릇한 느낌이 들었다',\n",
       " '흥미롭게 봤어요. 여배우들 이쁘네요. 반했음',\n",
       " '스토리, 액션, 그래픽 머 하나 건질게 없는 망작. 그냥 게임으로나 즐기셔~',\n",
       " '그냥 레전드다 레전드!!!',\n",
       " '평론가 명치를 겁나 때리고 싶다. 정말 이 영화 재미없을거라 생각했는데 재미도 있고 내 인생에 도움이 가장큰 영화입니다. 본인이 깨달고 싶으면 꼭 보세요. 인생을 바꿔줄겁니다.',\n",
       " '키아누 리브스 최고의 액션 영화!!',\n",
       " '소재가 아름다운 영화. 다소 아쉬운 부분들이 있는 이유는 이 영화는 영화스러운 극적 로맨스보단, 좀 더 사실적으로 한 남자의 마음과 시선을 말하고 싶었기 때문 아닐까.',\n",
       " '영화평론가는 아니지만, 좋았다, 한번보고마는 영화가 아닌, 울림이있는영화',\n",
       " '역시 효느!!! 역시 재밌다ㅋㅋㅋ 재탕중...',\n",
       " '4대강',\n",
       " '간첩색휘들 애쓴다 밥은 먹고 다니냐?',\n",
       " '좀 검증된 애들좀 출현시켜라이탈리아 특집 장난하냐',\n",
       " '아 정말짜증나네 절때보지말껄욕나옴',\n",
       " '슬프다 ㅠㅠ',\n",
       " '.최악의 환경속에서 이런 만화라도 만든사람들에게 경의를 보낸다.',\n",
       " 'What is this movie for?',\n",
       " '여운이 엄청~길게 남는영화.. 이이경을 사랑하게하는 영화!',\n",
       " '이딴게 한국 영화라니',\n",
       " '짜가인가 이게뭐여..뭔..',\n",
       " '굿 10자 이상 .가나다라',\n",
       " '짱이다ㅎ 혼자자식키우며살아온엄마 그의아들 힘들게살아오면서 서로예민해지고날카로워질때도잇엇지만 결국 ..가족ㅎ 아빠라는 사람도 생각보다최악이아니고..여자는, 확실히 요구하면도와준다는 그말이 왠지짠하게와닿는다ㅎ 나혼자괜히끙끙거리지말자ㅡ이런단순한생각이든다',\n",
       " 'CG도 별로고 전개도 별로고 연기도 별로고 한마디로 재미없다',\n",
       " '번지수 잃고 갈팡질팡',\n",
       " 'Yesterday when i was young',\n",
       " '너무 사랑스럽고 감동적인 영화:) 정말 좋앗어요',\n",
       " '최고의영화',\n",
       " '13년전 영활 다시보니 공효진 코평수줄이고 콧대높였네...완전 못생겼어 ㅎㅎ호 권상우는 화산고때 왼쪽 팔자 심하더니 지금 사라지고 더 잘생겨졌고 장혁은 멋지게 늙었네. ㅋㅋㅋ다시보니 웃겨',\n",
       " '말랑말랑 ...',\n",
       " '공부 열심히 합시다 공부 안하면 저런 OO인생 삽니다.',\n",
       " '그냥. 최고다.',\n",
       " '전쟁이후의 아픔을 잘 그린영화마지막 장면이 압권유대인줄 알아 더럽게 여기나 도움이 필요하니동행했던 토마스에게 더러운유태인이라고 말한장면 그러나 유대인인척한 사실 유대인가족사진을 보면서 미묘한 감정들을 사슴인형을 밟아까며 대변한다므찐영화^^',\n",
       " '오랜만에 동화다운 동화를 본 기분이다.',\n",
       " '감사합니다 정말로 감사합니다.',\n",
       " '걍 둘다 변태',\n",
       " '샤넬의 인생과 성공,이 아니라 샤넬과 그의 남자들',\n",
       " '영화가 내용이 없다',\n",
       " '십수년의 세월을 찰나의 순간처럼, 찰나의 순간을 영원한 기억으로 남기는 시간의 상대성 이론에 관하여.',\n",
       " '니노의 이중인격연기 두근거리네요♥',\n",
       " '보다가 울컥핫 영화...재미도 있고...먼가 감동적임',\n",
       " '열정만으로 돌진하고 싶게 만드는 영화.',\n",
       " '연기력에서 유혹하지 못한다',\n",
       " '난감하다. 재미도 없고, 세상을 깜짝 놀라게 하는 센세이션도 없다.',\n",
       " \"아무리 노력했어도 '차이나타운'을 대놓고 베낀 것은 용서가 안 됨.\",\n",
       " '신화 화이팅 에릭 화이팅>< 모두 힘내요 !',\n",
       " '엔딩이 넘 슬퍼요 :(',\n",
       " '영화관에 가서 보면 더 좋았을걸...어린시절로 돌아간 느낌이들어 만감이...',\n",
       " '정말 최고였어요 ㅠㅠ 이민정씨와 신하균씨 연기 너무 좋았어요!!',\n",
       " '몇 안되는 재밌게 본 영화',\n",
       " '교양시간에 보고 좀 충격먹은 영화....마지막에 너무 슬펐다 빨갱이라 소리지르던 몬초가 갑자기 다른 단어를 말한건 선생님에대한 그리움 미안함 슬픔이었을까...몬초가 마지막에 좀 울먹인거 같기도 하고...',\n",
       " '잘봤습니다',\n",
       " '안무서워!! 귀신이 애기라 그런건지,,, 그냥 깜놀하기만할뿐이야',\n",
       " '뭐하자는건쥐... 모든것이 다 어설프고...',\n",
       " '배우들의 따뜻한 연기도 일상의 힘겨움을 그리는 현실감도 다 좋았어요.',\n",
       " '남자배우들 정말 미스캐스팅. 연기력 안습... 조은숙, 김유미 연기땜에 참고 봤다',\n",
       " '1차 세계대전 中 피고 진 청춘들. 무기와 기술력은 20t세기, 전쟁을 일으킨 정치인들과 전쟁을 지휘하는 고위 장교들의 생각은 19세기.',\n",
       " '책과는 분명히 다른시선. 괜찮네요',\n",
       " '내가 이거 왜 봤지 싶은데 한예슬이랑 김태희 나와서 본 듯. 적월도 개 쌤 ㅋㅋ',\n",
       " '솔직히 6점때가 뭐냐 약간 더러운 장면만빼면 7.5정도다',\n",
       " '와 이연서님 신인답지 않은 연기력 잘 봤습니다 다음 작품에서 또 뵙길 바랍니다',\n",
       " '반전이 전부가 아닌영화..몇 번을 봐도 또 보고 싶은 영화',\n",
       " '피해자만 있고,피의자는 없는 ..',\n",
       " '개답답 먼주인공이 지혼자 복수도 못함?주변에서 해주길바라는 민폐녀?아직도 끌려다니고ㅡㅡ',\n",
       " '신선한 소재. 화끈한 액션. 스피디한 전개',\n",
       " '이 영화의 3박자는 디테일이었다. (정말 시가전의 퀄리티는 완벽했고) 남자의 사랑에 대한 묘사... (작중에 한석규는 누군가를 사랑하는 마음은 정말 디테일이 대단했다.) 마지막 얘기의 완급조절이 완벽했다. 이 영화가 정말 멋졌다.',\n",
       " '탕웨이찡 그녀 만으로도 10점주기에 충분하다!!',\n",
       " '감동적인 영화다',\n",
       " '당시 대박쳤던 영화..괜찮다!!',\n",
       " '억지스러운 시나리오..지루한 전개.. 1편 보다 못한 구성등.. 2편은 안나오는게 나았다..망작..배우들이 영화보는 눈이 없어서 안타깝다.',\n",
       " 'ㅋㅋㅋㅋㅋㅋㅋㅋ 반도 안되는 영화',\n",
       " '이 영화가 평점이 높은 이유를 모르겠어..ㅡ.ㅡ::',\n",
       " '평생 기억할만한 영화,정상적인 소재는 아니지만',\n",
       " '요즘 상황 보고 이 영화가 생각났다.',\n",
       " '많을 것을 생각하게 만드는 영화입니다.마지막에 사람들이 짐승으로 보이고 아수라가 사람같아 보였습니다.',\n",
       " '진짜 재미 없는 영화 공통점....스포츠영화,군대영화,자막 나오는 영화',\n",
       " '로버트 드니로의 광기의 복수 연기를 만끽할수 있는 수작 서스펜스 스릴러물',\n",
       " '감동감동감동의 도가니탕',\n",
       " '세계 어디서나 정치 경제 문화 사회 전반에 걸쳐 변화가 절실한 상황이지만 변화를 가져올 방법이 없다는게 함정인 것 같다...',\n",
       " '귀여운벤지.. 똑똑한 벤지 예쁘고 귀여운 친구... 압삘럽 ㅎ',\n",
       " '당시 개봉날 보고 울면서 나왔다. 돈아까워서..ㅋㅋ',\n",
       " '정말 최고의 영화...',\n",
       " '잔잔하게 숨막히는 영화 . 연출이 대단하다. 곳곳에 숨어있는 복선. 치밀하다 싶을정도로 섬세한 감정표현. 거기에 김영애의 연기까지',\n",
       " 'once upon a dream',\n",
       " '시나리오 연출 연기 어느것 하나 갖추지 못한 시간이 넘 아까운 억지 싸구려 중국 신파 경극...',\n",
       " '거부하는 몸짓으로 저 하늘을 ~ ^^',\n",
       " '그만빙빙돌리고 밝혀지게하면안되나요 ?보려다아직도질질끌어짜증나.안봄 여기서또사고터져 또질질끌면진짜짜증날듯 ?빨리빨리밝혀질건밝혀지면서반전이있든지 ?작가님 이드라마사랑하고잼있는데 넘끌어짜증나요',\n",
       " '졸면서 봤다 왜이리 평정이 높은겨 내용도 별거 없고 아오 감수성 영화냐 이거',\n",
       " '기대하지 않았던 영화의 아름다움이 밀려온다. 꽤 괜찮다았던 영화.',\n",
       " '진짜 한번만더 이런영화 상영하면 용서하지 않는다지금 영화보면서 카톡하고잇음 아놔 진짜',\n",
       " '살아는 있지만 생동감을 잃은 박물관',\n",
       " '노땅들의 한심한 추억미화',\n",
       " '어릴적에 눈물흘리며 웃던기억에 간신히 찾아 다시 봤네요 ^^',\n",
       " '인종차별과 유괴라는 두주제의 불협화음',\n",
       " '고명환이 연기가 쩌냐? 아니면 돈이 없어 쓴거냐..후자라면 볼가치가 없는영화',\n",
       " '속편에서는주인공이전작처럼앨빈의밴드였으면좋았을것같다.캐릭터추가로더이상해진듯',\n",
       " '혼자 보긴 너무 아깝다. 2004년 올해의 영화.',\n",
       " '마지막 결투씬 최고! ㅋㅋ 폭풍눈물에~ 팝핀현준 할아버지 ㅋㅋㅋ',\n",
       " 'ㄵ 5점대asfgsdlgkbjsjvb',\n",
       " '좋아 상술최고..아니 선거술 최고...',\n",
       " '쓰레기 함부로 버리지 맙시다.',\n",
       " '글쎄 나와는 안 맞는 성향의 영화 중 하나. OST는 들을 만함',\n",
       " '즐~~~~~',\n",
       " '막장도 재미가있어야 보지..재미도 없고 짜증만 남남녀주인공이 어울리면 참고보겠는데 진짜 안어울리고웬만하면 다 재밌게 보는데 진짜 내가본것중 제일 최악이였음!!무튼 주인공들부터시작해서 성격 개 이상함!!조기종영이 답이다...',\n",
       " '줄리델피는 나이가 들수록 멋지다!',\n",
       " '내가 본 일드 중 쵝오~!!!!!>0<',\n",
       " '역시 명작은 명작이다...',\n",
       " '글쎄요.... 뭐랄까... 영화 제목을 잘못 보고 착각한 내 잘못이랄까...',\n",
       " '그냥 기독교영화네요. 좀 더 깊이있는 내용을 기대했는데.. 실망입니다. 영화도 뭔가 엉성해요;;',\n",
       " '그냥 책으로 읽는게 더 절절하게 다가온다. 영화는 내용을 너무 비약하고 삭제해서 행간을 잃어버렸다. 책에서 꽉 찼었던 느낌과 반대로 모든 것이 엉성하다.',\n",
       " '너무나 감동적인 영화',\n",
       " '스킨헤드성님들이 이 영화를 싫어합니다.',\n",
       " '자동차 매니아인 나의 평점은 5점 이하~속았다...아오~',\n",
       " '나 이거 보고 인형 절대안삼',\n",
       " '정체성은 사치인가?',\n",
       " '나이먹은아저씨들이 일찐놀이하는영화 개역겹다. 알바풀었냐 현실감 개진짜 개제로',\n",
       " '남극은 왔는데 그만 길을 잃었다. 오르지 못할 곳은 오르는 것이 아니다.',\n",
       " '재밌음 귀엽고 신남',\n",
       " '포스터는 진심 개쩐다~ 엑소시스트를 능가하는 공포물 같지만 실상은 처키보다 못한영화',\n",
       " '시청률 44%는 개뿔;; 존11나 재미없어;; 이제보니 MBC가 사극너무못만드네;;',\n",
       " '요즘 재방보는데 넘 재밌는데...왜 시청률은 저조했을까 싶네요...둘다 귀요미',\n",
       " '연출 연기 영상이 아름다운 영화입니다. 저예산영화인 관계로 스펙타클은 부족하지만 한국영화계에 새로운 바람, 희망, 다크호스가 될것임을 믿습니다. 많은 응원부탁드리고 벌써부터 일찍 관람해주신분들 진심으로 감사합니다. New hope',\n",
       " '평점이왜이렇게낮지?난 이거 또다운받고있다.3번째...정말잼있던데...끝에 견자단하고 대빵하고싸울땐 정말 가슴이뜨거워졌다.난정말로 잼있게봤다...최근댓글이니 내가 알바아닌줄은 알거다.',\n",
       " '이게 어떻게 평점이 낮을수가 있지?',\n",
       " '블랙코미디 조롱 대상이 우린데 기분 드러워서 점수 주겠냐? 성기 노출 등으로 어그로나 끌고서는 ㅉㅉ',\n",
       " '촌동네 조폭삼류영화. 가끔씩 툭툭들이미는 유머도 영쌩뚱맞구 촌스럽기까지하다.',\n",
       " '10점 만들기',\n",
       " '스타뎀 형님의 얼굴에 먹칠을 한영화..',\n",
       " '헐...남자몸매보면 기분 좋나?',\n",
       " '안봐도 별점 한개 주고싶은 10류 영화 같다... ㅋㅋ심형래 아저씨와 동급감독인듯 ㅋㅋㅋ',\n",
       " '정말 완벽했다.최고의 영화중에 꼽히는 영화.',\n",
       " '조잡하고 유치한 저예산 3류 B급 영화다.. 스토리에 깊이감도 없고 전체적으로 루즈하다.',\n",
       " '진짜..뭐냐 민국이나 지아는 더빙 더이상시키면안되겠네 더빙이 얼마나중요한데 이런애들을시켜데뷔도안한애들을 연예인이해도 뭐라고하는판에',\n",
       " '그냥 재미가 없어요....ㅠㅠ',\n",
       " '쇼를해라 쇼',\n",
       " '중심이 약하니 언저리 가지고 무리한 승부수를 띄운다',\n",
       " '주연배우들의 이름만 기억에 남.',\n",
       " '그냥 안보는게 이득 ...',\n",
       " '키기키기키기키기키기',\n",
       " '박얘쁜 빠수니 죄다 OO 없어져버려',\n",
       " '진짜 짜증나는 영화..',\n",
       " '불은 잘 보이지도 않고 사람 죽어나갈 때는 엄청난 웅장한 음악만 나오고 전혀 마음에 와 닿지 않는 설정들',\n",
       " '망작',\n",
       " '상당히 재밌게 봤습니다',\n",
       " '내코끼리내놔가 더재밌음ㅋ',\n",
       " '코믹은 코믹으로 봐라 패러디하고 카메오들보는 재미도 있다',\n",
       " '유치짬뽕이네!!. 딱 초등3학년 영화다. 초등학교 자녀 있는 가족분께 추천함!!',\n",
       " '후속 지금이라도 나와라 한국애니 좀 살려보자',\n",
       " 'EBS를 통해 봤는데.. 정말 재밌게 잘 봤어요. 요 근래 본 영화 중 최고인듯!',\n",
       " '기대않고 봤는데, 찰지게 만든 토종느와르네~! 흥미진진하다..',\n",
       " '성인영화를 가족영화로 만드려하는 멍청한 자막제작자가 마음에 안들어서 1점',\n",
       " '일본인 특유의 어색한 연기 여주인공 연기 너무 못해',\n",
       " '전반적으로 무거운 느낌의 영화네요.가비의향과맛처럼,씁쓸함이 느껴집니다.장윤현감독님께서,커피부분에관해 신경을 쓰시다보니,연출부분에있어서,좀 미흡하지않았나싶고, 배우들연기력은 괜찮았습니다.',\n",
       " '전작보다 100 재밌다. 배우, 내용 모두 세련됨',\n",
       " '진지하고 무거운 소재를 경쾌하고 재미있게 만들었다',\n",
       " '유럽작품상 탈만한 유럽에 중요한 얘기..또한 픽션',\n",
       " '풍정정은 어케된거지ㅋㅋㅋ과도한 압축으로 개연성없지만...배우들이 호화로워서...',\n",
       " '이영화 구성좋다는분들 ㅋㅋ아마 친구랑 같이영화보고 님들이 영화 좋다고 재밌다하면 같이본 친구들은 이해하지 못할겁니다 ㅋㅋ진짜 최악 최저 스토리 주인공 행동 개연성없음캐릭간의 이해관계 최악 ㅋㅋㅋCIA갘ㅋㅋ이렇게 허접하게 표현된 영화 간만이라능ㅋ',\n",
       " '이젠 그만 보고 싶은, 막돼먹은 스토리텔링.',\n",
       " '말이 필요 없다.로맨스 싫어하는 내가 봤을때 기절할 것 같았어 ㅜㅜㅜㅜ',\n",
       " '제 취향적 이고 우울한 마음을 완전히 날려버리고 슬픈내용을 본뒤 마음을 정화시켜주네요.',\n",
       " '영상미가 역시 최고네요',\n",
       " '끙.....',\n",
       " '역시 한국영화는 보지말아야돼',\n",
       " '괜찮은 영화...',\n",
       " '요즘 재밌음!',\n",
       " '소재는 참 좋아서 삼점준다. 제작된 영화는 공포도, 스릴러도 아닌 본분을 잊은 드라마아닌 드라마같은 느낌이다. 연기, 연출은 괜찮았다. 다만 시작부터 끝까지 지루할 뿐이다. 또 어떤 장면들은 살짝 유치했다.',\n",
       " '남자인데 보는내내 울었다 딸 낳으면 잘해줘야지...',\n",
       " '안타까울뿐. 안타까울뿐.',\n",
       " '영웅은 사람들이 원하기 때문에 만들어지는 또다른 희생자다..',\n",
       " '그냥 평작. 욕까진안나오고..',\n",
       " '극장가서 안본 내머리를 깨버리고싶네요. 제인생 최고의 영홥니다. 키이라작품 중에서도 최고일듯. 알럽키이라♡♡',\n",
       " '중고생들의 마마추어 포르노',\n",
       " '비디오 물이냐 동시상영물이냐 ~ 넌 정체가 모냐',\n",
       " '이건 말로 설명할 수 없는 유치함이다. 진짜 필름이 아깝다',\n",
       " '이승연의 강렬함이 묻어나는 영화. 그러나 홍경인은 너무 불쌍하게 나옴',\n",
       " \"'드릴브라' 에서 뿜었다\",\n",
       " '2% 부족한 영화가아닌 98%부족한 영화감동이 있다길래 참고 끝까지 다봤는데...;;진심으로 이렇게 재미없다고 느끼는건 처음;;',\n",
       " '계몽영화의 한계를 고스란이 답습한다',\n",
       " '우와 정말 오랜만에 통쾌하게 웃었네요 ㅎㅎ 내일이 기대됩니다',\n",
       " '청춘에는 마침표가 없다.',\n",
       " '세얼간이 아줌마 나와서 한번 본건데 실망...신선한 반전을 주고싶었나 본데 개연성도 없구 뭐이런...',\n",
       " '좋은 소재에 만족할 연출.',\n",
       " '심혜진이 나와서 겨우 저정도라니 실망이다',\n",
       " '아들놈은 끝까지 아빠한테 미안한 감정 없어..ㅠ 소재가 신선했는데 영화 자체는 메시지도 모호하고 스토리가 짜임새 있지 않은 것 같다.',\n",
       " '창업을 꿈꾸는가! 좋은 아이템이 있어 사업을 하려하는가!! 그렇다면 기를 쓰고 이 영활 보기바란다!! 그 멀고 험한 여정에 스승이 될것이요 지침서가 될것이다... 혹은 단념에 도움이 될지도... 참 오랜만에 박장대소하며 본 독립영활세~~~ ★',\n",
       " '슬픈액션영화치고는실망이크다부자간의배신과원망으로끝나는것이너무허무하다',\n",
       " 'EBS 명화에서 이거보고 움 진짜감동적',\n",
       " '낰였다 티 프리미엄ㅡㅡ 인간적인 면이 쫌 맘에 들어서 2점줬다 근데 진짜 이선균 정재영 김상중 연기파배우들 불러노코 이딴 쓰레기 영화 찍냐ㅡㅡ 진짜 영화보는데 계쇠 지루하고 괴로웠다ㅡㅡ',\n",
       " '너무나 따뜻하고 감동적인 영화',\n",
       " 'C급영화도 안되는...일점도 아깝다... 네이버는 마이너스 점수도 만들어 달라',\n",
       " '스토리의 부진은 액션의 재미까지 반감시킨다',\n",
       " '누구나 ㅡ낄수ㅣㅆ느덕을 영화화함...굿,,',\n",
       " '시종일관 오락가락 말하고자하는게 뭔지 모르겠다 감독자기만의 세계에 빠져 만든것같은 영화..',\n",
       " '왠지모를 색다른 감동을 주는영화이다....',\n",
       " '전주영화제에서봤었는데넘늦게개봉한듯... 종교와업에대해한번더생각할수있게만든영화. 저예산으로만들었으나감독의노력이느껴져큰박수를보내고싶다. 화이팅!',\n",
       " '보는내내 웃었습니다 재밌네요',\n",
       " '1',\n",
       " '사랑에 상처받으면 다시 치유될수 있을까? 하는 생각이 드는 영화!',\n",
       " '극장가서 본영화중 쓰디쓴아픔을 처음으로 느끼게해준 퍼스트',\n",
       " '최고! 더 무슨평가가 필요한가 ~~탑!',\n",
       " '자신의삶에대해 다시한번 생각하게하는영화...',\n",
       " '알바놈들 양심도 없냐...멀보고 십점주는거냐',\n",
       " '90년도로 돌아가게 해준다는 ㅡㅡ',\n",
       " '끼워 맞추기 개쩔던데, 반전 하나 보고 와 하는 인간들 이해 불가',\n",
       " '우웩. 개랑 무슨짓을 했길래. 후세가 태어나. 일본놈들 진짜 정신상태 이상하네.',\n",
       " '4',\n",
       " '이 영활 보고나면 흐뭇해진다.. 영화는 한국이 더 잘만든다는 걸 느끼게 되니까..',\n",
       " '지들이 뭔데 대우를 까냐?',\n",
       " '재밌고 짠하고 그게 매력입니다',\n",
       " '와 ㅠㅠ 내머릿속지우개 이후에 진짜 슬픈영화였어요 ㅠㅠ 마지막에 눈물폭발 ㅜㅜ 오늘이후에도 또보고싶네요',\n",
       " '월요커플 짱짱!! 덕분에 아주 재미있게 보고 있습니당!!',\n",
       " '007 터키특집..액션은 스키추격이 기억에 남고. 소피의,소피에 의한,소피를 위한 시리즈..로저무어 시절보다 재미는 조금 떨어진다',\n",
       " '수많은 최루성 멜로는 여기에서...',\n",
       " '내평생 최고의 걸작. 현실 건너편 세계를 잠시 엿본듯한 느낌.',\n",
       " '내 인생 최고의 영화',\n",
       " '진짜 추천해요 ^^',\n",
       " '포스터가 사기. 너무 현실적이어서 배우들은 심각한데 빵빵 터지는 화성남 금성녀. 아 슈발 지는 혼자 내리면서 본전생각에 담배 피는 남편.',\n",
       " '머가마술이라는거야?나죽기전에외계인만나볼수나있을지?',\n",
       " '참 재밌는 영화 ㅎㅎ',\n",
       " '빨리좀 끝나라...으이그 처음엔재밌는줄알았는데이게뭐야!이리재미없다.',\n",
       " '극에 전혀 몰입안되는 장면 이어붙이기식 단순 진행,연출력이 형편없음.',\n",
       " '자막제작자가 써놨듯이 막장임.',\n",
       " '그리 무서운 수도승이 물에 쉽게 떠내려가네',\n",
       " '이게왜 주온보다 평점이높은지 이해가안간다 이영화 맨처음 여배우가 물대포쏠때부터 웃겻다 포스터가 더무섭다 영화상영시간내내 포스터만보여줘도 충분히지린다',\n",
       " '진짜 신기하다...라는 말밖에 안나와',\n",
       " '좋은 배우들을 데리고....;; 작품의 부족함.',\n",
       " '아니 왜 5점대라니, 근래에 본 다크 히어로무비 중에서 최고였어요. 아주 그냥 고스트라이더에게 걸리면 스치면 사망인거에요.',\n",
       " '묵직하게 시작해서 우습게 끝남',\n",
       " '내용 전개가엉성하고지루할정도로 재미가없슴',\n",
       " '돈뭉치로 싸대기;; 명장면이다ㅋㅋ',\n",
       " '2.2고고하자 ㅋㅋㅋ',\n",
       " '쓰레기영화',\n",
       " '너무일찍슬픔을알게된제제가안쓰럽다..책으로읽고도눈물이났는데..영화도마찬가지다.어린나이의제제는슬픔을너무일찍알아버렸다',\n",
       " '정말 비디오마저 돈주고 보고 아깝다..최악...',\n",
       " '말그대로 뚝방에서 볼영화',\n",
       " '내 인생 최고의 영화. 10년이 다되가는데, 아직도 아련하고 애틋한 기억.',\n",
       " '감독ㅡㅡ다신영화찍지마라',\n",
       " '육감적인 섹시한 여인들의 존재 자체가 이 영화의 전부',\n",
       " '영화 첫 도입부 부터 카메라 각도라든지 화질이라든지 겁나 구림.. 영화 아닌줄 알았음',\n",
       " '진정 좋은 영화란 볼때당시 잼있다... 도 있지만.. 두고두고 기억나고생각나고 또 한번쯤 보고싶은 이런영화가 아닐런지요 ㅋㅋ',\n",
       " '박사아들 정시현 정말 멋져요',\n",
       " '1편이 너무좋아서 2편이 너무묻힌다',\n",
       " '할 말이 없다',\n",
       " '난 별로던데 -_ -',\n",
       " '이런 영화가 참 좋다.',\n",
       " '곳곳에 번뜩이는 아이디어. 아기자기한 구성이 돋보이는 수작.',\n",
       " '우아....새벽에보니까 무섭네 ㅠ_ㅠ 미스터리와에로스와 스릴러를 겸비한 영화!',\n",
       " '짧지만 정말 재밌게 잘봤어요~. 윤계상 능청연기 좋구 잘됬으면 하는 생각을 계속 했네요~ ㅋㅋ',\n",
       " '에린이 초반에 타던차 현대자동차 프레스토 네요. 보면서 추억이세록세록',\n",
       " '남들이 철학적인 영화라고도 하지만 단순 액션용으로 봐도 이 정도 점수는 나와야된다',\n",
       " '4.444.444.444.444.44',\n",
       " '효과음이 기가막혔던 영화',\n",
       " '솔직히 평점 8점 이상은 되야되는거같다.',\n",
       " '난강혜정이 일본가서 찍은건가 했네ㅋㅋ닮은것같다는 생각이 들었을 뿐이고...',\n",
       " '일본영화 좋아한다면 꼭 봐야할 영화!',\n",
       " '진짜 이건 아님ㅋㅋㅋㅋㅋ액션영화좋아해서 액션영화만 다운받아서 꾸준히 본게 벌써 몇년인 사람임 근데 이건 진짴ㅋㅋㅋㅋㅋㅋ아무리 점수 잘 줘도 100점 만점에 10점?ㅡㅡ돈주고봤는데너무아깝다진짜ㅜㅜ그리고대체 왜 13구역 타이틀을 달고나왔는지 모르겠음 실망',\n",
       " '가슴이 먹먹하다, 뷰욕을 왜 이제서야 알게됐을까',\n",
       " '커스틴 때문에 좋겠다',\n",
       " '보는내내 찝찝하고 영화가 끝나고 나서도 불쾌했다.. 중년의 남성이 이렇게까지 추잡해보일 수가 있을까..',\n",
       " '진짜 퀵이유로 이렇게 어이없고 재미없는영화는 처음입니다 진짜 돈아까운적은 두번째라',\n",
       " '진짜재미없다..영화관에삼십분정도늦게들어갔는데사람이한명도없고..그이유를왠지알것같네..^^완전비추요',\n",
       " '2012년에 본영화인대 솜이랑 키작은남자 살아서 나감',\n",
       " 'ㅋㅋ 조금은 유치했지만 왕조현 주윤발 이것만으로도 충분히 볼만했다.',\n",
       " '난 솔직히 재미없었어. 코믹요소가 없어서',\n",
       " '싸구려 왜색 영화, 키작고 교활한 일본원숭이들의 망상, 사무라이 정신..토나온다...',\n",
       " '재미있게봄 감동적이고',\n",
       " '아니 찍어놓고 모니터링 한번 안하나 어떻게 염치 업이 이런걸 극장에 걸수가 있지?',\n",
       " \"영화'산업'이라고 하잖는가? 이딴식으로 홍보 해놓고 속여서 팔았다는 게 소비자 입장에서는 짜증난다. 그나마 다행은 아주 싸구려를 상급품으로 속여판 게 아니라는 점. 그래서 1점. 차라리 연상호 감독 작품 처럼 홍보가 됐다면, 그 비슷하게 만이라도 하지\",\n",
       " '완전 감동이다 ㅠㅠ 박신혜 짱이뻐요 ㅎㅎ',\n",
       " '절망속에서 결국 빠져나온 눈물겨운 실화',\n",
       " '국민학교 다닐때 이거 동생이랑 보다가.... 눈물이...ㅋ',\n",
       " '욕망이라는 이름의 전차.',\n",
       " \"'디 워'랑 같은 부류.. 저예산 + 저렴한 CG + 마구잡이연출\",\n",
       " '무기여 잘있거라는 보는 내내 손에 땀을 쥐고본 첫번째 애니',\n",
       " '배우들 연기력이 아깝다. 별 한 개도 아깝다.',\n",
       " '딱 90년대코미디영화',\n",
       " '어릴때 진짜 재미있게 봤음ㅋㅋㅋㅋ',\n",
       " '정말최고의영화고 마지막 아이들의 노래와 비행기가 정말 잊을수 없는 여운을 남긴다.이런 영화를 이제알게된것자체가 후회될정도로 잔잔하고 깊은 여운이 남는 영화.',\n",
       " '보면서 어이없어서 헛웃음만 나던....',\n",
       " '악역인 금단비가 더 주목받았다는것은 주연여배우들의 미스캐스팅을 의미한다',\n",
       " 'General',\n",
       " '보고 나서도 내내 여운이 남는 영화..',\n",
       " '절대로 보지마라 보면 후회한다!!이걸영화라고 만든거냐!볼사람은 뇌를 놓고보아라!',\n",
       " '무슨 내용인지 도통 모르겠다... 쓸데없이 특별해 보이려는 시도에만 열중이었던 영화.',\n",
       " '기쁨, 슬픔, 생명 그리고 죽음. 인간의 역사속에 거대한 하나님의 우주적 섭리가 느껴지는 영화. 특별히 어머니의 역을 맡은 여배우의 여성미와 자애로움이 인상적이다. 인생을 살면서 그런 존재가 된다면. 영상미 예술이다!',\n",
       " '이게뭔가요내용도없고',\n",
       " '평점 어마어마하게 높네;;;; 빨리 낮춰야 할듯 5점이 적당한 영화.',\n",
       " '이야기도보통재미있고. 10점정도는아니라고봐요.5점6점정도인데 고릴라제작한거도 잘했긴했고.하지만 감동은 보통..아쉬운결말',\n",
       " '솔직히 웬만한 공포영화는 다 섭렵할만큼 매니아인데. 주온은 정말 무서웠었다. 아직까지도 샤워하면서 머리감을때 공포를 느낀다. 누가 나를 쳐다보고 있는 느낌이라서... 이 느낌 나말고도 겪어본사람 있을거야. 그만큼 당시에 대단했던 영화다.',\n",
       " '아름다운 영화였어요',\n",
       " '정말 광해와 비슷한가?',\n",
       " '조쉬 하트넷 특유의 여성들을 자극하는 나약한듯하면서도 남성적인 이미지를 작 부각한듯',\n",
       " '정말 속은느낌이다',\n",
       " '몸매,베드신 보기좋다고 한사람은 영화 안본사람',\n",
       " \"잘봤어요 외모뿐만이 아니라 여러가지들을 따지며 사랑에 빠지는것이 아니라 '하려고' 하는 요즘 사람들에게 좋은 영화인거 같아요....\",\n",
       " '최악의 쓰레기. 어설프려고 정말 노력했다',\n",
       " '콜린파렐. 123412341234',\n",
       " '난이게 제일 재밌었는데..',\n",
       " '난 좋았는데요..... 괜찮았어요',\n",
       " '영화보다 댓글이 더 재밌어',\n",
       " '에라이 미친 사이코 드라마야!!!',\n",
       " '모든 일본문화가 들어가 있다고 할 수 있을까? 최고의 사극!!',\n",
       " '엄청나게 기대를 하고 본게 아니라 괜찮았던듯?',\n",
       " '더빙이 똥이야 ....',\n",
       " '안타깝네. 이해를 못하는사람들 속출. 불교적이고 철학적인 작품.',\n",
       " '진짜 이런 개 씨,1바ㄹ OOO 같은 영화 개 시간낭비 의미도없고 무섭지도않고 내가 왠만하면 공포영화는 즐겨보는데 이건 진짜 OOOO같다',\n",
       " '색다르고 재밌는 영화였음. 실제로도 이런 일이 있다면 참 재밌을 것 같음. 막장 of 막장.',\n",
       " '어캐봐여? 꼬옥~~~~~~~보고싶내여~~~~~~~~~~~~~~~~~~~~',\n",
       " '정말 식상하다못해 촌스럽기까지 ~~~~~~~~~~',\n",
       " '종교적 분위기 물씬 풍기는 최루성 가족영화',\n",
       " '재밌다',\n",
       " '그냥 살지 그랬어.. 이성재만 멋짐',\n",
       " '음악영화라 나에겐 취향저격이지만... 비긴어게인처럼 대중적으로 흥행하긴 힘들 영화네요.. 하지만 여주가 너무 매력적이에요 ㅎㅎ',\n",
       " '별 0개 선택 왜없어요? 솔직히 별 반개도 아깝다',\n",
       " '돈에 미친 남편과 .. 아기에 미친 돈 있는 남자 그속에서 갈등 하는 여자 18',\n",
       " '어린이의 시점에서만 볼만하겠지. 오로지 어린이의 시점.',\n",
       " '잠을 청할 수 있었다.',\n",
       " '좋아하는 사람의 뇌가 아니던가?.. 완전 난해함.. 결말 왕실망임',\n",
       " '전작에 비해서 왠지 허탈하다. 카이사르도 전작이 더 멋있는 듯 하고...',\n",
       " '김민종 최고! 더 잘되시요',\n",
       " '공격적인 재미, 유순한 여성성, 일기토, 지략 삼국지의 그것과 맞짱!',\n",
       " '-점수를 주고 싶다. 2003년에 이정도 밖에 못만들었다는게 충격...',\n",
       " '비디오테잎으로 좍좍 감아가며 봤던 영화. 가장 슬펐던 영화',\n",
       " '도입부를 제외하고는 따분.헬기에서 민간인을 마구 쏴 죽이는 미군, 베트공 여성 스나이퍼 등,현실감 없는 극단적인 설정.라이언 일병에서의 업햄 그리고 이 영화 주인공인 조커, 두 넘 모두 내가 싫어하는 캐릭터, 착한척 하면서 주위에 피해를 주는 넘들.',\n",
       " '재밌는데...나만 그런가? 참고로 우리나라 까거나 하는건 하나도 안나옴 그냥 지들끼리 소설쓰고 지들끼리 자위하고 자위대도 등장하는데 그사람들도 자위나 하고 있음 일본 감정 다 떠나서 과학도로써 과학적으로 볼만한 영화였음 신선함',\n",
       " '제 취향은 아니네요~~~~',\n",
       " '평점 조절...',\n",
       " '1점도 아까운 쓰레기영화 전작이 아까움',\n",
       " '일편에 비해 삽질하는 브리짓이 쪼~끔 짜증날 때도 있었지만 그래도 여전히 사랑스럽다ㅎ 콜린 퍼스와 휴 그랜트를 한자리에 모아놓은 것 만으로도 10점줘야함!',\n",
       " '지금까지본 아이리스 시리즈중 최악이다ㅠㅠ 이거해도 너무하는거아닌가...수치스럽다. 연기고자시고 다 떠나 너무도허접합....',\n",
       " '연기력때문에 할말이 없다. 정우성과 고소영이 왜그토록 흥행작이 없는지 알고싶으면, 비트에서 연기하는거 봐라.',\n",
       " '전라도 노예 업주 처벌 안받았나요?? 이슈가안됐네요 그러고보니..',\n",
       " '배우가 아깝다 ,,',\n",
       " '볼만 한데',\n",
       " '결말의 의미공자가 자연에 숨어사는 노자에게 말했지. 짐승도 끼리끼리 사는데 사람이라고 따로 사냐고 진정 순수함은 더러운것사이에서도 그 빛을 유지하는것 ·',\n",
       " '크리스 터커 짱이삼! ㅋㅋ',\n",
       " '믿고보는 덴젤와싱턴. 근데 모레쯔는 왜이렇게 후덕하지...',\n",
       " '나오코 진짜 집중안된다',\n",
       " '감독이 밥은 먹고 다니는지 궁금하다. 배틀로얄2 이후로 최고 쓰래기.',\n",
       " '아 재미 너무 없네요.. 시간 아까워요',\n",
       " '난 잼있던데..ㅎㅎ',\n",
       " '어떻게 상류층의 속물근성을 정당화시키면서미화시킨지 모르겠다. 감독이 국회의원이나 사회적 강자한테 아부하고 싶은 가봐요 그리고 얼굴만 예쁘다고 왕되는것은 맞지만 드라마라도 도덕적으로 표현좀 해야되는게 아닌가요 감독님 정신차리세요',\n",
       " '가만히 보고만 있어도 씨익 웃음나는 행복한 가족의 이야기',\n",
       " '사고 후 잠시 정상인이 되었던 일탈',\n",
       " '좋은 영화~',\n",
       " '이거예전에나온거같은데 재미네',\n",
       " '샬라샬라 나오다즁자쥬아',\n",
       " '......감독의 옹졸함과 치졸함이 묻어나는 영화',\n",
       " '팔빠다 ㅋㅋ',\n",
       " '재미없음 -_-',\n",
       " '무슨 생각으로 만든걸까.',\n",
       " '스토리도 흥미롭고 배우들의 연기도 인상적이다. 충분히 볼만하다!!!',\n",
       " '내 인생 최고의 미드!!',\n",
       " \"이 영화를 보고 '사랑하고 싶다' 라는 생각을 했습니다. 청소년 관람불가임에도 선정적인 장면은 나오지 않았습니다. 연인 혹은 솔로이신 분들에게 추천합니다.\",\n",
       " '일본공포영화는 링 주온 이후로 망했음',\n",
       " '지루하다.. 지루해..',\n",
       " '625를 직접 겪은 어르신들 얘길 들어보면 그당시 잔인한 학살은 대부분 주민들 서로간에 (주로 하층민들의 복수심에서 비롯된) 또는 군/경이 빨치산 학살한다며 벌인 살인이었지 정작 북한군은 민간인들한테는 잘해줬다고 하던데?',\n",
       " '그냥 다큐일뿐 ..',\n",
       " '10점짜리 영화는아닌데 개인적으로는 평균평점 7점정도의 가치는 한다고 본다 스타일리쉬한 영화 ㅋ',\n",
       " '정말 질질끌고 작가님제발좀 적당히하시죠은희수역맡은 사람도 그만 나쁘게 만들지아침드라마가 막장이네',\n",
       " '으이구 괴물 그래픽이나 좀 다듬지 그게 머니 다 티나게 공포영화보다 웃은 건 첨이다',\n",
       " '대표적인 쓰레기 김치드라마',\n",
       " '네이버 별점, 꽤 신뢰도가 높네요.5점 이하는 안보는게 좋을듯..',\n",
       " '남주 헤어스타일 왜 저래...? 가게분신노찌쯔!!!!',\n",
       " '이런영화는 두번봐야지 안다 작은 일에도 크게 화를만드는 저나라의 국민이 인상깊다',\n",
       " '김명민이 약 구해서 차 탔을 때 진짜 설마설마 했음',\n",
       " '보지말아라 재미있든 재미없든 진짜 찝찝하고 기분 드러운 영화공포영화 싸이코 영화...',\n",
       " '짝퉁쓰래기',\n",
       " '이거 시청률이 너무낮은대 명작이고만',\n",
       " '현실감 제로지만 배우들이 너무 좋았어요. 특히 다니엘헤니를 많이 볼 수 있어 좋았어요. 같은 남자지만 게이는 아닙니당. 다니엘헤니 최고. 설경구 씨두 최고!',\n",
       " '프레디가 나에게 모욕감을 줬다 그래도 프레디라서4점준다',\n",
       " '잼없네요넘',\n",
       " '평점이 너무 높군요. 원작으로 보심이 나을듯. 짧은 러닝타임에 감사하다고 해야하나. 주인공이 썰매를 타고 목적지에 가니 모든 사람들의 기억이 돌아온다는 황당한 설정이고 인간의 감정을 통제한다는건 데몰리션맨, 이퀄리브리엄에서 봤기때문에 신선함도 없음',\n",
       " '막장 드라마의 원조격인 영화... 근데 이 영화는 확실히 로즈번이 살린듯',\n",
       " '해군 출신이라 관심있게 본 영화~',\n",
       " '파란색 슬픔이 영화에..',\n",
       " '액션 완전 OOO기..차라리 유오성이 나오는 챔프를 보겠다..;;',\n",
       " '폭풍오열ㅠㅜㅠㅍ퓨ㅠ',\n",
       " '착한영화... 그리고... 재미없습니다',\n",
       " '사소한 이야기조차 눈을 뗄수 없게 만들던 거장의 솜씨. 예전 장이모우 그립다',\n",
       " '내가본영화중 베스트5안에 듬 진짜꼭보세요',\n",
       " '지금까지 본 페이크다큐영화중 제일 별로...',\n",
       " '재미도 있고 공감도되는 누구나 즐길수있는 독립영화 !!!',\n",
       " '\"\"\"시미즈레이코의 만화책\"\"\"\"비밀\"\"\"\".에서 영향받은거 아냐? 똑같애\"\"\"',\n",
       " '기존 한국 영화에서 느끼지 못한 색다른 느낌상업적이기 보다는 새로움에 도전한듯한 ..',\n",
       " '장난하나--반전같은거 있을 줄 알고 끝까지 다 봤는데 진짜 아오..시간아까워',\n",
       " '예고편을 왜 하는건지 모르겠음.. 예고편에 나오는건 하나도 안나오고.. 예고편은 대판 쌈질 하는것마냥 나오더니 하하호호 하고 끝남.. 예고편이 무슨 뜻인지를 모르는건지.. 시청자들을 호구로 보는건지..낚시질좀 그만하시고 차라리 시청률 걱정되면 폐지해',\n",
       " '난 프랑스 영화가 이래서 좋다..',\n",
       " '쓰레기쓰레기쓰레기쓰레기쓰레기쓰레기쓰레기쓰레기',\n",
       " '참 재밌게 봤는데... 귀여운 지미 +_+',\n",
       " '시간이 지나서 또 봐도 정말 가슴애린 드라마......ㅠ.ㅠ',\n",
       " '사촌동생들 때문에 같이 보긴했는데 정말.. 사촌동생들도 재미없다고 하네요',\n",
       " '설득력없는 꼴통페미니즘. 페미나치적인 마인드.',\n",
       " 'B급을 지향하는 C급 작품.',\n",
       " '음 잘 모르겠다 뭘 봐야 하는 건지 소녀 가장 이야기인가',\n",
       " '우리와 틀리다고 생각했던 장애인이 우리와 틀리지않단것을 알려주었다.10403',\n",
       " '재밌고 감각있고 쿨한 영화였는데.마지막 결말이 약간 아쉽지만',\n",
       " '그냥 재미없네 보던거니까 마저봐야지 이랬는데 갑자기 원주민생활하는건 진짜 어처구니가 없었음이건 그냥 영화가 아니다',\n",
       " '진짜 언제 90분이 지나갔는지 모를정도로 몰입해서보고 정말 너무 재미있게 봄... 너무 아련해서 영화 평 정말 처음 남겨봄.. 진짜 내가 이 나이에 애니를 보며 이 밤중에 이렇게 울줄이야.. 에몽아ㅠㅠ',\n",
       " '사과해요, 나한테!!!',\n",
       " '골목상권에 들어온 대형슈퍼마켓이 생각난다',\n",
       " '평점 조절이 필요하다 라는 생각이 든다!',\n",
       " '무협 멜로의 걸작 ... 말해 모해',\n",
       " '너무재미있게 보았는데요 다시 볼수없을까요',\n",
       " '오글거리고 유치하고 완전최악이었음...',\n",
       " '절대비추.....',\n",
       " '한국껀줄알앗는데 일본꺼엿네 ㅋㅋ',\n",
       " '꽃 한송이 놓고 갑니다ㅋㅋ',\n",
       " '내 삶의 가장 의미있는 일 중 하나라면 바로 이 영화를 봤다는 것이다. 살면서 죽기 전에 한번 꼭 봐야 할 영화.',\n",
       " '생각보다 볼만했음ㅋ여주인공이 연기가 좋네여',\n",
       " '자꾸 뭘 설득할려하고 설교할려고하는게 보기거북하다. 그리고결혼반지를 위해 범죄가담하다니 무슨 개역지설정이냐.',\n",
       " '와...',\n",
       " '제발 전문성우를 써주세요 ㅠㅠ',\n",
       " '살면서 처음 접해본 장르라서 조금 당황스럽다. 솔직히 영화 자체는 100% 자신의 색깔에 충실했고 완성도 역시 뛰어난 편이지만.. 좋아하지도 이해하지도 못하겠다ㅋ',\n",
       " '오늘 아이데리고 봤는데...아이는 좋아하데요...ㅎㅎ 미취학, 초등 어린이에게 추천~',\n",
       " '이것을 끝까지 참고 본 내가 제일 자랑스럽습니다.',\n",
       " '존내재밋습네다',\n",
       " '안봐도 되는 영화.',\n",
       " '원작 망쳤네요',\n",
       " '그냥 주는거다. 5점은 아닌 듯',\n",
       " '나쁘지 않으나 개인적으로는 지루했다는.',\n",
       " '어의없는 스토리.. 여자죽을때 웃음나옴.. 로맨스영화냐?',\n",
       " '순수함이 두근거려 좋았다 감독님은 관객들이 뭘원하는지 잘아는듯..여운이 많이 남는다',\n",
       " '기방난동사건이후 최악의 영화 .재밌다는 사람들 믿고 봤더니 다 알바생인듯 ... ㅜㅜ',\n",
       " '로맨스와 스릴러 짬뽕놔서 뭘 말하고 싶은건지.. 스토리도 허황된 느낌',\n",
       " '이건좀 아니잖아...',\n",
       " '윤아은 안됨!!원작자님 캐스팅에 참여해주세요작품 망치면 안되잖아요',\n",
       " '지금생각해도 내가본영화중에 이영화는 내생애 최고의영화였던것같다',\n",
       " '천녀유혼1,2에 비하면, 뭐라 표현하기 힘든 퀭한 영화',\n",
       " '불륜을 미화한 영화 남은사람들은 어쩌라고 또 돈걱정 따위 안하는 사람들의 이야기를 공감하라고 강요하는 영화 음악이랑 영상미로 3점',\n",
       " '최고다....... walk like a man 이란 노래는 원곡보다 영화속 노래가 훠~~얼씬 좋아요',\n",
       " '소재가 굉장히 신선했다',\n",
       " '내사랑 키아누 ♡.♡ 리브스 ♡.♡',\n",
       " '두말할 나위없이 최고의 작품.인생에 대해서 생각해보게 하는 깊이있는 영화.전 출연진과 제작진에게 큰박수를 보낸다.',\n",
       " '솔직히 산만 하기만했다',\n",
       " '말이필요없지.. 성룡영화에선.....무언가를다른것을느낄수있다',\n",
       " '화학을 해서 그런지 잼잇게 봣습니닼ㅋ 옆에 친구 중간중간 노이해.... 나중에 해석 ㅠㅠ 잼잇엇숩니다',\n",
       " '아직 준비되지 않는 젊은영화인들여 함부로 장편에 손대지 마라천천히 공부하고 나와라',\n",
       " '으엉 간만에 추억돋아서 봤는데사실 원작 자체도 두서없이 전개되는데영화감독은 내용앞뒤도없이 막 잘라서정신없음ㅇ배우들은 책읽고 특히 대사 그대로 살린거 오그리오그링ㅋㅋㅋ간만에 소설로 읽어야지',\n",
       " '개 쓰레기같은 것들아 감히 파라노말엑티비티를 팔아먹냐',\n",
       " '기억은 조작되기 마련.. 그사람이 아니고서는 함부러 말하지 말자',\n",
       " '재밌게 봤습니다,, 그저 문헌에 적힌 문란한 사도세자가 아닌, 정조의 아버지로서 그 그릇이 어느 정도였는지 잘 보여준 작품이 아니었나 싶네요 시나리오도 시나리오지만 배우들 연기가 일품이었습니다',\n",
       " '휴일낮에 침대에누워서 티비보다가 영화채널에서 틀어주길래 어쩔수 없이 봤는데 나중에는 벌떡 앉아서 봤던 영화.!완전 몰입되고 나름 스토리도 치밀하고 해리슨 포드다운 액션- 좋습니다. 저는 영화광도 영화 평론가도 아니고 영화 자주보는 일반 남자사람임',\n",
       " '절제의 미학이아니라.. 지루함의 극치가 되버린 안타갑다..',\n",
       " '영화관에서 보기엔 돈아까웠다;;;;;....... 솔직히 재미없었다 ㅜㅜ',\n",
       " '인간의 솔직함을 보여 주고 싶었는가..이런 방법말고도 다른 방법이 충분이 있을텐데?',\n",
       " '정말 사랑에 대해 다시생각한거같습니다 감동이에요',\n",
       " '내용은 교육적이나 정말지루해서요ㅜ',\n",
       " '꿀잼! 특히 소유랑 서인영ㅋㅋㅋㅋ매력터져',\n",
       " '태어나서 본 영화중에 제일 재미없었음',\n",
       " '화면을 흑백으로 바꾸기만 하면 50년대 작',\n",
       " '쇼핑몰 안에서만 찍어서 너무 재미없고 답답한..내용도 없다.',\n",
       " '진짜 쓰레기영화.. 돈아까워 죽는줄 알았다.. 여러분 보지 마세요',\n",
       " '와아오 두근두근~ 익스트림자체',\n",
       " '폭력영화, 자극적이고 실험적이라고 예술인가?',\n",
       " '일본영화랑 비슷한건 저만 느끼는건가요??수트입으면 미남으루 변하구 마지막에 평생입으라구 권유받구...창조가 이렇게까지 중복될수 있눈건지...잘 모르겠네여',\n",
       " '진짜 이렇게 재미도 없고 감동도 없는 영화는 처음이네특히나 박사고 나발이고 모든인물들이 컴퓨터 할때 손찍는데키보드 누르지도 않고 ㅋㅋㅋ컴퓨터 화면들은 똑같은 파트만 무한 반복되고허접해도 너무 허접하네... 배우들 연기도 개떡이고 ...',\n",
       " '최고의 농촌드라마.',\n",
       " \"독립영화 실력자들의 스타 리그, 옴니버스라는 피로감이 극복되는 수준이다. '얼음강'은 단독 장편으로 만들었어도 좋았을 듯. 주인공이 혹여 - 평소라면 1%도 공감 안되는 - 여호와의 증인이라도 납득이 될 정도로 감정을 설득하는 솜씨가 탁월하다.\",\n",
       " '좀비좀비 그러는데 좀비아닙니다. 우주의 아름다움에 미쳐버린 인간일뿐 충분히 가능한 일이죠',\n",
       " '개재미없음 막장스토리 어거지 ㅋㅋ',\n",
       " '뭐하나 흠잡을 것이 없다. 최고!',\n",
       " 'OST가 좋은 영화!!',\n",
       " '탁재훈나오믄재밌는데와이라지스토리중반부터너무쳐짐약해약해약해~지겨워뒈지는줄알',\n",
       " '서스펜스도 없고 스릴도 없다.',\n",
       " '우리나라 정서하고 안맞다`~',\n",
       " '어디선가 많이 본 흔한 스토리',\n",
       " '최고의 드라마....',\n",
       " '우리 모두는 누군가에게 섬머였다!',\n",
       " '힘알이 하나 없는 주인공들..맥이 다 빠진다.',\n",
       " '너무너무귀여운영화',\n",
       " '전형적인 일본식 엽기 괴짜 코메디. 그 특이함에 끌리는건 왜지',\n",
       " '와 이걸 5점 이상 준 사람들은 뭐지. 나루토 극장판 중에 가장 쓰래기',\n",
       " '정당한 노력이란 보상받게 마련이다.나름 일정 성취가 있고,좋은 결실을 거둔 작품.',\n",
       " '아씨 울었다.',\n",
       " '기적은 이미 일어났다.',\n",
       " '아이들과 함께 보기 좋았지만, 그냥 그래요.',\n",
       " '전율을 느꼈다.',\n",
       " '여기저기 지저분한내용에 이기적인 사람들의 역겨운 연애사...마지막으로 갈수록 시청률 안나오니까 막 갈겨쓴내용...',\n",
       " '별로...완전별로....마지막빼고 넘 유치하고재미없고 ..',\n",
       " '세월이 지나서 다시 보니 뭔가 먹먹함이 다르더군요. 공감하는 사람이라면 가슴속에 명작으로 남을 듯...',\n",
       " '아이들이 보기엔 좋을지도?',\n",
       " '보니까 선정성이 좀 15세 같음:::: 그래도 액션은 좋음',\n",
       " '카타르시스를 느끼기에 충분한...값진영화였다..',\n",
       " '여주 린제이 로한 닮았다. 전체적인 분위기나 배경은 좋았지만 내용은 지루했다.',\n",
       " '당신이 솔로가 아니면 이 영화를 보지마세요.',\n",
       " '남이 차안에서 전화통화 하는걸 90분 가까이 구경하고 있으라고? 폰부스는 명작이라 생각하지만 이 영화는 진짜 장난하나',\n",
       " '전형적인 저질영화',\n",
       " '답을 알려고 하지마라.',\n",
       " '재미잇음매우~~',\n",
       " '진짜 잘 만든 수작',\n",
       " '제발 2좀 찍어주세요. 현기증 난단 말이에요',\n",
       " '너무나도 따뜻한, 마음이 따뜻해지는... 한번쯤 자신을 되돌아보게 만드는 영화',\n",
       " '뭔가 조금씩 부족한 영화 놀래킬려면 확! 놀래키던지 어정쩡한 -_-;;',\n",
       " '이거 참...소재는 참 좋은데 내용전개가 개판...사람수도 많고 총도 있는데 그걸 지들끼리 서로 다 흩어져서 일방적으로 밀리네..거기다 식인종이라면서 표현을 좀비로 해놓으면 어쩌잔거야..식인으로 인해 인성이 말살되고 짐승화 되었다는 표현이라도 있던가',\n",
       " '포스터만 그럴싸하다. 13구역이라는 이름만 가져다 쓴 영화. 완전 졸작이다. 액션 신도 개허술하고, 스토리도 이상하다.',\n",
       " '대체 왜 재미없다는거지;;난 존나재밌던데',\n",
       " '늑대들의 여정이 너무 낭만적이었던 애니 스토리도 좋지만 음악은 일본 애니중에 탑으로 뛰어나다',\n",
       " '미국 흑인 민권운동사를 완벽하게 요약했다.',\n",
       " '그가 뛰어내리지 않았다면 어떻게 되었을까',\n",
       " '8점대는 나와야지. 그냥 단순한 액션공포물이 아닌데도 긴장감 공포감 연출 쩔고 음악도 좋고.. 몇년이 지나도 기억나는 인상적인 좀비물인데. 평점 너무 짜서 10줌',\n",
       " '아역 연기는 좋았으나 내용은 쓰레기',\n",
       " '진짜....재미없다 극장에서 볼거없어서 걍 스릴러라길래봤는데ㅋㅋㅋㅋㅋㅋㅋㅋㅋ웃음밖에안나온다 혹시나해서라도 절대보지마라진짜제발',\n",
       " '평점은 믿지마셈 재밌음',\n",
       " '이거 좋다는 놈들은 뭐하는 것들이야 ㅡ.ㅡ',\n",
       " '이게 21c영화냐? 90년도영화냐? 쓰래기들아',\n",
       " 'ufo를 믿으려는 자들.',\n",
       " '너무 구식으로 웃길려고 함. 보는 내내 지겨움',\n",
       " '이런거 좋아하는 사람들 정신 세계가 궁금하다..',\n",
       " '연예계의 현실을 알리고자 하는 마음은 알겠지만, 영화의 재미는 없었다. 지루해 죽을뻔 했음.',\n",
       " '아주 재미있고 책으로봐도 정말재미있다~~',\n",
       " '..........끝내주게 재밌다.',\n",
       " '유투브동영상을 돈내고 보는게 낫다는 생각이 들게한 영화',\n",
       " '아쉬운 점도 있지만, 스토리에 맞는 분위기나 배경, 지하철기관사의 삶 등을 잘 묘사',\n",
       " '스타워즈 1편과 맞아떨어지도록 잘 만든영화 최고의 에피소드 다스베이더의 탄생과 루크,레이어의 운명을 알수있는 레전드',\n",
       " '소희가 귀엽다 귀엽다 졸귀',\n",
       " '소문난 잔치(호화 캐스팅)에 먹을 건 없다',\n",
       " '주성치 영화 최고의 졸작',\n",
       " '구우우웃~~!!!!',\n",
       " '딱히 흠잡을 것도 두근거릴 것도 없는 교과서적 플레이.',\n",
       " '영화의 중심은 역시 스토리인것을. 반전의 반전 너무 재미있다.',\n",
       " '8.3이 아니라 9.3 이 아닌가?',\n",
       " '참 재미있었다. 연기를 발로 하는 삼류배우들 얼굴보면서... ㅋㅋㅋ',\n",
       " '재밌군',\n",
       " '이것도 재밌는데...ㅋㅋ',\n",
       " '1점도 아깝다 평쓰는 것도 귀찮다 보는 내내 오글거려서 손발사라지는 줄 알았다',\n",
       " '기대 안하고 봤는데... 영화 보는 내내 몰입해서 재미있게 봤어요~~',\n",
       " '유쾌함과 스릴러적인 요소가 잘 어울려진 명작. 후속작 보다 훨씬 매력있음. 두고 두고 간직해두면서 꺼내보고 싶은 영화.',\n",
       " '좋네..괜찮고.',\n",
       " '명작. 너무 좋았던 드라마. 스토리, 캐스팅, 연기, 음악, 연출 모두 완벽했던.',\n",
       " '괜찮은영화,,영화도괜찮았지만 나영언니완전머싯고예뻤음ㅠㅠ',\n",
       " '일단 재미있다 ! 고래 몇마리로 국가적으로 호들갑떠는게 오버스럽겠지만 그런 모습이 우리는 모두가 도와가며 살아야하는 지구의 생명이란 메세지는 참으로 감동적이다.',\n",
       " '지금 첨봤는데 1회만 봐볼까하고 봤다가 주말 밤새완주하였다. 여운이 많이 남는 드라마',\n",
       " '애니메이션 뮬란이 아쉽다. 전쟁씬도 그렇고 연기도 그렇고 이야기도 그렇고그저 그래',\n",
       " '기대않 하고 봣는데 진짜 내용도 좋고 재미도 있네요!!',\n",
       " '좋았다',\n",
       " '슬픈 맑음. 파문에 주목하라.',\n",
       " '김윤진 좋아하니깐...♡',\n",
       " '재밌따!!',\n",
       " '무리수가 되어버린 코미디 기획상품.',\n",
       " '나홀로집에와더불어 나의최고의영화..',\n",
       " '나는 떠올랐다 그옛날 국산애니 (아마겟돈)의 악몽이',\n",
       " '완전 역겨운 쓰레기 영화다 기술적 수준을 떠나 각본이 무개념',\n",
       " 'sunday booldy sunday........., 고결한 신사들께서 무슨 짓을 하셧을까?',\n",
       " '캬.. 개안음..ㅎㅎㅎㅎ',\n",
       " '보는내내 너무너무 재미있었음',\n",
       " '김소현 팬됬습니다....너무 재밌음',\n",
       " '삐에로와 흑인남자와싸웠을때 재미있었다 ㅋㅋㅋ아웃겨',\n",
       " '유럽영화가 이번정부에 많이 들어와 즐겁긴하다만 그 내용들이 왜 이리 진부한걸까,,,,,,,,,,,,,,,,,,,,,,,,,,,유럽영화를 욕되게 하고있단 소리다,,',\n",
       " '왠만한 허접영화도 재미있게보는데 이건 도를 넘어섰다',\n",
       " '어떤 누구도 다른 이의 삶과 죽음에 대해 왈가왈부 할 순 없다.',\n",
       " '굿굿굿 또해라또해라 제발 ㅠㅠ',\n",
       " '주님께서 부르셔서 제가 여기 있나이다.',\n",
       " '미성년자가 돈많은 아저씨에게 순결을 바치고 데인후 결국 정신차리고 공부해거 명문대가는 진부한 결말',\n",
       " '정말 재밌게 봤고 빈센트도 꼬마도 연기 너무 잘하네요. ㅎ',\n",
       " '솔직히 원작보다 훨씬낫다 원작 무슨 인간이 말도못하게설정해놨어',\n",
       " '말이 필요없음,,, 아 진심 개재밌다ㅠㅠ',\n",
       " '보니까 이양반이 다세포소녀 감독이네',\n",
       " '굿 잡!!! 친구랑 또 보고 싶네요!',\n",
       " '재미진짜 흥하네 근데 yang**** 이새끼 관종인가 ㅋㅋㅋ',\n",
       " '야경꾼보다 엉망지루함',\n",
       " '예원찡... 그만울어....',\n",
       " '근 5년동안 본 모든영화 통틀어서 최악의영화..시간이 남아돌때 봐도 시간이 아까운 역대급 쓰레기영화;;',\n",
       " '감동이다.. 참고로 이 영화 보신분들 마지막엔딩부분에 자막으로나오는부분잇죠? .. 이게 영화상에서 실화라는거지 진짜 레알 현재 실제로 실화라는말이아니에요.. 전지현이 피디잔아요 다큐찍는거 ...그 다큐에서엔딩장면이지 진짜 실제가아니에여.. 쨋든',\n",
       " '달기지...미니어쳐 티 팍팍 나던데...우뢔매 보는줄 알았다...혹시 특수효과 감독이 심형래?',\n",
       " '재미 드럽게 없다ㅋㅋㅋ',\n",
       " '야 세르게이!!! 작은 고추의 매운맛을 보여주마',\n",
       " '정여립과 정철, 기축옥사까지.. 스토리 탄탄해서 좋습니다. 배우들도 연기 참 잘하고 남녀주인공들 케미도 좋고! 챙겨 볼 수 밖에 없는 드라마ㅠㅠㅠㅠ',\n",
       " '개OO영화네요....내용도없고 그냥심심해서만든영화가..',\n",
       " '두개는 줄려고 했는데 알바가 많아서. 아후 볼거없어서 채널 돌려도 다시 다른데로 돌리게만드는구나',\n",
       " '왜 0점은 줄 수 없나요?',\n",
       " '영화사에 남을 작품. 실험영화의 완성본',\n",
       " '자식을 그렇게 때리냐?',\n",
       " '이게 대체 무슨 내용이야;;',\n",
       " 'ㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋ옛다 1점이나 처먹어랔ㅋㅋㅋㅋㅋㅋㅋㅋ이게 7점급?이건 1점짜리. 내용도 결말도. 살다 살다 뭐 이딴...',\n",
       " '감동적이였고 좋았습니다',\n",
       " '초반에 개재미없었는데 볼수록 점점 재밌어짐! 외계인이 내가 알던 에일리언에 나오던 외계인이 아니야....',\n",
       " '쇼핑백 잊혀지지 않는다....',\n",
       " '의도는 좋지만 너무 몰입이 안되는걸 어떡해',\n",
       " '유치하지만 가볍게 볼만함',\n",
       " '화려한 색채때문에 눈이 아프지만 그 나름대로 화려연예계여자욕망에대해 표현해냈던거같다 보는내내 진짜 리리코심정가진 연옌들도 있을거같고..나를한번도보지못하고알지못하는사람들이날어떻게사랑하냐그런대사 나왔을때 소름돋더라 연예인들은 많은사랑받으면서도 참 허전할듯',\n",
       " '본지 수OO이 지나도 아직도 생생함. 고양이 귀신의 복수가 진짜 무서웠지',\n",
       " '영상이 대학교 졸업작품같아서 그렇지 꽤나 많은걸 담아놓은 영화임에는 분명하다.',\n",
       " '최강 전차부대 ..,,..',\n",
       " 'ㅇㅇ',\n",
       " '진짜 어이없는 소재라고 생각하며 보는데 개 웃겨.... 남자로서는 솔직히 조금은 부러울수도 있는',\n",
       " 'tv 전기세가 아까웠다!!!',\n",
       " '초등학교때 선생님이 보여주신 영화 시간이 흘러서 기억나는건 에이즈에 걸렸던 남자아이와 운동화였고 그때 봤던 영화가 뭐였을까? 궁금했었는데 그 영화가 바로 굿바이마이프렌드였다 12년전이나 12년후나 명작은 시간이 흘러도 명작이다',\n",
       " '넘 재밌었어요/ㅅ/ㅎㅎㅎ',\n",
       " '설리 94년생인데 93년도 영화에 어떻게 나오져?',\n",
       " '샷의 연결이 아닌 충돌만큼이나 거룩한 제목 또한 인상적이구려',\n",
       " 'ㅋㅋㅋ 재미없음',\n",
       " '오오 난 여태까지 맷데이먼의 최고의영화는 본 얼티메이텀,라이언일병구하기 뿐인줄알았음ㅠ 굿윌헌팅도쩐당',\n",
       " '이야기 자체가 흥미를 끌지 못하는군',\n",
       " '날 로그인하게 만들다니.....청춘이여 영원하라....',\n",
       " '현정언니 짱이죠 완전 잼잇어요 ㅎ',\n",
       " '영상미 예쁘고 좋지만 러닝타임이 2시간이 넘는데 초반 30분에 줄거리 다 나갔고 엄청 지루한 화보집 보는 기분 일본영화 특유의 그 이해못할 희한함이 있음',\n",
       " '스토리 연결 전혀 안되고 편집해서 끼워맞춘 드라마 말아먹은 작품',\n",
       " '여자 주인공이 예뻐서 끝까지 봤다',\n",
       " '지구를 지켜라...혹 이 작품을 보고 만든 건 아닌지...',\n",
       " '저렇게 힘들게 영화를 만드는데, 왜 한국영화는 다 쓰레기냐?',\n",
       " '케릭터가 살아있었으며, 미장센이 훌륭했다. 이야기는 몰입도 있었고, 불필요한 샷은 존재하지 않았다. 노인을 위한나라는 없다 먼저 봤지만 코엔감독 매력적인영화를 만드는 멋있는 사람',\n",
       " '마지막이 좀황당했지만 좋은영화',\n",
       " '우연히 tv를 돌려보다가 사로잡혔다. 최근 10년간 본 코미디 영화 중 최고',\n",
       " '연 기 굿 화이팅해요누나',\n",
       " '마이클베이 최근작을 볼때마다 느낀다. 블록버스터 액션장르라도 탄탄한 시나리오는 영화의 필수라는것을. 그리고 당신이 기대하던 메간폭스는 늙었다.',\n",
       " '0점은없나?1점은 너무 후하네',\n",
       " '미달이는.. 연예계를 바라보는 태도를 고쳐야 한다.',\n",
       " '파괴된 관객들.',\n",
       " '알콜중독자들 덕에 평점이 낮은가?',\n",
       " '중견배우들이 만들어놓은 긴장감이 나름 긴장감있게 싸워보려했던 도술사들에 의해 헛웃음나온다.',\n",
       " '남자 주인공 늑대 인간으로 변하고 끝나네유. 평점 보고 안 볼까 하다가 봤는디 재밌네유. CG보다 이런 실물 특수 효과가 더 보는 재미가 있어유. 웃기기까지 하네유. 근디 제목 번역은 어느 바보가 한거여. 그냥 늑대 인간이 아니잖여.',\n",
       " ...]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 문자열 아닌 데이터 모두 제거\n",
    "train_review = [review for review in train_data['document'] if type(review) is str]\n",
    "train_review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 한글 폰트 설정(.ttf파일 다운로드 후 실행)\n",
    "wordcloud = WordCloud(DATA_PATH+'hangeul.ttf').generate(' '.join(train_review))\n",
    "plt.imshow(wordcloud, interpolation='bilinear')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "긍정 리뷰 갯수: 74827\n",
      "부정 리뷰 갯수: 75173\n"
     ]
    }
   ],
   "source": [
    "#긍정 1, 부정 0\n",
    "print('긍정 리뷰 갯수: {}'.format(train_data['label'].value_counts()[1]))\n",
    "print('부정 리뷰 갯수: {}'.format(train_data['label'].value_counts()[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 데이터 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                  아 더빙.. 진짜 짜증나네요 목소리\n",
       "1                    흠...포스터보고 초딩영화줄....오버연기조차 가볍지 않구나\n",
       "2                                    너무재밓었다그래서보는것을추천한다\n",
       "3                        교도소 이야기구먼 ..솔직히 재미는 없다..평점 조정\n",
       "4    사이몬페그의 익살스런 연기가 돋보였던 영화!스파이더맨에서 늙어보이기만 했던 커스틴 ...\n",
       "Name: document, dtype: object"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import json\n",
    "from konlpy.tag import Okt\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "\n",
    "DATA_PATH = './DATA/' # 데이터 경로 설정\n",
    "train_data = pd.read_csv(DATA_PATH+'ratings_train.txt', header = 0, delimiter='\\t', quoting=3)\n",
    "\n",
    "train_data['document'][:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "#전처리 함수 만들기\n",
    "def preprocessing(review, okt, remove_stopwords = False, stop_words =[]):\n",
    "  #함수인자설명\n",
    "  # review: 전처리할 텍스트\n",
    "  # okt: okt객체를 반복적으로 생성하지 않고 미리 생성 후 인자로 받음\n",
    "  # remove_stopword: 불용어를 제거할지 여부 선택. 기본값 False\n",
    "  # stop_words: 불용어 사전은 사용자가 직접 입력, 기본값 빈 리스트\n",
    "\n",
    "  # 1. 한글 및 공백 제외한 문자 모두 제거\n",
    "    review_text = re.sub('[^가-힣ㄱ-ㅎㅏ-ㅣ\\\\s]','',review)\n",
    "  \n",
    "  #2. okt 객체를 활용하여 형태소 단어로 나눔\n",
    "    word_review = okt.morphs(review_text,stem=True)\n",
    "\n",
    "    if remove_stopwords:\n",
    "    #3. 불용어 제거(선택)\n",
    "        word_review = [token for token in word_review if not token in stop_words]\n",
    "    return word_review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-118-aedbdac6dc16>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m   \u001b[0;31m# 리뷰가 문자열인 경우만 전처리 진행\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreview\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m         \u001b[0mclean_train_review\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreprocessing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreview\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mokt\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mremove_stopwords\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mstop_words\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mstop_words\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mclean_train_review\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#str이 아닌 행은 빈칸으로 놔두기\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-117-aab4efb58f06>\u001b[0m in \u001b[0;36mpreprocessing\u001b[0;34m(review, okt, remove_stopwords, stop_words)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m   \u001b[0;31m#2. okt 객체를 활용하여 형태소 단어로 나눔\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0mword_review\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mokt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmorphs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreview_text\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mstem\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mremove_stopwords\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/konlpy/tag/_okt.py\u001b[0m in \u001b[0;36mmorphs\u001b[0;34m(self, phrase, norm, stem)\u001b[0m\n\u001b[1;32m     87\u001b[0m         \u001b[0;34m\"\"\"Parse phrase to morphemes.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0ms\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpos\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mphrase\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnorm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstem\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     90\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mphrases\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mphrase\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/konlpy/tag/_okt.py\u001b[0m in \u001b[0;36mpos\u001b[0;34m(self, phrase, norm, stem, join)\u001b[0m\n\u001b[1;32m     72\u001b[0m                     \u001b[0mphrase\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m                     \u001b[0mjpype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjava\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlang\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBoolean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m                     jpype.java.lang.Boolean(stem)).toArray()\n\u001b[0m\u001b[1;32m     75\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mjoin\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mt\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtokens\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# 전체 텍스트 전처리\n",
    "stop_words = ['은','는','이','가','하','아','것','들','의','있','되','수','보','주','등','한', '좀', '잘', '걍', '과', '도', '를', '으로', '자', '에', '와', '하다']\n",
    "okt = Okt()\n",
    "clean_train_review = []\n",
    "\n",
    "for review in train_data['document']:\n",
    "  # 리뷰가 문자열인 경우만 전처리 진행\n",
    "    if type(review) == str:\n",
    "        clean_train_review.append(preprocessing(review,okt,remove_stopwords=True,stop_words= stop_words))\n",
    "    else:\n",
    "        clean_train_review.append([]) #str이 아닌 행은 빈칸으로 놔두기\n",
    "\n",
    "clean_train_review[:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#테스트 리뷰도 동일하게 전처리\n",
    "test_data = pd.read_csv(DATA_PATH + 'ratings_test.txt', header = 0, delimiter='\\t', quoting=3)\n",
    "\n",
    "clean_test_review = []\n",
    "for review in test_data['document']:\n",
    "    if type(review) == str:\n",
    "        clean_test_review.append(preprocessing(review, okt, remove_stopwords=True, stop_words=stop_words))\n",
    "    else:\n",
    "        clean_test_review.append([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 인덱스 벡터 변환 후 일정 길이 넘어가거나 모자라는 리뷰 패딩처리\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(clean_train_review)\n",
    "train_sequences = tokenizer.texts_to_sequences(clean_train_review)\n",
    "test_sequences = tokenizer.texts_to_sequences(clean_test_review)\n",
    "\n",
    "word_vocab = tokenizer.word_index #단어사전형태\n",
    "MAX_SEQUENCE_LENGTH = 8 #문장 최대 길이\n",
    "\n",
    "#학습 데이터\n",
    "train_inputs = pad_sequences(train_sequences,maxlen=MAX_SEQUENCE_LENGTH,padding='post')\n",
    "\n",
    "#학습 데이터 라벨 벡터화\n",
    "train_labels = np.array(train_data['label'])\n",
    "\n",
    "#평가 데이터 \n",
    "test_inputs = pad_sequences(test_sequences,maxlen=MAX_SEQUENCE_LENGTH,padding='post')\n",
    "#평가 데이터 라벨 벡터화\n",
    "test_labels = np.array(test_data['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n#전처리한 데이터들 파일로저장\\nimport os\\n\\nif not os.path.exists(DEFAULT_PATH + DATA_PATH):\\n    os.makedirs(DEFAULT_PATH+DATA_PATH)\\n\\n#전처리 학습데이터 넘파이로 저장\\nnp.save(open(DEFAULT_PATH+DATA_PATH+TRAIN_INPUT_DATA,'wb'),train_inputs)\\nnp.save(open(DEFAULT_PATH+DATA_PATH+TRAIN_LABEL_DATA,'wb'),train_labels)\\n#전처리 테스트데이터 넘파이로 저장\\nnp.save(open(DEFAULT_PATH+DATA_PATH+TEST_INPUT_DATA,'wb'),test_inputs)\\nnp.save(open(DEFAULT_PATH+DATA_PATH+TEST_LABEL_DATA,'wb'),test_labels)\\n\\n#데이터 사전 json으로 저장\\njson.dump(data_configs,open(DAFAULT_PATH + DATA_PATH + DATA_CONFIGS,'w'),ensure_ascii=False)\\n\""
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#DEFAULT_PATH  = '/content/sample_data/' # 경로지정\n",
    "import sys\n",
    "from importlib import reload\n",
    "reload(sys)\n",
    "\n",
    "\n",
    "DATA_PATH = './CLEAN_DATA/' #.npy파일 저장 경로지정\n",
    "TRAIN_INPUT_DATA = 'nsmc_train_input.npy'\n",
    "TRAIN_LABEL_DATA = 'nsmc_train_label.npy'\n",
    "TEST_INPUT_DATA = 'nsmc_test_input.npy'\n",
    "TEST_LABEL_DATA = 'nsmc_test_label.npy'\n",
    "DATA_CONFIGS = 'data_configs.json'\n",
    "\n",
    "data_configs={}\n",
    "data_configs['vocab'] = word_vocab\n",
    "data_configs['vocab_size'] = len(word_vocab) + 1\n",
    "\n",
    "#전처리한 데이터들 파일로저장\n",
    "import os\n",
    "\n",
    "if not os.path.exists(DATA_PATH):\n",
    "    os.makedirs(DATA_PATH)\n",
    "\n",
    "#전처리 학습데이터 넘파이로 저장\n",
    "np.save(open(DATA_PATH+TRAIN_INPUT_DATA,'wb'),train_inputs)\n",
    "np.save(open(DATA_PATH+TRAIN_LABEL_DATA,'wb'),train_labels)\n",
    "#전처리 테스트데이터 넘파이로 저장\n",
    "np.save(open(DATA_PATH+TEST_INPUT_DATA,'wb'),test_inputs)\n",
    "np.save(open(DATA_PATH+TEST_LABEL_DATA,'wb'),test_labels)\n",
    "\n",
    "#데이터 사전 json으로 저장\n",
    "json.dump(data_configs,open(DATA_PATH + DATA_CONFIGS,'w', encoding = 'utf-8'),ensure_ascii=False)\n",
    "\n",
    "\"\"\"\n",
    "#전처리한 데이터들 파일로저장\n",
    "import os\n",
    "\n",
    "if not os.path.exists(DEFAULT_PATH + DATA_PATH):\n",
    "    os.makedirs(DEFAULT_PATH+DATA_PATH)\n",
    "\n",
    "#전처리 학습데이터 넘파이로 저장\n",
    "np.save(open(DEFAULT_PATH+DATA_PATH+TRAIN_INPUT_DATA,'wb'),train_inputs)\n",
    "np.save(open(DEFAULT_PATH+DATA_PATH+TRAIN_LABEL_DATA,'wb'),train_labels)\n",
    "#전처리 테스트데이터 넘파이로 저장\n",
    "np.save(open(DEFAULT_PATH+DATA_PATH+TEST_INPUT_DATA,'wb'),test_inputs)\n",
    "np.save(open(DEFAULT_PATH+DATA_PATH+TEST_LABEL_DATA,'wb'),test_labels)\n",
    "\n",
    "#데이터 사전 json으로 저장\n",
    "json.dump(data_configs,open(DAFAULT_PATH + DATA_PATH + DATA_CONFIGS,'w'),ensure_ascii=False)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 모델링"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습 데이터 불러오기\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras import layers\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "\n",
    "#전처리 데이터 불러오기\n",
    "DATA_PATH = './CLEAN_DATA/'\n",
    "DATA_OUT = './DATA_OUT/'\n",
    "INPUT_TRAIN_DATA = 'nsmc_train_input.npy'\n",
    "LABEL_TRAIN_DATA = 'nsmc_train_label.npy'\n",
    "DATA_CONFIGS = 'data_configs.json'\n",
    "\n",
    "train_input = np.load(open(DATA_PATH + INPUT_TRAIN_DATA,'rb'))\n",
    "train_input = pad_sequences(train_input,maxlen=train_input.shape[1])\n",
    "train_label = np.load(open(DATA_PATH + LABEL_TRAIN_DATA,'rb'))\n",
    "prepro_configs = json.load(open(DATA_PATH+DATA_CONFIGS,'r', encoding = 'utf-8'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 파라미터 세팅"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name= 'cnn_classifier_kr/'\n",
    "BATCH_SIZE = 512\n",
    "NUM_EPOCHS = 500\n",
    "VALID_SPLIT = 0.1\n",
    "MAX_LEN = train_input.shape[1]\n",
    "\n",
    "kargs={'model_name': model_name, 'vocab_size':prepro_configs['vocab_size'],'embbeding_size':128, 'num_filters':100,'dropout_rate':0.5, 'hidden_dimension':250,'output_dimension':1}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 모델 함수 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNNClassifier(tf.keras.Model):\n",
    "\n",
    "    def __init__(self, **kargs):\n",
    "        super(CNNClassifier, self).__init__(name=kargs['model_name'])\n",
    "        self.embedding = layers.Embedding(input_dim=kargs['vocab_size'], output_dim=kargs['embbeding_size'])\n",
    "        self.conv_list = [layers.Conv1D(filters=kargs['num_filters'], kernel_size=kernel_size, padding='valid',activation = tf.keras.activations.relu,\n",
    "                                        kernel_constraint = tf.keras.constraints.MaxNorm(max_value=3)) for kernel_size in [3,4,5]]\n",
    "        self.pooling = layers.GlobalMaxPooling1D()\n",
    "        self.dropout = layers.Dropout(kargs['dropout_rate'])\n",
    "        self.fc1 = layers.Dense(units=kargs['hidden_dimension'],\n",
    "                                activation = tf.keras.activations.relu,\n",
    "                                kernel_constraint=tf.keras.constraints.MaxNorm(max_value=3.))\n",
    "        self.fc2 = layers.Dense(units=kargs['output_dimension'],\n",
    "                                activation=tf.keras.activations.sigmoid,\n",
    "                                kernel_constraint= tf.keras.constraints.MaxNorm(max_value=3.))\n",
    "    \n",
    "\n",
    "    def call(self,x):\n",
    "        x = self.embedding(x)\n",
    "        x = self.dropout(x)\n",
    "        x = tf.concat([self.pooling(conv(x)) for conv in self.conv_list], axis = 1)\n",
    "        x = self.fc1(x)\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 모델 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "import absl.logging\n",
    "absl.logging.set_verbosity(absl.logging.ERROR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./DATA_OUT/cnn_classifier_kr -- Folder already exists \n",
      "\n",
      "Epoch 1/500\n",
      "263/264 [============================>.] - ETA: 0s - loss: 0.4590 - accuracy: 0.7731\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.82080, saving model to ./DATA_OUT/cnn_classifier_kr/weights.h5\n",
      "264/264 [==============================] - 7s 27ms/step - loss: 0.4586 - accuracy: 0.7733 - val_loss: 0.3891 - val_accuracy: 0.8208\n",
      "Epoch 2/500\n",
      "262/264 [============================>.] - ETA: 0s - loss: 0.3514 - accuracy: 0.8456\n",
      "Epoch 00002: val_accuracy improved from 0.82080 to 0.82900, saving model to ./DATA_OUT/cnn_classifier_kr/weights.h5\n",
      "264/264 [==============================] - 7s 25ms/step - loss: 0.3514 - accuracy: 0.8456 - val_loss: 0.3791 - val_accuracy: 0.8290\n",
      "Epoch 3/500\n",
      "263/264 [============================>.] - ETA: 0s - loss: 0.2988 - accuracy: 0.8742\n",
      "Epoch 00003: val_accuracy did not improve from 0.82900\n",
      "264/264 [==============================] - 7s 25ms/step - loss: 0.2987 - accuracy: 0.8742 - val_loss: 0.3886 - val_accuracy: 0.8285\n",
      "Epoch 4/500\n",
      "263/264 [============================>.] - ETA: 0s - loss: 0.2563 - accuracy: 0.8938\n",
      "Epoch 00004: val_accuracy did not improve from 0.82900\n",
      "264/264 [==============================] - 6s 24ms/step - loss: 0.2563 - accuracy: 0.8938 - val_loss: 0.4135 - val_accuracy: 0.8259\n",
      "Epoch 5/500\n",
      "263/264 [============================>.] - ETA: 0s - loss: 0.2202 - accuracy: 0.9100\n",
      "Epoch 00005: val_accuracy did not improve from 0.82900\n",
      "264/264 [==============================] - 6s 24ms/step - loss: 0.2202 - accuracy: 0.9100 - val_loss: 0.4319 - val_accuracy: 0.8197\n",
      "Epoch 6/500\n",
      "264/264 [==============================] - ETA: 0s - loss: 0.1947 - accuracy: 0.9202\n",
      "Epoch 00006: val_accuracy did not improve from 0.82900\n",
      "264/264 [==============================] - 6s 23ms/step - loss: 0.1947 - accuracy: 0.9202 - val_loss: 0.4640 - val_accuracy: 0.8180\n",
      "Epoch 7/500\n",
      "262/264 [============================>.] - ETA: 0s - loss: 0.1739 - accuracy: 0.9302\n",
      "Epoch 00007: val_accuracy did not improve from 0.82900\n",
      "264/264 [==============================] - 6s 24ms/step - loss: 0.1741 - accuracy: 0.9301 - val_loss: 0.4998 - val_accuracy: 0.8162\n",
      "Epoch 8/500\n",
      "264/264 [==============================] - ETA: 0s - loss: 0.1568 - accuracy: 0.9363\n",
      "Epoch 00008: val_accuracy did not improve from 0.82900\n",
      "264/264 [==============================] - 6s 25ms/step - loss: 0.1568 - accuracy: 0.9363 - val_loss: 0.5168 - val_accuracy: 0.8153\n",
      "Epoch 9/500\n",
      "264/264 [==============================] - ETA: 0s - loss: 0.1445 - accuracy: 0.9420\n",
      "Epoch 00009: val_accuracy did not improve from 0.82900\n",
      "264/264 [==============================] - 6s 23ms/step - loss: 0.1445 - accuracy: 0.9420 - val_loss: 0.5391 - val_accuracy: 0.8141\n",
      "Epoch 10/500\n",
      "262/264 [============================>.] - ETA: 0s - loss: 0.1368 - accuracy: 0.9444\n",
      "Epoch 00010: val_accuracy did not improve from 0.82900\n",
      "264/264 [==============================] - 6s 25ms/step - loss: 0.1369 - accuracy: 0.9444 - val_loss: 0.5671 - val_accuracy: 0.8189\n",
      "Epoch 11/500\n",
      "262/264 [============================>.] - ETA: 0s - loss: 0.1276 - accuracy: 0.9487\n",
      "Epoch 00011: val_accuracy did not improve from 0.82900\n",
      "264/264 [==============================] - 7s 25ms/step - loss: 0.1278 - accuracy: 0.9486 - val_loss: 0.5987 - val_accuracy: 0.8166\n",
      "Epoch 12/500\n",
      "262/264 [============================>.] - ETA: 0s - loss: 0.1213 - accuracy: 0.9506\n",
      "Epoch 00012: val_accuracy did not improve from 0.82900\n",
      "264/264 [==============================] - 6s 24ms/step - loss: 0.1213 - accuracy: 0.9506 - val_loss: 0.6022 - val_accuracy: 0.8169\n",
      "Epoch 13/500\n",
      "264/264 [==============================] - ETA: 0s - loss: 0.1162 - accuracy: 0.9527\n",
      "Epoch 00013: val_accuracy did not improve from 0.82900\n",
      "264/264 [==============================] - 6s 24ms/step - loss: 0.1162 - accuracy: 0.9527 - val_loss: 0.6260 - val_accuracy: 0.8157\n",
      "Epoch 14/500\n",
      "263/264 [============================>.] - ETA: 0s - loss: 0.1084 - accuracy: 0.9560\n",
      "Epoch 00014: val_accuracy did not improve from 0.82900\n",
      "264/264 [==============================] - 7s 25ms/step - loss: 0.1084 - accuracy: 0.9560 - val_loss: 0.6447 - val_accuracy: 0.8140\n",
      "Epoch 15/500\n",
      "263/264 [============================>.] - ETA: 0s - loss: 0.1064 - accuracy: 0.9567\n",
      "Epoch 00015: val_accuracy did not improve from 0.82900\n",
      "264/264 [==============================] - 6s 24ms/step - loss: 0.1064 - accuracy: 0.9567 - val_loss: 0.6683 - val_accuracy: 0.8148\n",
      "Epoch 16/500\n",
      "264/264 [==============================] - ETA: 0s - loss: 0.1023 - accuracy: 0.9577\n",
      "Epoch 00016: val_accuracy did not improve from 0.82900\n",
      "264/264 [==============================] - 6s 24ms/step - loss: 0.1023 - accuracy: 0.9577 - val_loss: 0.6890 - val_accuracy: 0.8133\n",
      "Epoch 17/500\n",
      "264/264 [==============================] - ETA: 0s - loss: 0.0991 - accuracy: 0.9594\n",
      "Epoch 00017: val_accuracy did not improve from 0.82900\n",
      "264/264 [==============================] - 7s 25ms/step - loss: 0.0991 - accuracy: 0.9594 - val_loss: 0.6902 - val_accuracy: 0.8144\n",
      "Epoch 18/500\n",
      "264/264 [==============================] - ETA: 0s - loss: 0.0966 - accuracy: 0.9609\n",
      "Epoch 00018: val_accuracy did not improve from 0.82900\n",
      "264/264 [==============================] - 6s 24ms/step - loss: 0.0966 - accuracy: 0.9609 - val_loss: 0.6977 - val_accuracy: 0.8131\n",
      "Epoch 19/500\n",
      "263/264 [============================>.] - ETA: 0s - loss: 0.0929 - accuracy: 0.9620\n",
      "Epoch 00019: val_accuracy did not improve from 0.82900\n",
      "264/264 [==============================] - 6s 24ms/step - loss: 0.0929 - accuracy: 0.9620 - val_loss: 0.7005 - val_accuracy: 0.8171\n",
      "Epoch 20/500\n",
      "263/264 [============================>.] - ETA: 0s - loss: 0.0895 - accuracy: 0.9634\n",
      "Epoch 00020: val_accuracy did not improve from 0.82900\n",
      "264/264 [==============================] - 6s 24ms/step - loss: 0.0895 - accuracy: 0.9634 - val_loss: 0.7150 - val_accuracy: 0.8137\n",
      "Epoch 21/500\n",
      "263/264 [============================>.] - ETA: 0s - loss: 0.0877 - accuracy: 0.9642\n",
      "Epoch 00021: val_accuracy did not improve from 0.82900\n",
      "264/264 [==============================] - 6s 23ms/step - loss: 0.0877 - accuracy: 0.9642 - val_loss: 0.7405 - val_accuracy: 0.8157\n",
      "Epoch 22/500\n",
      "262/264 [============================>.] - ETA: 0s - loss: 0.0852 - accuracy: 0.9657\n",
      "Epoch 00022: val_accuracy did not improve from 0.82900\n",
      "264/264 [==============================] - 6s 24ms/step - loss: 0.0853 - accuracy: 0.9657 - val_loss: 0.7516 - val_accuracy: 0.8165\n",
      "Epoch 23/500\n",
      "263/264 [============================>.] - ETA: 0s - loss: 0.0836 - accuracy: 0.9656\n",
      "Epoch 00023: val_accuracy did not improve from 0.82900\n",
      "264/264 [==============================] - 6s 24ms/step - loss: 0.0836 - accuracy: 0.9656 - val_loss: 0.7424 - val_accuracy: 0.8135\n",
      "Epoch 24/500\n",
      "263/264 [============================>.] - ETA: 0s - loss: 0.0823 - accuracy: 0.9658\n",
      "Epoch 00024: val_accuracy did not improve from 0.82900\n",
      "264/264 [==============================] - 6s 24ms/step - loss: 0.0822 - accuracy: 0.9658 - val_loss: 0.7800 - val_accuracy: 0.8155\n",
      "Epoch 25/500\n",
      "262/264 [============================>.] - ETA: 0s - loss: 0.0801 - accuracy: 0.9674\n",
      "Epoch 00025: val_accuracy did not improve from 0.82900\n",
      "264/264 [==============================] - 6s 23ms/step - loss: 0.0802 - accuracy: 0.9673 - val_loss: 0.7792 - val_accuracy: 0.8135\n",
      "Epoch 26/500\n",
      "264/264 [==============================] - ETA: 0s - loss: 0.0781 - accuracy: 0.9679\n",
      "Epoch 00026: val_accuracy did not improve from 0.82900\n",
      "264/264 [==============================] - 6s 24ms/step - loss: 0.0781 - accuracy: 0.9679 - val_loss: 0.8005 - val_accuracy: 0.8127\n",
      "Epoch 27/500\n",
      "263/264 [============================>.] - ETA: 0s - loss: 0.0768 - accuracy: 0.9687\n",
      "Epoch 00027: val_accuracy did not improve from 0.82900\n",
      "264/264 [==============================] - 6s 25ms/step - loss: 0.0768 - accuracy: 0.9687 - val_loss: 0.8121 - val_accuracy: 0.8171\n",
      "Epoch 28/500\n",
      "262/264 [============================>.] - ETA: 0s - loss: 0.0759 - accuracy: 0.9681\n",
      "Epoch 00028: val_accuracy did not improve from 0.82900\n",
      "264/264 [==============================] - 7s 25ms/step - loss: 0.0759 - accuracy: 0.9681 - val_loss: 0.7916 - val_accuracy: 0.8153\n",
      "Epoch 29/500\n",
      "264/264 [==============================] - ETA: 0s - loss: 0.0740 - accuracy: 0.9702\n",
      "Epoch 00029: val_accuracy did not improve from 0.82900\n",
      "264/264 [==============================] - 6s 23ms/step - loss: 0.0740 - accuracy: 0.9702 - val_loss: 0.8014 - val_accuracy: 0.8150\n",
      "Epoch 30/500\n",
      "263/264 [============================>.] - ETA: 0s - loss: 0.0735 - accuracy: 0.9698\n",
      "Epoch 00030: val_accuracy did not improve from 0.82900\n",
      "264/264 [==============================] - 7s 25ms/step - loss: 0.0735 - accuracy: 0.9698 - val_loss: 0.7947 - val_accuracy: 0.8135\n",
      "Epoch 31/500\n",
      "263/264 [============================>.] - ETA: 0s - loss: 0.0720 - accuracy: 0.9704\n",
      "Epoch 00031: val_accuracy did not improve from 0.82900\n",
      "264/264 [==============================] - 6s 24ms/step - loss: 0.0721 - accuracy: 0.9704 - val_loss: 0.7982 - val_accuracy: 0.8145\n",
      "Epoch 32/500\n",
      "263/264 [============================>.] - ETA: 0s - loss: 0.0712 - accuracy: 0.9704\n",
      "Epoch 00032: val_accuracy did not improve from 0.82900\n",
      "264/264 [==============================] - 6s 24ms/step - loss: 0.0712 - accuracy: 0.9704 - val_loss: 0.8497 - val_accuracy: 0.8164\n",
      "Epoch 33/500\n",
      "263/264 [============================>.] - ETA: 0s - loss: 0.0700 - accuracy: 0.9717\n",
      "Epoch 00033: val_accuracy did not improve from 0.82900\n",
      "264/264 [==============================] - 6s 24ms/step - loss: 0.0700 - accuracy: 0.9716 - val_loss: 0.8047 - val_accuracy: 0.8135\n",
      "Epoch 34/500\n",
      "262/264 [============================>.] - ETA: 0s - loss: 0.0689 - accuracy: 0.9717\n",
      "Epoch 00034: val_accuracy did not improve from 0.82900\n",
      "264/264 [==============================] - 6s 24ms/step - loss: 0.0691 - accuracy: 0.9717 - val_loss: 0.8399 - val_accuracy: 0.8142\n",
      "Epoch 35/500\n",
      "264/264 [==============================] - ETA: 0s - loss: 0.0688 - accuracy: 0.9719\n",
      "Epoch 00035: val_accuracy did not improve from 0.82900\n",
      "264/264 [==============================] - 6s 24ms/step - loss: 0.0688 - accuracy: 0.9719 - val_loss: 0.8051 - val_accuracy: 0.8111\n",
      "Epoch 36/500\n",
      "263/264 [============================>.] - ETA: 0s - loss: 0.0653 - accuracy: 0.9728\n",
      "Epoch 00036: val_accuracy did not improve from 0.82900\n",
      "264/264 [==============================] - 6s 23ms/step - loss: 0.0653 - accuracy: 0.9728 - val_loss: 0.8657 - val_accuracy: 0.8121\n",
      "Epoch 37/500\n",
      "263/264 [============================>.] - ETA: 0s - loss: 0.0658 - accuracy: 0.9728\n",
      "Epoch 00037: val_accuracy did not improve from 0.82900\n",
      "264/264 [==============================] - 6s 23ms/step - loss: 0.0658 - accuracy: 0.9728 - val_loss: 0.8987 - val_accuracy: 0.8129\n",
      "Epoch 38/500\n",
      "263/264 [============================>.] - ETA: 0s - loss: 0.0652 - accuracy: 0.9729\n",
      "Epoch 00038: val_accuracy did not improve from 0.82900\n",
      "264/264 [==============================] - 6s 24ms/step - loss: 0.0653 - accuracy: 0.9728 - val_loss: 0.8728 - val_accuracy: 0.8136\n",
      "Epoch 39/500\n",
      "264/264 [==============================] - ETA: 0s - loss: 0.0655 - accuracy: 0.9730\n",
      "Epoch 00039: val_accuracy did not improve from 0.82900\n",
      "264/264 [==============================] - 7s 25ms/step - loss: 0.0655 - accuracy: 0.9730 - val_loss: 0.8568 - val_accuracy: 0.8145\n",
      "Epoch 40/500\n",
      "263/264 [============================>.] - ETA: 0s - loss: 0.0643 - accuracy: 0.9737\n",
      "Epoch 00040: val_accuracy did not improve from 0.82900\n",
      "264/264 [==============================] - 7s 25ms/step - loss: 0.0643 - accuracy: 0.9737 - val_loss: 0.8701 - val_accuracy: 0.8125\n",
      "Epoch 41/500\n",
      "262/264 [============================>.] - ETA: 0s - loss: 0.0620 - accuracy: 0.9747\n",
      "Epoch 00041: val_accuracy did not improve from 0.82900\n",
      "264/264 [==============================] - 6s 24ms/step - loss: 0.0620 - accuracy: 0.9746 - val_loss: 0.8728 - val_accuracy: 0.8135\n",
      "Epoch 42/500\n",
      "263/264 [============================>.] - ETA: 0s - loss: 0.0624 - accuracy: 0.9741\n",
      "Epoch 00042: val_accuracy did not improve from 0.82900\n",
      "264/264 [==============================] - 6s 23ms/step - loss: 0.0624 - accuracy: 0.9741 - val_loss: 0.8969 - val_accuracy: 0.8131\n",
      "Epoch 43/500\n",
      "262/264 [============================>.] - ETA: 0s - loss: 0.0614 - accuracy: 0.9745\n",
      "Epoch 00043: val_accuracy did not improve from 0.82900\n",
      "264/264 [==============================] - 6s 23ms/step - loss: 0.0614 - accuracy: 0.9744 - val_loss: 0.9009 - val_accuracy: 0.8092\n",
      "Epoch 44/500\n",
      "264/264 [==============================] - ETA: 0s - loss: 0.0606 - accuracy: 0.9751\n",
      "Epoch 00044: val_accuracy did not improve from 0.82900\n",
      "264/264 [==============================] - 6s 22ms/step - loss: 0.0606 - accuracy: 0.9751 - val_loss: 0.8932 - val_accuracy: 0.8116\n",
      "Epoch 45/500\n",
      "262/264 [============================>.] - ETA: 0s - loss: 0.0603 - accuracy: 0.9754\n",
      "Epoch 00045: val_accuracy did not improve from 0.82900\n",
      "264/264 [==============================] - 6s 23ms/step - loss: 0.0603 - accuracy: 0.9754 - val_loss: 0.8868 - val_accuracy: 0.8111\n",
      "Epoch 46/500\n",
      "264/264 [==============================] - ETA: 0s - loss: 0.0603 - accuracy: 0.9751\n",
      "Epoch 00046: val_accuracy did not improve from 0.82900\n",
      "264/264 [==============================] - 6s 23ms/step - loss: 0.0603 - accuracy: 0.9751 - val_loss: 0.8901 - val_accuracy: 0.8113\n",
      "Epoch 47/500\n",
      "264/264 [==============================] - ETA: 0s - loss: 0.0596 - accuracy: 0.9755\n",
      "Epoch 00047: val_accuracy did not improve from 0.82900\n",
      "264/264 [==============================] - 6s 23ms/step - loss: 0.0596 - accuracy: 0.9755 - val_loss: 0.8695 - val_accuracy: 0.8139\n",
      "Epoch 48/500\n",
      "264/264 [==============================] - ETA: 0s - loss: 0.0577 - accuracy: 0.9765\n",
      "Epoch 00048: val_accuracy did not improve from 0.82900\n",
      "264/264 [==============================] - 6s 25ms/step - loss: 0.0577 - accuracy: 0.9765 - val_loss: 0.9215 - val_accuracy: 0.8147\n",
      "Epoch 49/500\n",
      "264/264 [==============================] - ETA: 0s - loss: 0.0587 - accuracy: 0.9759\n",
      "Epoch 00049: val_accuracy did not improve from 0.82900\n",
      "264/264 [==============================] - 6s 24ms/step - loss: 0.0587 - accuracy: 0.9759 - val_loss: 0.8707 - val_accuracy: 0.8171\n",
      "Epoch 50/500\n",
      "262/264 [============================>.] - ETA: 0s - loss: 0.0561 - accuracy: 0.9768\n",
      "Epoch 00050: val_accuracy did not improve from 0.82900\n",
      "264/264 [==============================] - 6s 24ms/step - loss: 0.0560 - accuracy: 0.9769 - val_loss: 0.9049 - val_accuracy: 0.8121\n",
      "Epoch 51/500\n",
      "262/264 [============================>.] - ETA: 0s - loss: 0.0575 - accuracy: 0.9763\n",
      "Epoch 00051: val_accuracy did not improve from 0.82900\n",
      "264/264 [==============================] - 6s 24ms/step - loss: 0.0576 - accuracy: 0.9763 - val_loss: 0.8841 - val_accuracy: 0.8149\n",
      "Epoch 52/500\n",
      "264/264 [==============================] - ETA: 0s - loss: 0.0565 - accuracy: 0.9770\n",
      "Epoch 00052: val_accuracy did not improve from 0.82900\n",
      "264/264 [==============================] - 6s 24ms/step - loss: 0.0565 - accuracy: 0.9770 - val_loss: 0.9159 - val_accuracy: 0.8126\n",
      "Epoch 53/500\n",
      "264/264 [==============================] - ETA: 0s - loss: 0.0561 - accuracy: 0.9769\n",
      "Epoch 00053: val_accuracy did not improve from 0.82900\n",
      "264/264 [==============================] - 6s 23ms/step - loss: 0.0561 - accuracy: 0.9769 - val_loss: 0.9405 - val_accuracy: 0.8118\n",
      "Epoch 54/500\n",
      "264/264 [==============================] - ETA: 0s - loss: 0.0561 - accuracy: 0.9771\n",
      "Epoch 00054: val_accuracy did not improve from 0.82900\n",
      "264/264 [==============================] - 6s 24ms/step - loss: 0.0561 - accuracy: 0.9771 - val_loss: 0.8672 - val_accuracy: 0.8134\n",
      "Epoch 55/500\n",
      "262/264 [============================>.] - ETA: 0s - loss: 0.0543 - accuracy: 0.9774\n",
      "Epoch 00055: val_accuracy did not improve from 0.82900\n",
      "264/264 [==============================] - 6s 23ms/step - loss: 0.0543 - accuracy: 0.9773 - val_loss: 0.9195 - val_accuracy: 0.8115\n",
      "Epoch 56/500\n",
      "262/264 [============================>.] - ETA: 0s - loss: 0.0538 - accuracy: 0.9779\n",
      "Epoch 00056: val_accuracy did not improve from 0.82900\n",
      "264/264 [==============================] - 6s 24ms/step - loss: 0.0540 - accuracy: 0.9779 - val_loss: 0.9329 - val_accuracy: 0.8126\n",
      "Epoch 57/500\n",
      "264/264 [==============================] - ETA: 0s - loss: 0.0530 - accuracy: 0.9779\n",
      "Epoch 00057: val_accuracy did not improve from 0.82900\n",
      "264/264 [==============================] - 6s 23ms/step - loss: 0.0530 - accuracy: 0.9779 - val_loss: 0.9814 - val_accuracy: 0.8118\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58/500\n",
      "264/264 [==============================] - ETA: 0s - loss: 0.0547 - accuracy: 0.9771\n",
      "Epoch 00058: val_accuracy did not improve from 0.82900\n",
      "264/264 [==============================] - 6s 24ms/step - loss: 0.0547 - accuracy: 0.9771 - val_loss: 0.9303 - val_accuracy: 0.8089\n",
      "Epoch 59/500\n",
      "263/264 [============================>.] - ETA: 0s - loss: 0.0531 - accuracy: 0.9780\n",
      "Epoch 00059: val_accuracy did not improve from 0.82900\n",
      "264/264 [==============================] - 6s 23ms/step - loss: 0.0531 - accuracy: 0.9780 - val_loss: 0.9197 - val_accuracy: 0.8104\n",
      "Epoch 60/500\n",
      "264/264 [==============================] - ETA: 0s - loss: 0.0525 - accuracy: 0.9781\n",
      "Epoch 00060: val_accuracy did not improve from 0.82900\n",
      "264/264 [==============================] - 6s 23ms/step - loss: 0.0525 - accuracy: 0.9781 - val_loss: 0.9190 - val_accuracy: 0.8105\n",
      "Epoch 61/500\n",
      "262/264 [============================>.] - ETA: 0s - loss: 0.0523 - accuracy: 0.9779\n",
      "Epoch 00061: val_accuracy did not improve from 0.82900\n",
      "264/264 [==============================] - 6s 23ms/step - loss: 0.0524 - accuracy: 0.9779 - val_loss: 0.9255 - val_accuracy: 0.8102\n",
      "Epoch 62/500\n",
      "262/264 [============================>.] - ETA: 0s - loss: 0.0510 - accuracy: 0.9789\n",
      "Epoch 00062: val_accuracy did not improve from 0.82900\n",
      "264/264 [==============================] - 6s 23ms/step - loss: 0.0511 - accuracy: 0.9788 - val_loss: 0.9774 - val_accuracy: 0.8144\n",
      "Epoch 63/500\n",
      "264/264 [==============================] - ETA: 0s - loss: 0.0521 - accuracy: 0.9784\n",
      "Epoch 00063: val_accuracy did not improve from 0.82900\n",
      "264/264 [==============================] - 6s 22ms/step - loss: 0.0521 - accuracy: 0.9784 - val_loss: 0.9458 - val_accuracy: 0.8110\n",
      "Epoch 64/500\n",
      "264/264 [==============================] - ETA: 0s - loss: 0.0499 - accuracy: 0.9791\n",
      "Epoch 00064: val_accuracy did not improve from 0.82900\n",
      "264/264 [==============================] - 6s 24ms/step - loss: 0.0499 - accuracy: 0.9791 - val_loss: 0.9821 - val_accuracy: 0.8158\n",
      "Epoch 65/500\n",
      "264/264 [==============================] - ETA: 0s - loss: 0.0509 - accuracy: 0.9789\n",
      "Epoch 00065: val_accuracy did not improve from 0.82900\n",
      "264/264 [==============================] - 6s 23ms/step - loss: 0.0509 - accuracy: 0.9789 - val_loss: 0.9718 - val_accuracy: 0.8120\n",
      "Epoch 66/500\n",
      "262/264 [============================>.] - ETA: 0s - loss: 0.0512 - accuracy: 0.9783\n",
      "Epoch 00066: val_accuracy did not improve from 0.82900\n",
      "264/264 [==============================] - 6s 24ms/step - loss: 0.0512 - accuracy: 0.9783 - val_loss: 0.9609 - val_accuracy: 0.8131\n",
      "Epoch 67/500\n",
      "262/264 [============================>.] - ETA: 0s - loss: 0.0500 - accuracy: 0.9791\n",
      "Epoch 00067: val_accuracy did not improve from 0.82900\n",
      "264/264 [==============================] - 6s 23ms/step - loss: 0.0500 - accuracy: 0.9792 - val_loss: 0.9500 - val_accuracy: 0.8137\n",
      "Epoch 68/500\n",
      "264/264 [==============================] - ETA: 0s - loss: 0.0498 - accuracy: 0.9792\n",
      "Epoch 00068: val_accuracy did not improve from 0.82900\n",
      "264/264 [==============================] - 6s 23ms/step - loss: 0.0498 - accuracy: 0.9792 - val_loss: 0.9874 - val_accuracy: 0.8117\n",
      "Epoch 69/500\n",
      "263/264 [============================>.] - ETA: 0s - loss: 0.0496 - accuracy: 0.9792\n",
      "Epoch 00069: val_accuracy did not improve from 0.82900\n",
      "264/264 [==============================] - 6s 23ms/step - loss: 0.0496 - accuracy: 0.9792 - val_loss: 0.9465 - val_accuracy: 0.8122\n",
      "Epoch 70/500\n",
      "264/264 [==============================] - ETA: 0s - loss: 0.0492 - accuracy: 0.9798\n",
      "Epoch 00070: val_accuracy did not improve from 0.82900\n",
      "264/264 [==============================] - 6s 23ms/step - loss: 0.0492 - accuracy: 0.9798 - val_loss: 0.9740 - val_accuracy: 0.8137\n",
      "Epoch 71/500\n",
      "262/264 [============================>.] - ETA: 0s - loss: 0.0485 - accuracy: 0.9796\n",
      "Epoch 00071: val_accuracy did not improve from 0.82900\n",
      "264/264 [==============================] - 6s 23ms/step - loss: 0.0485 - accuracy: 0.9796 - val_loss: 0.9719 - val_accuracy: 0.8124\n",
      "Epoch 72/500\n",
      "264/264 [==============================] - ETA: 0s - loss: 0.0485 - accuracy: 0.9798\n",
      "Epoch 00072: val_accuracy did not improve from 0.82900\n",
      "264/264 [==============================] - 6s 23ms/step - loss: 0.0485 - accuracy: 0.9798 - val_loss: 0.9790 - val_accuracy: 0.8130\n",
      "Epoch 73/500\n",
      "262/264 [============================>.] - ETA: 0s - loss: 0.0480 - accuracy: 0.9796\n",
      "Epoch 00073: val_accuracy did not improve from 0.82900\n",
      "264/264 [==============================] - 6s 23ms/step - loss: 0.0480 - accuracy: 0.9795 - val_loss: 0.9645 - val_accuracy: 0.8127\n",
      "Epoch 74/500\n",
      "263/264 [============================>.] - ETA: 0s - loss: 0.0483 - accuracy: 0.9798\n",
      "Epoch 00074: val_accuracy did not improve from 0.82900\n",
      "264/264 [==============================] - 6s 22ms/step - loss: 0.0482 - accuracy: 0.9798 - val_loss: 0.9715 - val_accuracy: 0.8141\n",
      "Epoch 75/500\n",
      "264/264 [==============================] - ETA: 0s - loss: 0.0469 - accuracy: 0.9799\n",
      "Epoch 00075: val_accuracy did not improve from 0.82900\n",
      "264/264 [==============================] - 6s 23ms/step - loss: 0.0469 - accuracy: 0.9799 - val_loss: 1.0129 - val_accuracy: 0.8162\n",
      "Epoch 76/500\n",
      "264/264 [==============================] - ETA: 0s - loss: 0.0463 - accuracy: 0.9806\n",
      "Epoch 00076: val_accuracy did not improve from 0.82900\n",
      "264/264 [==============================] - 6s 23ms/step - loss: 0.0463 - accuracy: 0.9806 - val_loss: 1.0122 - val_accuracy: 0.8145\n",
      "Epoch 77/500\n",
      "262/264 [============================>.] - ETA: 0s - loss: 0.0463 - accuracy: 0.9807\n",
      "Epoch 00077: val_accuracy did not improve from 0.82900\n",
      "264/264 [==============================] - 6s 22ms/step - loss: 0.0463 - accuracy: 0.9807 - val_loss: 1.0068 - val_accuracy: 0.8109\n",
      "Epoch 78/500\n",
      "262/264 [============================>.] - ETA: 0s - loss: 0.0465 - accuracy: 0.9807\n",
      "Epoch 00078: val_accuracy did not improve from 0.82900\n",
      "264/264 [==============================] - 6s 23ms/step - loss: 0.0466 - accuracy: 0.9806 - val_loss: 0.9713 - val_accuracy: 0.8128\n",
      "Epoch 79/500\n",
      "263/264 [============================>.] - ETA: 0s - loss: 0.0468 - accuracy: 0.9801\n",
      "Epoch 00079: val_accuracy did not improve from 0.82900\n",
      "264/264 [==============================] - 6s 24ms/step - loss: 0.0468 - accuracy: 0.9802 - val_loss: 0.9827 - val_accuracy: 0.8122\n",
      "Epoch 80/500\n",
      "263/264 [============================>.] - ETA: 0s - loss: 0.0467 - accuracy: 0.9802\n",
      "Epoch 00080: val_accuracy did not improve from 0.82900\n",
      "264/264 [==============================] - 6s 23ms/step - loss: 0.0467 - accuracy: 0.9802 - val_loss: 0.9675 - val_accuracy: 0.8119\n",
      "Epoch 81/500\n",
      "262/264 [============================>.] - ETA: 0s - loss: 0.0457 - accuracy: 0.9806\n",
      "Epoch 00081: val_accuracy did not improve from 0.82900\n",
      "264/264 [==============================] - 6s 22ms/step - loss: 0.0457 - accuracy: 0.9806 - val_loss: 0.9917 - val_accuracy: 0.8129\n",
      "Epoch 82/500\n",
      "262/264 [============================>.] - ETA: 0s - loss: 0.0445 - accuracy: 0.9813\n",
      "Epoch 00082: val_accuracy did not improve from 0.82900\n",
      "264/264 [==============================] - 6s 23ms/step - loss: 0.0445 - accuracy: 0.9813 - val_loss: 1.0038 - val_accuracy: 0.8115\n",
      "Epoch 83/500\n",
      "262/264 [============================>.] - ETA: 0s - loss: 0.0459 - accuracy: 0.9805\n",
      "Epoch 00083: val_accuracy did not improve from 0.82900\n",
      "264/264 [==============================] - 6s 24ms/step - loss: 0.0459 - accuracy: 0.9805 - val_loss: 0.9881 - val_accuracy: 0.8125\n",
      "Epoch 84/500\n",
      "264/264 [==============================] - ETA: 0s - loss: 0.0452 - accuracy: 0.9810\n",
      "Epoch 00084: val_accuracy did not improve from 0.82900\n",
      "264/264 [==============================] - 6s 24ms/step - loss: 0.0452 - accuracy: 0.9810 - val_loss: 1.0267 - val_accuracy: 0.8140\n",
      "Epoch 85/500\n",
      "263/264 [============================>.] - ETA: 0s - loss: 0.0450 - accuracy: 0.9814\n",
      "Epoch 00085: val_accuracy did not improve from 0.82900\n",
      "264/264 [==============================] - 6s 24ms/step - loss: 0.0449 - accuracy: 0.9814 - val_loss: 1.0078 - val_accuracy: 0.8140\n",
      "Epoch 86/500\n",
      "263/264 [============================>.] - ETA: 0s - loss: 0.0447 - accuracy: 0.9815\n",
      "Epoch 00086: val_accuracy did not improve from 0.82900\n",
      "264/264 [==============================] - 6s 23ms/step - loss: 0.0447 - accuracy: 0.9815 - val_loss: 1.0399 - val_accuracy: 0.8111\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 87/500\n",
      "264/264 [==============================] - ETA: 0s - loss: 0.0440 - accuracy: 0.9814\n",
      "Epoch 00087: val_accuracy did not improve from 0.82900\n",
      "264/264 [==============================] - 6s 24ms/step - loss: 0.0440 - accuracy: 0.9814 - val_loss: 1.0494 - val_accuracy: 0.8137\n",
      "Epoch 88/500\n",
      "262/264 [============================>.] - ETA: 0s - loss: 0.0434 - accuracy: 0.9817\n",
      "Epoch 00088: val_accuracy did not improve from 0.82900\n",
      "264/264 [==============================] - 6s 23ms/step - loss: 0.0434 - accuracy: 0.9817 - val_loss: 1.0045 - val_accuracy: 0.8116\n",
      "Epoch 89/500\n",
      "263/264 [============================>.] - ETA: 0s - loss: 0.0446 - accuracy: 0.9812\n",
      "Epoch 00089: val_accuracy did not improve from 0.82900\n",
      "264/264 [==============================] - 6s 23ms/step - loss: 0.0446 - accuracy: 0.9812 - val_loss: 0.9900 - val_accuracy: 0.8139\n",
      "Epoch 90/500\n",
      "264/264 [==============================] - ETA: 0s - loss: 0.0442 - accuracy: 0.9816\n",
      "Epoch 00090: val_accuracy did not improve from 0.82900\n",
      "264/264 [==============================] - 6s 23ms/step - loss: 0.0442 - accuracy: 0.9816 - val_loss: 0.9629 - val_accuracy: 0.8120\n",
      "Epoch 91/500\n",
      "264/264 [==============================] - ETA: 0s - loss: 0.0429 - accuracy: 0.9819\n",
      "Epoch 00091: val_accuracy did not improve from 0.82900\n",
      "264/264 [==============================] - 6s 23ms/step - loss: 0.0429 - accuracy: 0.9819 - val_loss: 1.0128 - val_accuracy: 0.8137\n",
      "Epoch 92/500\n",
      "263/264 [============================>.] - ETA: 0s - loss: 0.0433 - accuracy: 0.9819\n",
      "Epoch 00092: val_accuracy did not improve from 0.82900\n",
      "264/264 [==============================] - 6s 23ms/step - loss: 0.0432 - accuracy: 0.9819 - val_loss: 1.0133 - val_accuracy: 0.8133\n",
      "Epoch 93/500\n",
      "262/264 [============================>.] - ETA: 0s - loss: 0.0435 - accuracy: 0.9815\n",
      "Epoch 00093: val_accuracy did not improve from 0.82900\n",
      "264/264 [==============================] - 6s 24ms/step - loss: 0.0434 - accuracy: 0.9815 - val_loss: 1.0125 - val_accuracy: 0.8121\n",
      "Epoch 94/500\n",
      "262/264 [============================>.] - ETA: 0s - loss: 0.0430 - accuracy: 0.9820\n",
      "Epoch 00094: val_accuracy did not improve from 0.82900\n",
      "264/264 [==============================] - 6s 23ms/step - loss: 0.0430 - accuracy: 0.9819 - val_loss: 1.0214 - val_accuracy: 0.8155\n",
      "Epoch 95/500\n",
      "264/264 [==============================] - ETA: 0s - loss: 0.0436 - accuracy: 0.9812\n",
      "Epoch 00095: val_accuracy did not improve from 0.82900\n",
      "264/264 [==============================] - 6s 23ms/step - loss: 0.0436 - accuracy: 0.9812 - val_loss: 0.9782 - val_accuracy: 0.8079\n",
      "Epoch 96/500\n",
      "264/264 [==============================] - ETA: 0s - loss: 0.0420 - accuracy: 0.9822\n",
      "Epoch 00096: val_accuracy did not improve from 0.82900\n",
      "264/264 [==============================] - 6s 22ms/step - loss: 0.0420 - accuracy: 0.9822 - val_loss: 1.0211 - val_accuracy: 0.8108\n",
      "Epoch 97/500\n",
      "264/264 [==============================] - ETA: 0s - loss: 0.0428 - accuracy: 0.9819\n",
      "Epoch 00097: val_accuracy did not improve from 0.82900\n",
      "264/264 [==============================] - 6s 23ms/step - loss: 0.0428 - accuracy: 0.9819 - val_loss: 1.0370 - val_accuracy: 0.8135\n",
      "Epoch 98/500\n",
      "262/264 [============================>.] - ETA: 0s - loss: 0.0418 - accuracy: 0.9824\n",
      "Epoch 00098: val_accuracy did not improve from 0.82900\n",
      "264/264 [==============================] - 6s 22ms/step - loss: 0.0420 - accuracy: 0.9823 - val_loss: 1.0337 - val_accuracy: 0.8143\n",
      "Epoch 99/500\n",
      "262/264 [============================>.] - ETA: 0s - loss: 0.0416 - accuracy: 0.9823\n",
      "Epoch 00099: val_accuracy did not improve from 0.82900\n",
      "264/264 [==============================] - 6s 22ms/step - loss: 0.0416 - accuracy: 0.9823 - val_loss: 1.0290 - val_accuracy: 0.8131\n",
      "Epoch 100/500\n",
      "262/264 [============================>.] - ETA: 0s - loss: 0.0423 - accuracy: 0.9820\n",
      "Epoch 00100: val_accuracy did not improve from 0.82900\n",
      "264/264 [==============================] - 6s 21ms/step - loss: 0.0423 - accuracy: 0.9821 - val_loss: 1.0017 - val_accuracy: 0.8130\n",
      "Epoch 101/500\n",
      "264/264 [==============================] - ETA: 0s - loss: 0.0412 - accuracy: 0.9825\n",
      "Epoch 00101: val_accuracy did not improve from 0.82900\n",
      "264/264 [==============================] - 6s 22ms/step - loss: 0.0412 - accuracy: 0.9825 - val_loss: 1.0587 - val_accuracy: 0.8141\n",
      "Epoch 102/500\n",
      "262/264 [============================>.] - ETA: 0s - loss: 0.0414 - accuracy: 0.9825\n",
      "Epoch 00102: val_accuracy did not improve from 0.82900\n",
      "264/264 [==============================] - 6s 22ms/step - loss: 0.0414 - accuracy: 0.9825 - val_loss: 1.0298 - val_accuracy: 0.8117\n",
      "Epoch 103/500\n",
      "264/264 [==============================] - ETA: 0s - loss: 0.0411 - accuracy: 0.9825\n",
      "Epoch 00103: val_accuracy did not improve from 0.82900\n",
      "264/264 [==============================] - 6s 23ms/step - loss: 0.0411 - accuracy: 0.9825 - val_loss: 1.0108 - val_accuracy: 0.8109\n",
      "Epoch 104/500\n",
      "263/264 [============================>.] - ETA: 0s - loss: 0.0413 - accuracy: 0.9824\n",
      "Epoch 00104: val_accuracy did not improve from 0.82900\n",
      "264/264 [==============================] - 6s 22ms/step - loss: 0.0413 - accuracy: 0.9824 - val_loss: 1.0433 - val_accuracy: 0.8143\n",
      "Epoch 105/500\n",
      "264/264 [==============================] - ETA: 0s - loss: 0.0421 - accuracy: 0.9822\n",
      "Epoch 00105: val_accuracy did not improve from 0.82900\n",
      "264/264 [==============================] - 6s 22ms/step - loss: 0.0421 - accuracy: 0.9822 - val_loss: 1.0140 - val_accuracy: 0.8105\n",
      "Epoch 106/500\n",
      "263/264 [============================>.] - ETA: 0s - loss: 0.0405 - accuracy: 0.9826\n",
      "Epoch 00106: val_accuracy did not improve from 0.82900\n",
      "264/264 [==============================] - 6s 22ms/step - loss: 0.0404 - accuracy: 0.9826 - val_loss: 1.0300 - val_accuracy: 0.8143\n",
      "Epoch 107/500\n",
      "264/264 [==============================] - ETA: 0s - loss: 0.0412 - accuracy: 0.9826\n",
      "Epoch 00107: val_accuracy did not improve from 0.82900\n",
      "264/264 [==============================] - 6s 22ms/step - loss: 0.0412 - accuracy: 0.9826 - val_loss: 1.0178 - val_accuracy: 0.8079\n",
      "Epoch 108/500\n",
      "263/264 [============================>.] - ETA: 0s - loss: 0.0397 - accuracy: 0.9832\n",
      "Epoch 00108: val_accuracy did not improve from 0.82900\n",
      "264/264 [==============================] - 6s 23ms/step - loss: 0.0397 - accuracy: 0.9832 - val_loss: 1.0303 - val_accuracy: 0.8107\n",
      "Epoch 109/500\n",
      "264/264 [==============================] - ETA: 0s - loss: 0.0412 - accuracy: 0.9827\n",
      "Epoch 00109: val_accuracy did not improve from 0.82900\n",
      "264/264 [==============================] - 6s 22ms/step - loss: 0.0412 - accuracy: 0.9827 - val_loss: 1.0724 - val_accuracy: 0.8169\n",
      "Epoch 110/500\n",
      "263/264 [============================>.] - ETA: 0s - loss: 0.0401 - accuracy: 0.9828\n",
      "Epoch 00110: val_accuracy did not improve from 0.82900\n",
      "264/264 [==============================] - 6s 23ms/step - loss: 0.0401 - accuracy: 0.9828 - val_loss: 1.0496 - val_accuracy: 0.8153\n",
      "Epoch 111/500\n",
      "264/264 [==============================] - ETA: 0s - loss: 0.0392 - accuracy: 0.9836\n",
      "Epoch 00111: val_accuracy did not improve from 0.82900\n",
      "264/264 [==============================] - 6s 22ms/step - loss: 0.0392 - accuracy: 0.9836 - val_loss: 1.1050 - val_accuracy: 0.8165\n",
      "Epoch 112/500\n",
      "263/264 [============================>.] - ETA: 0s - loss: 0.0398 - accuracy: 0.9828\n",
      "Epoch 00112: val_accuracy did not improve from 0.82900\n",
      "264/264 [==============================] - 6s 23ms/step - loss: 0.0397 - accuracy: 0.9828 - val_loss: 1.0612 - val_accuracy: 0.8133\n",
      "Epoch 113/500\n",
      "262/264 [============================>.] - ETA: 0s - loss: 0.0387 - accuracy: 0.9837\n",
      "Epoch 00113: val_accuracy did not improve from 0.82900\n",
      "264/264 [==============================] - 6s 22ms/step - loss: 0.0387 - accuracy: 0.9837 - val_loss: 1.0713 - val_accuracy: 0.8109\n",
      "Epoch 114/500\n",
      "263/264 [============================>.] - ETA: 0s - loss: 0.0396 - accuracy: 0.9830\n",
      "Epoch 00114: val_accuracy did not improve from 0.82900\n",
      "264/264 [==============================] - 6s 22ms/step - loss: 0.0397 - accuracy: 0.9830 - val_loss: 1.0551 - val_accuracy: 0.8127\n",
      "Epoch 115/500\n",
      "264/264 [==============================] - ETA: 0s - loss: 0.0397 - accuracy: 0.9832\n",
      "Epoch 00115: val_accuracy did not improve from 0.82900\n",
      "264/264 [==============================] - 6s 23ms/step - loss: 0.0397 - accuracy: 0.9832 - val_loss: 1.0575 - val_accuracy: 0.8143\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 116/500\n",
      "264/264 [==============================] - ETA: 0s - loss: 0.0392 - accuracy: 0.9831\n",
      "Epoch 00116: val_accuracy did not improve from 0.82900\n",
      "264/264 [==============================] - 6s 23ms/step - loss: 0.0392 - accuracy: 0.9831 - val_loss: 1.0644 - val_accuracy: 0.8123\n",
      "Epoch 117/500\n",
      "263/264 [============================>.] - ETA: 0s - loss: 0.0383 - accuracy: 0.9835\n",
      "Epoch 00117: val_accuracy did not improve from 0.82900\n",
      "264/264 [==============================] - 6s 22ms/step - loss: 0.0384 - accuracy: 0.9835 - val_loss: 1.0845 - val_accuracy: 0.8143\n",
      "Epoch 118/500\n",
      "264/264 [==============================] - ETA: 0s - loss: 0.0386 - accuracy: 0.9833\n",
      "Epoch 00118: val_accuracy did not improve from 0.82900\n",
      "264/264 [==============================] - 6s 22ms/step - loss: 0.0386 - accuracy: 0.9833 - val_loss: 1.0334 - val_accuracy: 0.8100\n",
      "Epoch 119/500\n",
      "262/264 [============================>.] - ETA: 0s - loss: 0.0389 - accuracy: 0.9837\n",
      "Epoch 00119: val_accuracy did not improve from 0.82900\n",
      "264/264 [==============================] - 6s 22ms/step - loss: 0.0389 - accuracy: 0.9837 - val_loss: 1.0905 - val_accuracy: 0.8156\n",
      "Epoch 120/500\n",
      "264/264 [==============================] - ETA: 0s - loss: 0.0388 - accuracy: 0.9835\n",
      "Epoch 00120: val_accuracy did not improve from 0.82900\n",
      "264/264 [==============================] - 6s 22ms/step - loss: 0.0388 - accuracy: 0.9835 - val_loss: 1.0655 - val_accuracy: 0.8125\n",
      "Epoch 121/500\n",
      "264/264 [==============================] - ETA: 0s - loss: 0.0375 - accuracy: 0.9840\n",
      "Epoch 00121: val_accuracy did not improve from 0.82900\n",
      "264/264 [==============================] - 6s 24ms/step - loss: 0.0375 - accuracy: 0.9840 - val_loss: 1.0602 - val_accuracy: 0.8149\n",
      "Epoch 122/500\n",
      "263/264 [============================>.] - ETA: 0s - loss: 0.0388 - accuracy: 0.9833\n",
      "Epoch 00122: val_accuracy did not improve from 0.82900\n",
      "264/264 [==============================] - 6s 23ms/step - loss: 0.0388 - accuracy: 0.9833 - val_loss: 1.0770 - val_accuracy: 0.8109\n",
      "Epoch 123/500\n",
      "264/264 [==============================] - ETA: 0s - loss: 0.0377 - accuracy: 0.9838\n",
      "Epoch 00123: val_accuracy did not improve from 0.82900\n",
      "264/264 [==============================] - 6s 22ms/step - loss: 0.0377 - accuracy: 0.9838 - val_loss: 1.0759 - val_accuracy: 0.8143\n",
      "Epoch 124/500\n",
      "262/264 [============================>.] - ETA: 0s - loss: 0.0383 - accuracy: 0.9838\n",
      "Epoch 00124: val_accuracy did not improve from 0.82900\n",
      "264/264 [==============================] - 6s 22ms/step - loss: 0.0382 - accuracy: 0.9838 - val_loss: 1.0684 - val_accuracy: 0.8108\n",
      "Epoch 125/500\n",
      "263/264 [============================>.] - ETA: 0s - loss: 0.0369 - accuracy: 0.9845\n",
      "Epoch 00125: val_accuracy did not improve from 0.82900\n",
      "264/264 [==============================] - 6s 23ms/step - loss: 0.0369 - accuracy: 0.9844 - val_loss: 1.1542 - val_accuracy: 0.8157\n",
      "Epoch 126/500\n",
      "262/264 [============================>.] - ETA: 0s - loss: 0.0383 - accuracy: 0.9835\n",
      "Epoch 00126: val_accuracy did not improve from 0.82900\n",
      "264/264 [==============================] - 6s 22ms/step - loss: 0.0384 - accuracy: 0.9835 - val_loss: 1.0879 - val_accuracy: 0.8140\n",
      "Epoch 127/500\n",
      "264/264 [==============================] - ETA: 0s - loss: 0.0381 - accuracy: 0.9842\n",
      "Epoch 00127: val_accuracy did not improve from 0.82900\n",
      "264/264 [==============================] - 6s 23ms/step - loss: 0.0381 - accuracy: 0.9842 - val_loss: 1.0680 - val_accuracy: 0.8169\n",
      "Epoch 128/500\n",
      "264/264 [==============================] - ETA: 0s - loss: 0.0376 - accuracy: 0.9844\n",
      "Epoch 00128: val_accuracy did not improve from 0.82900\n",
      "264/264 [==============================] - 6s 22ms/step - loss: 0.0376 - accuracy: 0.9844 - val_loss: 1.0556 - val_accuracy: 0.8130\n",
      "Epoch 129/500\n",
      "262/264 [============================>.] - ETA: 0s - loss: 0.0373 - accuracy: 0.9840\n",
      "Epoch 00129: val_accuracy did not improve from 0.82900\n",
      "264/264 [==============================] - 6s 22ms/step - loss: 0.0374 - accuracy: 0.9839 - val_loss: 1.0319 - val_accuracy: 0.8139\n",
      "Epoch 130/500\n",
      "263/264 [============================>.] - ETA: 0s - loss: 0.0366 - accuracy: 0.9842\n",
      "Epoch 00130: val_accuracy did not improve from 0.82900\n",
      "264/264 [==============================] - 6s 23ms/step - loss: 0.0366 - accuracy: 0.9841 - val_loss: 1.0928 - val_accuracy: 0.8154\n",
      "Epoch 131/500\n",
      "262/264 [============================>.] - ETA: 0s - loss: 0.0369 - accuracy: 0.9842\n",
      "Epoch 00131: val_accuracy did not improve from 0.82900\n",
      "264/264 [==============================] - 6s 23ms/step - loss: 0.0369 - accuracy: 0.9842 - val_loss: 1.0485 - val_accuracy: 0.8122\n",
      "Epoch 132/500\n",
      "262/264 [============================>.] - ETA: 0s - loss: 0.0366 - accuracy: 0.9842\n",
      "Epoch 00132: val_accuracy did not improve from 0.82900\n",
      "264/264 [==============================] - 6s 23ms/step - loss: 0.0366 - accuracy: 0.9842 - val_loss: 1.1098 - val_accuracy: 0.8146\n",
      "Epoch 133/500\n",
      "263/264 [============================>.] - ETA: 0s - loss: 0.0374 - accuracy: 0.9840\n",
      "Epoch 00133: val_accuracy did not improve from 0.82900\n",
      "264/264 [==============================] - 6s 22ms/step - loss: 0.0374 - accuracy: 0.9841 - val_loss: 1.0553 - val_accuracy: 0.8127\n",
      "Epoch 134/500\n",
      "262/264 [============================>.] - ETA: 0s - loss: 0.0371 - accuracy: 0.9842\n",
      "Epoch 00134: val_accuracy did not improve from 0.82900\n",
      "264/264 [==============================] - 6s 22ms/step - loss: 0.0371 - accuracy: 0.9842 - val_loss: 1.0772 - val_accuracy: 0.8149\n",
      "Epoch 135/500\n",
      "264/264 [==============================] - ETA: 0s - loss: 0.0365 - accuracy: 0.9844\n",
      "Epoch 00135: val_accuracy did not improve from 0.82900\n",
      "264/264 [==============================] - 6s 22ms/step - loss: 0.0365 - accuracy: 0.9844 - val_loss: 1.1067 - val_accuracy: 0.8163\n",
      "Epoch 136/500\n",
      "263/264 [============================>.] - ETA: 0s - loss: 0.0364 - accuracy: 0.9842\n",
      "Epoch 00136: val_accuracy did not improve from 0.82900\n",
      "264/264 [==============================] - 6s 22ms/step - loss: 0.0364 - accuracy: 0.9842 - val_loss: 1.0860 - val_accuracy: 0.8161\n",
      "Epoch 137/500\n",
      "264/264 [==============================] - ETA: 0s - loss: 0.0358 - accuracy: 0.9844\n",
      "Epoch 00137: val_accuracy did not improve from 0.82900\n",
      "264/264 [==============================] - 6s 23ms/step - loss: 0.0358 - accuracy: 0.9844 - val_loss: 1.0985 - val_accuracy: 0.8116\n",
      "Epoch 138/500\n",
      "264/264 [==============================] - ETA: 0s - loss: 0.0366 - accuracy: 0.9845\n",
      "Epoch 00138: val_accuracy did not improve from 0.82900\n",
      "264/264 [==============================] - 6s 23ms/step - loss: 0.0366 - accuracy: 0.9845 - val_loss: 1.0739 - val_accuracy: 0.8123\n",
      "Epoch 139/500\n",
      "262/264 [============================>.] - ETA: 0s - loss: 0.0368 - accuracy: 0.9841\n",
      "Epoch 00139: val_accuracy did not improve from 0.82900\n",
      "264/264 [==============================] - 6s 23ms/step - loss: 0.0367 - accuracy: 0.9841 - val_loss: 1.0306 - val_accuracy: 0.8095\n",
      "Epoch 140/500\n",
      "263/264 [============================>.] - ETA: 0s - loss: 0.0365 - accuracy: 0.9842\n",
      "Epoch 00140: val_accuracy did not improve from 0.82900\n",
      "264/264 [==============================] - 6s 23ms/step - loss: 0.0365 - accuracy: 0.9842 - val_loss: 1.0835 - val_accuracy: 0.8102\n",
      "Epoch 141/500\n",
      "264/264 [==============================] - ETA: 0s - loss: 0.0355 - accuracy: 0.9847\n",
      "Epoch 00141: val_accuracy did not improve from 0.82900\n",
      "264/264 [==============================] - 6s 24ms/step - loss: 0.0355 - accuracy: 0.9847 - val_loss: 1.1425 - val_accuracy: 0.8139\n",
      "Epoch 142/500\n",
      "263/264 [============================>.] - ETA: 0s - loss: 0.0361 - accuracy: 0.9844\n",
      "Epoch 00142: val_accuracy did not improve from 0.82900\n",
      "264/264 [==============================] - 6s 24ms/step - loss: 0.0361 - accuracy: 0.9844 - val_loss: 1.1381 - val_accuracy: 0.8119\n",
      "Epoch 143/500\n",
      "264/264 [==============================] - ETA: 0s - loss: 0.0353 - accuracy: 0.9848\n",
      "Epoch 00143: val_accuracy did not improve from 0.82900\n",
      "264/264 [==============================] - 6s 23ms/step - loss: 0.0353 - accuracy: 0.9848 - val_loss: 1.1277 - val_accuracy: 0.8141\n",
      "Epoch 144/500\n",
      "264/264 [==============================] - ETA: 0s - loss: 0.0358 - accuracy: 0.9846\n",
      "Epoch 00144: val_accuracy did not improve from 0.82900\n",
      "264/264 [==============================] - 6s 24ms/step - loss: 0.0358 - accuracy: 0.9846 - val_loss: 1.0921 - val_accuracy: 0.8147\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 145/500\n",
      "262/264 [============================>.] - ETA: 0s - loss: 0.0352 - accuracy: 0.9851\n",
      "Epoch 00145: val_accuracy did not improve from 0.82900\n",
      "264/264 [==============================] - 6s 23ms/step - loss: 0.0352 - accuracy: 0.9851 - val_loss: 1.1447 - val_accuracy: 0.8157\n",
      "Epoch 146/500\n",
      "264/264 [==============================] - ETA: 0s - loss: 0.0358 - accuracy: 0.9844\n",
      "Epoch 00146: val_accuracy did not improve from 0.82900\n",
      "264/264 [==============================] - 6s 23ms/step - loss: 0.0358 - accuracy: 0.9844 - val_loss: 1.0906 - val_accuracy: 0.8139\n",
      "Epoch 147/500\n",
      "262/264 [============================>.] - ETA: 0s - loss: 0.0352 - accuracy: 0.9850\n",
      "Epoch 00147: val_accuracy did not improve from 0.82900\n",
      "264/264 [==============================] - 6s 23ms/step - loss: 0.0353 - accuracy: 0.9850 - val_loss: 1.1244 - val_accuracy: 0.8169\n",
      "Epoch 148/500\n",
      "262/264 [============================>.] - ETA: 0s - loss: 0.0347 - accuracy: 0.9852\n",
      "Epoch 00148: val_accuracy did not improve from 0.82900\n",
      "264/264 [==============================] - 6s 24ms/step - loss: 0.0347 - accuracy: 0.9851 - val_loss: 1.0757 - val_accuracy: 0.8140\n",
      "Epoch 149/500\n",
      "264/264 [==============================] - ETA: 0s - loss: 0.0359 - accuracy: 0.9847\n",
      "Epoch 00149: val_accuracy did not improve from 0.82900\n",
      "264/264 [==============================] - 6s 24ms/step - loss: 0.0359 - accuracy: 0.9847 - val_loss: 1.0814 - val_accuracy: 0.8133\n",
      "Epoch 150/500\n",
      "263/264 [============================>.] - ETA: 0s - loss: 0.0358 - accuracy: 0.9848\n",
      "Epoch 00150: val_accuracy did not improve from 0.82900\n",
      "264/264 [==============================] - 6s 24ms/step - loss: 0.0359 - accuracy: 0.9848 - val_loss: 1.1169 - val_accuracy: 0.8134\n",
      "Epoch 151/500\n",
      "263/264 [============================>.] - ETA: 0s - loss: 0.0340 - accuracy: 0.9852\n",
      "Epoch 00151: val_accuracy did not improve from 0.82900\n",
      "264/264 [==============================] - 6s 24ms/step - loss: 0.0340 - accuracy: 0.9852 - val_loss: 1.1369 - val_accuracy: 0.8139\n",
      "Epoch 152/500\n",
      "262/264 [============================>.] - ETA: 0s - loss: 0.0351 - accuracy: 0.9847\n",
      "Epoch 00152: val_accuracy did not improve from 0.82900\n",
      "264/264 [==============================] - 6s 23ms/step - loss: 0.0350 - accuracy: 0.9847 - val_loss: 1.0941 - val_accuracy: 0.8135\n",
      "Epoch 153/500\n",
      "264/264 [==============================] - ETA: 0s - loss: 0.0344 - accuracy: 0.9852\n",
      "Epoch 00153: val_accuracy did not improve from 0.82900\n",
      "264/264 [==============================] - 6s 24ms/step - loss: 0.0344 - accuracy: 0.9852 - val_loss: 1.1311 - val_accuracy: 0.8120\n",
      "Epoch 154/500\n",
      "263/264 [============================>.] - ETA: 0s - loss: 0.0340 - accuracy: 0.9853\n",
      "Epoch 00154: val_accuracy did not improve from 0.82900\n",
      "264/264 [==============================] - 6s 23ms/step - loss: 0.0340 - accuracy: 0.9853 - val_loss: 1.1325 - val_accuracy: 0.8129\n",
      "Epoch 155/500\n",
      "262/264 [============================>.] - ETA: 0s - loss: 0.0342 - accuracy: 0.9850\n",
      "Epoch 00155: val_accuracy did not improve from 0.82900\n",
      "264/264 [==============================] - 6s 23ms/step - loss: 0.0342 - accuracy: 0.9851 - val_loss: 1.1169 - val_accuracy: 0.8139\n",
      "Epoch 156/500\n",
      "264/264 [==============================] - ETA: 0s - loss: 0.0349 - accuracy: 0.9848\n",
      "Epoch 00156: val_accuracy did not improve from 0.82900\n",
      "264/264 [==============================] - 6s 23ms/step - loss: 0.0349 - accuracy: 0.9848 - val_loss: 1.0724 - val_accuracy: 0.8129\n",
      "Epoch 157/500\n",
      "263/264 [============================>.] - ETA: 0s - loss: 0.0344 - accuracy: 0.9853\n",
      "Epoch 00157: val_accuracy did not improve from 0.82900\n",
      "264/264 [==============================] - 6s 23ms/step - loss: 0.0344 - accuracy: 0.9853 - val_loss: 1.1177 - val_accuracy: 0.8134\n",
      "Epoch 158/500\n",
      "262/264 [============================>.] - ETA: 0s - loss: 0.0341 - accuracy: 0.9850\n",
      "Epoch 00158: val_accuracy did not improve from 0.82900\n",
      "264/264 [==============================] - 6s 23ms/step - loss: 0.0341 - accuracy: 0.9850 - val_loss: 1.1014 - val_accuracy: 0.8081\n",
      "Epoch 159/500\n",
      "263/264 [============================>.] - ETA: 0s - loss: 0.0341 - accuracy: 0.9851\n",
      "Epoch 00159: val_accuracy did not improve from 0.82900\n",
      "264/264 [==============================] - 6s 23ms/step - loss: 0.0341 - accuracy: 0.9851 - val_loss: 1.1192 - val_accuracy: 0.8136\n",
      "Epoch 160/500\n",
      "262/264 [============================>.] - ETA: 0s - loss: 0.0335 - accuracy: 0.9855\n",
      "Epoch 00160: val_accuracy did not improve from 0.82900\n",
      "264/264 [==============================] - 6s 23ms/step - loss: 0.0335 - accuracy: 0.9855 - val_loss: 1.1766 - val_accuracy: 0.8130\n",
      "Epoch 161/500\n",
      "264/264 [==============================] - ETA: 0s - loss: 0.0342 - accuracy: 0.9853\n",
      "Epoch 00161: val_accuracy did not improve from 0.82900\n",
      "264/264 [==============================] - 6s 23ms/step - loss: 0.0342 - accuracy: 0.9853 - val_loss: 1.0877 - val_accuracy: 0.8121\n",
      "Epoch 162/500\n",
      "264/264 [==============================] - ETA: 0s - loss: 0.0346 - accuracy: 0.9853\n",
      "Epoch 00162: val_accuracy did not improve from 0.82900\n",
      "264/264 [==============================] - 6s 24ms/step - loss: 0.0346 - accuracy: 0.9853 - val_loss: 1.0861 - val_accuracy: 0.8107\n",
      "Epoch 163/500\n",
      "263/264 [============================>.] - ETA: 0s - loss: 0.0340 - accuracy: 0.9852\n",
      "Epoch 00163: val_accuracy did not improve from 0.82900\n",
      "264/264 [==============================] - 6s 24ms/step - loss: 0.0340 - accuracy: 0.9852 - val_loss: 1.1424 - val_accuracy: 0.8120\n",
      "Epoch 164/500\n",
      "264/264 [==============================] - ETA: 0s - loss: 0.0337 - accuracy: 0.9856\n",
      "Epoch 00164: val_accuracy did not improve from 0.82900\n",
      "264/264 [==============================] - 6s 23ms/step - loss: 0.0337 - accuracy: 0.9856 - val_loss: 1.1129 - val_accuracy: 0.8111\n",
      "Epoch 165/500\n",
      "262/264 [============================>.] - ETA: 0s - loss: 0.0342 - accuracy: 0.9855\n",
      "Epoch 00165: val_accuracy did not improve from 0.82900\n",
      "264/264 [==============================] - 6s 23ms/step - loss: 0.0341 - accuracy: 0.9855 - val_loss: 1.1149 - val_accuracy: 0.8136\n",
      "Epoch 166/500\n",
      "263/264 [============================>.] - ETA: 0s - loss: 0.0334 - accuracy: 0.9856\n",
      "Epoch 00166: val_accuracy did not improve from 0.82900\n",
      "264/264 [==============================] - 6s 22ms/step - loss: 0.0334 - accuracy: 0.9856 - val_loss: 1.1434 - val_accuracy: 0.8126\n",
      "Epoch 167/500\n",
      "263/264 [============================>.] - ETA: 0s - loss: 0.0343 - accuracy: 0.9854\n",
      "Epoch 00167: val_accuracy did not improve from 0.82900\n",
      "264/264 [==============================] - 6s 22ms/step - loss: 0.0343 - accuracy: 0.9854 - val_loss: 1.1178 - val_accuracy: 0.8135\n",
      "Epoch 168/500\n",
      "263/264 [============================>.] - ETA: 0s - loss: 0.0335 - accuracy: 0.9854\n",
      "Epoch 00168: val_accuracy did not improve from 0.82900\n",
      "264/264 [==============================] - 6s 22ms/step - loss: 0.0336 - accuracy: 0.9854 - val_loss: 1.1390 - val_accuracy: 0.8135\n",
      "Epoch 169/500\n",
      "264/264 [==============================] - ETA: 0s - loss: 0.0332 - accuracy: 0.9855\n",
      "Epoch 00169: val_accuracy did not improve from 0.82900\n",
      "264/264 [==============================] - 6s 23ms/step - loss: 0.0332 - accuracy: 0.9855 - val_loss: 1.1097 - val_accuracy: 0.8123\n",
      "Epoch 170/500\n",
      "263/264 [============================>.] - ETA: 0s - loss: 0.0327 - accuracy: 0.9859\n",
      "Epoch 00170: val_accuracy did not improve from 0.82900\n",
      "264/264 [==============================] - 6s 24ms/step - loss: 0.0327 - accuracy: 0.9859 - val_loss: 1.0895 - val_accuracy: 0.8118\n",
      "Epoch 171/500\n",
      "262/264 [============================>.] - ETA: 0s - loss: 0.0339 - accuracy: 0.9853\n",
      "Epoch 00171: val_accuracy did not improve from 0.82900\n",
      "264/264 [==============================] - 6s 23ms/step - loss: 0.0340 - accuracy: 0.9853 - val_loss: 1.0836 - val_accuracy: 0.8145\n",
      "Epoch 172/500\n",
      "263/264 [============================>.] - ETA: 0s - loss: 0.0332 - accuracy: 0.9857\n",
      "Epoch 00172: val_accuracy did not improve from 0.82900\n",
      "264/264 [==============================] - 6s 23ms/step - loss: 0.0332 - accuracy: 0.9858 - val_loss: 1.1352 - val_accuracy: 0.8121\n",
      "Epoch 173/500\n",
      "264/264 [==============================] - ETA: 0s - loss: 0.0326 - accuracy: 0.9858\n",
      "Epoch 00173: val_accuracy did not improve from 0.82900\n",
      "264/264 [==============================] - 6s 23ms/step - loss: 0.0326 - accuracy: 0.9858 - val_loss: 1.1760 - val_accuracy: 0.8134\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 174/500\n",
      "264/264 [==============================] - ETA: 0s - loss: 0.0339 - accuracy: 0.9852\n",
      "Epoch 00174: val_accuracy did not improve from 0.82900\n",
      "264/264 [==============================] - 6s 23ms/step - loss: 0.0339 - accuracy: 0.9852 - val_loss: 1.1033 - val_accuracy: 0.8109\n",
      "Epoch 175/500\n",
      "264/264 [==============================] - ETA: 0s - loss: 0.0331 - accuracy: 0.9857\n",
      "Epoch 00175: val_accuracy did not improve from 0.82900\n",
      "264/264 [==============================] - 6s 23ms/step - loss: 0.0331 - accuracy: 0.9857 - val_loss: 1.1018 - val_accuracy: 0.8091\n",
      "Epoch 176/500\n",
      "263/264 [============================>.] - ETA: 0s - loss: 0.0329 - accuracy: 0.9857\n",
      "Epoch 00176: val_accuracy did not improve from 0.82900\n",
      "264/264 [==============================] - 6s 23ms/step - loss: 0.0329 - accuracy: 0.9857 - val_loss: 1.1578 - val_accuracy: 0.8102\n",
      "Epoch 177/500\n",
      "262/264 [============================>.] - ETA: 0s - loss: 0.0319 - accuracy: 0.9860\n",
      "Epoch 00177: val_accuracy did not improve from 0.82900\n",
      "264/264 [==============================] - 6s 23ms/step - loss: 0.0320 - accuracy: 0.9860 - val_loss: 1.1602 - val_accuracy: 0.8078\n",
      "Epoch 178/500\n",
      "263/264 [============================>.] - ETA: 0s - loss: 0.0326 - accuracy: 0.9856\n",
      "Epoch 00178: val_accuracy did not improve from 0.82900\n",
      "264/264 [==============================] - 6s 24ms/step - loss: 0.0326 - accuracy: 0.9856 - val_loss: 1.1382 - val_accuracy: 0.8099\n",
      "Epoch 179/500\n",
      "263/264 [============================>.] - ETA: 0s - loss: 0.0329 - accuracy: 0.9861\n",
      "Epoch 00179: val_accuracy did not improve from 0.82900\n",
      "264/264 [==============================] - 6s 22ms/step - loss: 0.0329 - accuracy: 0.9860 - val_loss: 1.1330 - val_accuracy: 0.8114\n",
      "Epoch 180/500\n",
      "264/264 [==============================] - ETA: 0s - loss: 0.0331 - accuracy: 0.9856\n",
      "Epoch 00180: val_accuracy did not improve from 0.82900\n",
      "264/264 [==============================] - 6s 23ms/step - loss: 0.0331 - accuracy: 0.9856 - val_loss: 1.1321 - val_accuracy: 0.8142\n",
      "Epoch 181/500\n",
      "262/264 [============================>.] - ETA: 0s - loss: 0.0323 - accuracy: 0.9861\n",
      "Epoch 00181: val_accuracy did not improve from 0.82900\n",
      "264/264 [==============================] - 6s 23ms/step - loss: 0.0324 - accuracy: 0.9861 - val_loss: 1.1541 - val_accuracy: 0.8115\n",
      "Epoch 182/500\n",
      "262/264 [============================>.] - ETA: 0s - loss: 0.0322 - accuracy: 0.9862\n",
      "Epoch 00182: val_accuracy did not improve from 0.82900\n",
      "264/264 [==============================] - 6s 23ms/step - loss: 0.0321 - accuracy: 0.9863 - val_loss: 1.1587 - val_accuracy: 0.8117\n",
      "Epoch 183/500\n",
      "263/264 [============================>.] - ETA: 0s - loss: 0.0318 - accuracy: 0.9864\n",
      "Epoch 00183: val_accuracy did not improve from 0.82900\n",
      "264/264 [==============================] - 6s 23ms/step - loss: 0.0318 - accuracy: 0.9863 - val_loss: 1.1889 - val_accuracy: 0.8111\n",
      "Epoch 184/500\n",
      "262/264 [============================>.] - ETA: 0s - loss: 0.0322 - accuracy: 0.9861\n",
      "Epoch 00184: val_accuracy did not improve from 0.82900\n",
      "264/264 [==============================] - 6s 23ms/step - loss: 0.0322 - accuracy: 0.9861 - val_loss: 1.1558 - val_accuracy: 0.8104\n",
      "Epoch 185/500\n",
      "264/264 [==============================] - ETA: 0s - loss: 0.0321 - accuracy: 0.9862\n",
      "Epoch 00185: val_accuracy did not improve from 0.82900\n",
      "264/264 [==============================] - 6s 25ms/step - loss: 0.0321 - accuracy: 0.9862 - val_loss: 1.1272 - val_accuracy: 0.8111\n",
      "Epoch 186/500\n",
      "263/264 [============================>.] - ETA: 0s - loss: 0.0322 - accuracy: 0.9857\n",
      "Epoch 00186: val_accuracy did not improve from 0.82900\n",
      "264/264 [==============================] - 6s 24ms/step - loss: 0.0322 - accuracy: 0.9857 - val_loss: 1.1984 - val_accuracy: 0.8115\n",
      "Epoch 187/500\n",
      "262/264 [============================>.] - ETA: 0s - loss: 0.0332 - accuracy: 0.9857\n",
      "Epoch 00187: val_accuracy did not improve from 0.82900\n",
      "264/264 [==============================] - 6s 23ms/step - loss: 0.0331 - accuracy: 0.9857 - val_loss: 1.1622 - val_accuracy: 0.8138\n",
      "Epoch 188/500\n",
      "264/264 [==============================] - ETA: 0s - loss: 0.0323 - accuracy: 0.9858\n",
      "Epoch 00188: val_accuracy did not improve from 0.82900\n",
      "264/264 [==============================] - 6s 23ms/step - loss: 0.0323 - accuracy: 0.9858 - val_loss: 1.1499 - val_accuracy: 0.8079\n",
      "Epoch 189/500\n",
      "262/264 [============================>.] - ETA: 0s - loss: 0.0319 - accuracy: 0.9861\n",
      "Epoch 00189: val_accuracy did not improve from 0.82900\n",
      "264/264 [==============================] - 6s 24ms/step - loss: 0.0320 - accuracy: 0.9861 - val_loss: 1.1145 - val_accuracy: 0.8116\n",
      "Epoch 190/500\n",
      "263/264 [============================>.] - ETA: 0s - loss: 0.0314 - accuracy: 0.9859\n",
      "Epoch 00190: val_accuracy did not improve from 0.82900\n",
      "264/264 [==============================] - 6s 23ms/step - loss: 0.0314 - accuracy: 0.9859 - val_loss: 1.1495 - val_accuracy: 0.8103\n",
      "Epoch 191/500\n",
      "263/264 [============================>.] - ETA: 0s - loss: 0.0319 - accuracy: 0.9862\n",
      "Epoch 00191: val_accuracy did not improve from 0.82900\n",
      "264/264 [==============================] - 6s 23ms/step - loss: 0.0319 - accuracy: 0.9862 - val_loss: 1.1519 - val_accuracy: 0.8110\n",
      "Epoch 192/500\n",
      "263/264 [============================>.] - ETA: 0s - loss: 0.0329 - accuracy: 0.9859\n",
      "Epoch 00192: val_accuracy did not improve from 0.82900\n",
      "264/264 [==============================] - 6s 23ms/step - loss: 0.0329 - accuracy: 0.9859 - val_loss: 1.1465 - val_accuracy: 0.8113\n",
      "Epoch 193/500\n",
      "264/264 [==============================] - ETA: 0s - loss: 0.0309 - accuracy: 0.9866\n",
      "Epoch 00193: val_accuracy did not improve from 0.82900\n",
      "264/264 [==============================] - 6s 23ms/step - loss: 0.0309 - accuracy: 0.9866 - val_loss: 1.1308 - val_accuracy: 0.8122\n",
      "Epoch 194/500\n",
      "264/264 [==============================] - ETA: 0s - loss: 0.0311 - accuracy: 0.9867\n",
      "Epoch 00194: val_accuracy did not improve from 0.82900\n",
      "264/264 [==============================] - 6s 23ms/step - loss: 0.0311 - accuracy: 0.9867 - val_loss: 1.1621 - val_accuracy: 0.8107\n",
      "Epoch 195/500\n",
      "263/264 [============================>.] - ETA: 0s - loss: 0.0311 - accuracy: 0.9865\n",
      "Epoch 00195: val_accuracy did not improve from 0.82900\n",
      "264/264 [==============================] - 6s 23ms/step - loss: 0.0312 - accuracy: 0.9864 - val_loss: 1.1589 - val_accuracy: 0.8110\n",
      "Epoch 196/500\n",
      "262/264 [============================>.] - ETA: 0s - loss: 0.0311 - accuracy: 0.9865\n",
      "Epoch 00196: val_accuracy did not improve from 0.82900\n",
      "264/264 [==============================] - 6s 24ms/step - loss: 0.0312 - accuracy: 0.9865 - val_loss: 1.1311 - val_accuracy: 0.8125\n",
      "Epoch 197/500\n",
      "262/264 [============================>.] - ETA: 0s - loss: 0.0316 - accuracy: 0.9859\n",
      "Epoch 00197: val_accuracy did not improve from 0.82900\n",
      "264/264 [==============================] - 6s 23ms/step - loss: 0.0316 - accuracy: 0.9859 - val_loss: 1.1940 - val_accuracy: 0.8151\n",
      "Epoch 198/500\n",
      "264/264 [==============================] - ETA: 0s - loss: 0.0314 - accuracy: 0.9862\n",
      "Epoch 00198: val_accuracy did not improve from 0.82900\n",
      "264/264 [==============================] - 6s 23ms/step - loss: 0.0314 - accuracy: 0.9862 - val_loss: 1.1538 - val_accuracy: 0.8126\n",
      "Epoch 199/500\n",
      "262/264 [============================>.] - ETA: 0s - loss: 0.0312 - accuracy: 0.9864\n",
      "Epoch 00199: val_accuracy did not improve from 0.82900\n",
      "264/264 [==============================] - 6s 23ms/step - loss: 0.0312 - accuracy: 0.9865 - val_loss: 1.1756 - val_accuracy: 0.8128\n",
      "Epoch 200/500\n",
      "264/264 [==============================] - ETA: 0s - loss: 0.0314 - accuracy: 0.9864\n",
      "Epoch 00200: val_accuracy did not improve from 0.82900\n",
      "264/264 [==============================] - 6s 22ms/step - loss: 0.0314 - accuracy: 0.9864 - val_loss: 1.1544 - val_accuracy: 0.8113\n",
      "Epoch 201/500\n",
      "262/264 [============================>.] - ETA: 0s - loss: 0.0314 - accuracy: 0.9861\n",
      "Epoch 00201: val_accuracy did not improve from 0.82900\n",
      "264/264 [==============================] - 6s 22ms/step - loss: 0.0314 - accuracy: 0.9860 - val_loss: 1.1530 - val_accuracy: 0.8098\n",
      "Epoch 202/500\n",
      "262/264 [============================>.] - ETA: 0s - loss: 0.0300 - accuracy: 0.9868\n",
      "Epoch 00202: val_accuracy did not improve from 0.82900\n",
      "264/264 [==============================] - 6s 22ms/step - loss: 0.0300 - accuracy: 0.9869 - val_loss: 1.2520 - val_accuracy: 0.8158\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 203/500\n",
      "264/264 [==============================] - ETA: 0s - loss: 0.0312 - accuracy: 0.9867\n",
      "Epoch 00203: val_accuracy did not improve from 0.82900\n",
      "264/264 [==============================] - 6s 23ms/step - loss: 0.0312 - accuracy: 0.9867 - val_loss: 1.1565 - val_accuracy: 0.8118\n",
      "Epoch 204/500\n",
      "262/264 [============================>.] - ETA: 0s - loss: 0.0320 - accuracy: 0.9863\n",
      "Epoch 00204: val_accuracy did not improve from 0.82900\n",
      "264/264 [==============================] - 6s 23ms/step - loss: 0.0319 - accuracy: 0.9864 - val_loss: 1.1315 - val_accuracy: 0.8123\n",
      "Epoch 205/500\n",
      "262/264 [============================>.] - ETA: 0s - loss: 0.0306 - accuracy: 0.9865\n",
      "Epoch 00205: val_accuracy did not improve from 0.82900\n",
      "264/264 [==============================] - 6s 23ms/step - loss: 0.0306 - accuracy: 0.9865 - val_loss: 1.1915 - val_accuracy: 0.8114\n",
      "Epoch 206/500\n",
      "263/264 [============================>.] - ETA: 0s - loss: 0.0308 - accuracy: 0.9864\n",
      "Epoch 00206: val_accuracy did not improve from 0.82900\n",
      "264/264 [==============================] - 6s 23ms/step - loss: 0.0308 - accuracy: 0.9864 - val_loss: 1.2080 - val_accuracy: 0.8126\n",
      "Epoch 207/500\n",
      "262/264 [============================>.] - ETA: 0s - loss: 0.0319 - accuracy: 0.9862\n",
      "Epoch 00207: val_accuracy did not improve from 0.82900\n",
      "264/264 [==============================] - 6s 22ms/step - loss: 0.0319 - accuracy: 0.9862 - val_loss: 1.1332 - val_accuracy: 0.8095\n",
      "Epoch 208/500\n",
      "263/264 [============================>.] - ETA: 0s - loss: 0.0297 - accuracy: 0.9871\n",
      "Epoch 00208: val_accuracy did not improve from 0.82900\n",
      "264/264 [==============================] - 6s 23ms/step - loss: 0.0296 - accuracy: 0.9871 - val_loss: 1.2079 - val_accuracy: 0.8120\n",
      "Epoch 209/500\n",
      "264/264 [==============================] - ETA: 0s - loss: 0.0310 - accuracy: 0.9865\n",
      "Epoch 00209: val_accuracy did not improve from 0.82900\n",
      "264/264 [==============================] - 6s 22ms/step - loss: 0.0310 - accuracy: 0.9865 - val_loss: 1.1541 - val_accuracy: 0.8109\n",
      "Epoch 210/500\n",
      "264/264 [==============================] - ETA: 0s - loss: 0.0317 - accuracy: 0.9861\n",
      "Epoch 00210: val_accuracy did not improve from 0.82900\n",
      "264/264 [==============================] - 6s 22ms/step - loss: 0.0317 - accuracy: 0.9861 - val_loss: 1.1349 - val_accuracy: 0.8125\n",
      "Epoch 211/500\n",
      "263/264 [============================>.] - ETA: 0s - loss: 0.0313 - accuracy: 0.9863\n",
      "Epoch 00211: val_accuracy did not improve from 0.82900\n",
      "264/264 [==============================] - 6s 22ms/step - loss: 0.0313 - accuracy: 0.9863 - val_loss: 1.1326 - val_accuracy: 0.8118\n",
      "Epoch 212/500\n",
      "264/264 [==============================] - ETA: 0s - loss: 0.0306 - accuracy: 0.9865\n",
      "Epoch 00212: val_accuracy did not improve from 0.82900\n",
      "264/264 [==============================] - 6s 23ms/step - loss: 0.0306 - accuracy: 0.9865 - val_loss: 1.1654 - val_accuracy: 0.8113\n",
      "Epoch 213/500\n",
      "263/264 [============================>.] - ETA: 0s - loss: 0.0302 - accuracy: 0.9871\n",
      "Epoch 00213: val_accuracy did not improve from 0.82900\n",
      "264/264 [==============================] - 6s 23ms/step - loss: 0.0302 - accuracy: 0.9871 - val_loss: 1.1679 - val_accuracy: 0.8109\n",
      "Epoch 214/500\n",
      "264/264 [==============================] - ETA: 0s - loss: 0.0310 - accuracy: 0.9864\n",
      "Epoch 00214: val_accuracy did not improve from 0.82900\n",
      "264/264 [==============================] - 6s 22ms/step - loss: 0.0310 - accuracy: 0.9864 - val_loss: 1.1594 - val_accuracy: 0.8092\n",
      "Epoch 215/500\n",
      "262/264 [============================>.] - ETA: 0s - loss: 0.0297 - accuracy: 0.9871\n",
      "Epoch 00215: val_accuracy did not improve from 0.82900\n",
      "264/264 [==============================] - 6s 22ms/step - loss: 0.0298 - accuracy: 0.9871 - val_loss: 1.1499 - val_accuracy: 0.8091\n",
      "Epoch 216/500\n",
      "262/264 [============================>.] - ETA: 0s - loss: 0.0302 - accuracy: 0.9867\n",
      "Epoch 00216: val_accuracy did not improve from 0.82900\n",
      "264/264 [==============================] - 6s 23ms/step - loss: 0.0301 - accuracy: 0.9867 - val_loss: 1.1864 - val_accuracy: 0.8115\n",
      "Epoch 217/500\n",
      "262/264 [============================>.] - ETA: 0s - loss: 0.0297 - accuracy: 0.9870\n",
      "Epoch 00217: val_accuracy did not improve from 0.82900\n",
      "264/264 [==============================] - 6s 23ms/step - loss: 0.0297 - accuracy: 0.9870 - val_loss: 1.1754 - val_accuracy: 0.8093\n",
      "Epoch 218/500\n",
      "262/264 [============================>.] - ETA: 0s - loss: 0.0312 - accuracy: 0.9865\n",
      "Epoch 00218: val_accuracy did not improve from 0.82900\n",
      "264/264 [==============================] - 6s 23ms/step - loss: 0.0312 - accuracy: 0.9865 - val_loss: 1.1663 - val_accuracy: 0.8105\n",
      "Epoch 219/500\n",
      "262/264 [============================>.] - ETA: 0s - loss: 0.0298 - accuracy: 0.9869\n",
      "Epoch 00219: val_accuracy did not improve from 0.82900\n",
      "264/264 [==============================] - 6s 22ms/step - loss: 0.0300 - accuracy: 0.9868 - val_loss: 1.1850 - val_accuracy: 0.8097\n",
      "Epoch 220/500\n",
      "264/264 [==============================] - ETA: 0s - loss: 0.0296 - accuracy: 0.9871\n",
      "Epoch 00220: val_accuracy did not improve from 0.82900\n",
      "264/264 [==============================] - 6s 23ms/step - loss: 0.0296 - accuracy: 0.9871 - val_loss: 1.2499 - val_accuracy: 0.8149\n",
      "Epoch 221/500\n",
      "263/264 [============================>.] - ETA: 0s - loss: 0.0299 - accuracy: 0.9871\n",
      "Epoch 00221: val_accuracy did not improve from 0.82900\n",
      "264/264 [==============================] - 6s 22ms/step - loss: 0.0299 - accuracy: 0.9871 - val_loss: 1.2121 - val_accuracy: 0.8101\n",
      "Epoch 222/500\n",
      "262/264 [============================>.] - ETA: 0s - loss: 0.0300 - accuracy: 0.9870\n",
      "Epoch 00222: val_accuracy did not improve from 0.82900\n",
      "264/264 [==============================] - 6s 22ms/step - loss: 0.0300 - accuracy: 0.9871 - val_loss: 1.1479 - val_accuracy: 0.8085\n",
      "Epoch 223/500\n",
      "264/264 [==============================] - ETA: 0s - loss: 0.0305 - accuracy: 0.9866\n",
      "Epoch 00223: val_accuracy did not improve from 0.82900\n",
      "264/264 [==============================] - 6s 22ms/step - loss: 0.0305 - accuracy: 0.9866 - val_loss: 1.1724 - val_accuracy: 0.8095\n",
      "Epoch 224/500\n",
      "263/264 [============================>.] - ETA: 0s - loss: 0.0302 - accuracy: 0.9869\n",
      "Epoch 00224: val_accuracy did not improve from 0.82900\n",
      "264/264 [==============================] - 6s 22ms/step - loss: 0.0302 - accuracy: 0.9869 - val_loss: 1.2053 - val_accuracy: 0.8114\n",
      "Epoch 225/500\n",
      "264/264 [==============================] - ETA: 0s - loss: 0.0301 - accuracy: 0.9869\n",
      "Epoch 00225: val_accuracy did not improve from 0.82900\n",
      "264/264 [==============================] - 6s 22ms/step - loss: 0.0301 - accuracy: 0.9869 - val_loss: 1.2181 - val_accuracy: 0.8117\n",
      "Epoch 226/500\n",
      "264/264 [==============================] - ETA: 0s - loss: 0.0304 - accuracy: 0.9865\n",
      "Epoch 00226: val_accuracy did not improve from 0.82900\n",
      "264/264 [==============================] - 6s 22ms/step - loss: 0.0304 - accuracy: 0.9865 - val_loss: 1.1319 - val_accuracy: 0.8096\n",
      "Epoch 227/500\n",
      "262/264 [============================>.] - ETA: 0s - loss: 0.0299 - accuracy: 0.9867\n",
      "Epoch 00227: val_accuracy did not improve from 0.82900\n",
      "264/264 [==============================] - 6s 22ms/step - loss: 0.0299 - accuracy: 0.9867 - val_loss: 1.1900 - val_accuracy: 0.8109\n",
      "Epoch 228/500\n",
      "262/264 [============================>.] - ETA: 0s - loss: 0.0301 - accuracy: 0.9869\n",
      "Epoch 00228: val_accuracy did not improve from 0.82900\n",
      "264/264 [==============================] - 6s 22ms/step - loss: 0.0301 - accuracy: 0.9869 - val_loss: 1.2048 - val_accuracy: 0.8099\n",
      "Epoch 229/500\n",
      "262/264 [============================>.] - ETA: 0s - loss: 0.0299 - accuracy: 0.9869\n",
      "Epoch 00229: val_accuracy did not improve from 0.82900\n",
      "264/264 [==============================] - 6s 22ms/step - loss: 0.0299 - accuracy: 0.9869 - val_loss: 1.1952 - val_accuracy: 0.8095\n",
      "Epoch 230/500\n",
      "264/264 [==============================] - ETA: 0s - loss: 0.0300 - accuracy: 0.9865\n",
      "Epoch 00230: val_accuracy did not improve from 0.82900\n",
      "264/264 [==============================] - 6s 22ms/step - loss: 0.0300 - accuracy: 0.9865 - val_loss: 1.1774 - val_accuracy: 0.8118\n",
      "Epoch 231/500\n",
      "263/264 [============================>.] - ETA: 0s - loss: 0.0294 - accuracy: 0.9868\n",
      "Epoch 00231: val_accuracy did not improve from 0.82900\n",
      "264/264 [==============================] - 6s 22ms/step - loss: 0.0294 - accuracy: 0.9869 - val_loss: 1.2050 - val_accuracy: 0.8137\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 232/500\n",
      "263/264 [============================>.] - ETA: 0s - loss: 0.0289 - accuracy: 0.9870\n",
      "Epoch 00232: val_accuracy did not improve from 0.82900\n",
      "264/264 [==============================] - 6s 22ms/step - loss: 0.0289 - accuracy: 0.9870 - val_loss: 1.2401 - val_accuracy: 0.8093\n",
      "Epoch 233/500\n",
      "262/264 [============================>.] - ETA: 0s - loss: 0.0297 - accuracy: 0.9872\n",
      "Epoch 00233: val_accuracy did not improve from 0.82900\n",
      "264/264 [==============================] - 6s 22ms/step - loss: 0.0297 - accuracy: 0.9872 - val_loss: 1.1735 - val_accuracy: 0.8077\n",
      "Epoch 234/500\n",
      "262/264 [============================>.] - ETA: 0s - loss: 0.0296 - accuracy: 0.9870\n",
      "Epoch 00234: val_accuracy did not improve from 0.82900\n",
      "264/264 [==============================] - 6s 22ms/step - loss: 0.0295 - accuracy: 0.9870 - val_loss: 1.1932 - val_accuracy: 0.8117\n",
      "Epoch 235/500\n",
      "264/264 [==============================] - ETA: 0s - loss: 0.0296 - accuracy: 0.9873\n",
      "Epoch 00235: val_accuracy did not improve from 0.82900\n",
      "264/264 [==============================] - 6s 22ms/step - loss: 0.0296 - accuracy: 0.9873 - val_loss: 1.1693 - val_accuracy: 0.8070\n",
      "Epoch 236/500\n",
      "263/264 [============================>.] - ETA: 0s - loss: 0.0290 - accuracy: 0.9871\n",
      "Epoch 00236: val_accuracy did not improve from 0.82900\n",
      "264/264 [==============================] - 6s 22ms/step - loss: 0.0291 - accuracy: 0.9871 - val_loss: 1.2592 - val_accuracy: 0.8096\n",
      "Epoch 237/500\n",
      "264/264 [==============================] - ETA: 0s - loss: 0.0297 - accuracy: 0.9870\n",
      "Epoch 00237: val_accuracy did not improve from 0.82900\n",
      "264/264 [==============================] - 6s 23ms/step - loss: 0.0297 - accuracy: 0.9870 - val_loss: 1.2110 - val_accuracy: 0.8089\n",
      "Epoch 238/500\n",
      "264/264 [==============================] - ETA: 0s - loss: 0.0289 - accuracy: 0.9872\n",
      "Epoch 00238: val_accuracy did not improve from 0.82900\n",
      "264/264 [==============================] - 6s 23ms/step - loss: 0.0289 - accuracy: 0.9872 - val_loss: 1.2052 - val_accuracy: 0.8121\n",
      "Epoch 239/500\n",
      "264/264 [==============================] - ETA: 0s - loss: 0.0294 - accuracy: 0.9872\n",
      "Epoch 00239: val_accuracy did not improve from 0.82900\n",
      "264/264 [==============================] - 6s 23ms/step - loss: 0.0294 - accuracy: 0.9872 - val_loss: 1.1930 - val_accuracy: 0.8085\n",
      "Epoch 240/500\n",
      "264/264 [==============================] - ETA: 0s - loss: 0.0289 - accuracy: 0.9872\n",
      "Epoch 00240: val_accuracy did not improve from 0.82900\n",
      "264/264 [==============================] - 6s 23ms/step - loss: 0.0289 - accuracy: 0.9872 - val_loss: 1.2038 - val_accuracy: 0.8099\n",
      "Epoch 241/500\n",
      "263/264 [============================>.] - ETA: 0s - loss: 0.0295 - accuracy: 0.9875\n",
      "Epoch 00241: val_accuracy did not improve from 0.82900\n",
      "264/264 [==============================] - 6s 23ms/step - loss: 0.0295 - accuracy: 0.9875 - val_loss: 1.2054 - val_accuracy: 0.8096\n",
      "Epoch 242/500\n",
      "263/264 [============================>.] - ETA: 0s - loss: 0.0304 - accuracy: 0.9868\n",
      "Epoch 00242: val_accuracy did not improve from 0.82900\n",
      "264/264 [==============================] - 6s 22ms/step - loss: 0.0304 - accuracy: 0.9867 - val_loss: 1.2059 - val_accuracy: 0.8143\n",
      "Epoch 243/500\n",
      "263/264 [============================>.] - ETA: 0s - loss: 0.0295 - accuracy: 0.9870\n",
      "Epoch 00243: val_accuracy did not improve from 0.82900\n",
      "264/264 [==============================] - 6s 23ms/step - loss: 0.0295 - accuracy: 0.9871 - val_loss: 1.2068 - val_accuracy: 0.8118\n",
      "Epoch 244/500\n",
      "264/264 [==============================] - ETA: 0s - loss: 0.0294 - accuracy: 0.9873\n",
      "Epoch 00244: val_accuracy did not improve from 0.82900\n",
      "264/264 [==============================] - 6s 22ms/step - loss: 0.0294 - accuracy: 0.9873 - val_loss: 1.1930 - val_accuracy: 0.8139\n",
      "Epoch 245/500\n",
      "264/264 [==============================] - ETA: 0s - loss: 0.0293 - accuracy: 0.9873\n",
      "Epoch 00245: val_accuracy did not improve from 0.82900\n",
      "264/264 [==============================] - 6s 23ms/step - loss: 0.0293 - accuracy: 0.9873 - val_loss: 1.1928 - val_accuracy: 0.8129\n",
      "Epoch 246/500\n",
      "262/264 [============================>.] - ETA: 0s - loss: 0.0289 - accuracy: 0.9872\n",
      "Epoch 00246: val_accuracy did not improve from 0.82900\n",
      "264/264 [==============================] - 6s 23ms/step - loss: 0.0288 - accuracy: 0.9872 - val_loss: 1.1781 - val_accuracy: 0.8085\n",
      "Epoch 247/500\n",
      "264/264 [==============================] - ETA: 0s - loss: 0.0286 - accuracy: 0.9878\n",
      "Epoch 00247: val_accuracy did not improve from 0.82900\n",
      "264/264 [==============================] - 6s 22ms/step - loss: 0.0286 - accuracy: 0.9878 - val_loss: 1.1580 - val_accuracy: 0.8104\n",
      "Epoch 248/500\n",
      "264/264 [==============================] - ETA: 0s - loss: 0.0290 - accuracy: 0.9873\n",
      "Epoch 00248: val_accuracy did not improve from 0.82900\n",
      "264/264 [==============================] - 6s 23ms/step - loss: 0.0290 - accuracy: 0.9873 - val_loss: 1.2361 - val_accuracy: 0.8120\n",
      "Epoch 249/500\n",
      "264/264 [==============================] - ETA: 0s - loss: 0.0293 - accuracy: 0.9869\n",
      "Epoch 00249: val_accuracy did not improve from 0.82900\n",
      "264/264 [==============================] - 6s 22ms/step - loss: 0.0293 - accuracy: 0.9869 - val_loss: 1.2408 - val_accuracy: 0.8118\n",
      "Epoch 250/500\n",
      "262/264 [============================>.] - ETA: 0s - loss: 0.0291 - accuracy: 0.9872\n",
      "Epoch 00250: val_accuracy did not improve from 0.82900\n",
      "264/264 [==============================] - 6s 23ms/step - loss: 0.0292 - accuracy: 0.9872 - val_loss: 1.2011 - val_accuracy: 0.8137\n",
      "Epoch 251/500\n",
      "264/264 [==============================] - ETA: 0s - loss: 0.0287 - accuracy: 0.9874\n",
      "Epoch 00251: val_accuracy did not improve from 0.82900\n",
      "264/264 [==============================] - 6s 22ms/step - loss: 0.0287 - accuracy: 0.9874 - val_loss: 1.1860 - val_accuracy: 0.8103\n",
      "Epoch 252/500\n",
      "264/264 [==============================] - ETA: 0s - loss: 0.0298 - accuracy: 0.9869\n",
      "Epoch 00252: val_accuracy did not improve from 0.82900\n",
      "264/264 [==============================] - 6s 22ms/step - loss: 0.0298 - accuracy: 0.9869 - val_loss: 1.1634 - val_accuracy: 0.8104\n",
      "Epoch 253/500\n",
      "263/264 [============================>.] - ETA: 0s - loss: 0.0285 - accuracy: 0.9876\n",
      "Epoch 00253: val_accuracy did not improve from 0.82900\n",
      "264/264 [==============================] - 6s 22ms/step - loss: 0.0285 - accuracy: 0.9875 - val_loss: 1.2490 - val_accuracy: 0.8117\n",
      "Epoch 254/500\n",
      "262/264 [============================>.] - ETA: 0s - loss: 0.0281 - accuracy: 0.9876\n",
      "Epoch 00254: val_accuracy did not improve from 0.82900\n",
      "264/264 [==============================] - 6s 22ms/step - loss: 0.0281 - accuracy: 0.9875 - val_loss: 1.2143 - val_accuracy: 0.8097\n",
      "Epoch 255/500\n",
      "263/264 [============================>.] - ETA: 0s - loss: 0.0295 - accuracy: 0.9871\n",
      "Epoch 00255: val_accuracy did not improve from 0.82900\n",
      "264/264 [==============================] - 6s 23ms/step - loss: 0.0295 - accuracy: 0.9871 - val_loss: 1.1950 - val_accuracy: 0.8107\n",
      "Epoch 256/500\n",
      "262/264 [============================>.] - ETA: 0s - loss: 0.0286 - accuracy: 0.9872\n",
      "Epoch 00256: val_accuracy did not improve from 0.82900\n",
      "264/264 [==============================] - 6s 22ms/step - loss: 0.0286 - accuracy: 0.9871 - val_loss: 1.2012 - val_accuracy: 0.8076\n",
      "Epoch 257/500\n",
      "262/264 [============================>.] - ETA: 0s - loss: 0.0284 - accuracy: 0.9874\n",
      "Epoch 00257: val_accuracy did not improve from 0.82900\n",
      "264/264 [==============================] - 6s 23ms/step - loss: 0.0284 - accuracy: 0.9873 - val_loss: 1.1971 - val_accuracy: 0.8138\n",
      "Epoch 258/500\n",
      "262/264 [============================>.] - ETA: 0s - loss: 0.0288 - accuracy: 0.9871\n",
      "Epoch 00258: val_accuracy did not improve from 0.82900\n",
      "264/264 [==============================] - 6s 23ms/step - loss: 0.0288 - accuracy: 0.9871 - val_loss: 1.1688 - val_accuracy: 0.8131\n",
      "Epoch 259/500\n",
      "263/264 [============================>.] - ETA: 0s - loss: 0.0287 - accuracy: 0.9874\n",
      "Epoch 00259: val_accuracy did not improve from 0.82900\n",
      "264/264 [==============================] - 6s 23ms/step - loss: 0.0287 - accuracy: 0.9874 - val_loss: 1.1718 - val_accuracy: 0.8057\n",
      "Epoch 260/500\n",
      "264/264 [==============================] - ETA: 0s - loss: 0.0287 - accuracy: 0.9873\n",
      "Epoch 00260: val_accuracy did not improve from 0.82900\n",
      "264/264 [==============================] - 6s 22ms/step - loss: 0.0287 - accuracy: 0.9873 - val_loss: 1.2091 - val_accuracy: 0.8103\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 261/500\n",
      "263/264 [============================>.] - ETA: 0s - loss: 0.0282 - accuracy: 0.9874\n",
      "Epoch 00261: val_accuracy did not improve from 0.82900\n",
      "264/264 [==============================] - 6s 23ms/step - loss: 0.0281 - accuracy: 0.9874 - val_loss: 1.2510 - val_accuracy: 0.8125\n",
      "Epoch 262/500\n",
      "263/264 [============================>.] - ETA: 0s - loss: 0.0287 - accuracy: 0.9874\n",
      "Epoch 00262: val_accuracy did not improve from 0.82900\n",
      "264/264 [==============================] - 6s 24ms/step - loss: 0.0286 - accuracy: 0.9875 - val_loss: 1.2455 - val_accuracy: 0.8119\n",
      "Epoch 263/500\n",
      "262/264 [============================>.] - ETA: 0s - loss: 0.0283 - accuracy: 0.9878\n",
      "Epoch 00263: val_accuracy did not improve from 0.82900\n",
      "264/264 [==============================] - 6s 23ms/step - loss: 0.0283 - accuracy: 0.9878 - val_loss: 1.2112 - val_accuracy: 0.8146\n",
      "Epoch 264/500\n",
      "263/264 [============================>.] - ETA: 0s - loss: 0.0280 - accuracy: 0.9879\n",
      "Epoch 00264: val_accuracy did not improve from 0.82900\n",
      "264/264 [==============================] - 6s 23ms/step - loss: 0.0280 - accuracy: 0.9879 - val_loss: 1.2122 - val_accuracy: 0.8117\n",
      "Epoch 265/500\n",
      "264/264 [==============================] - ETA: 0s - loss: 0.0285 - accuracy: 0.9871\n",
      "Epoch 00265: val_accuracy did not improve from 0.82900\n",
      "264/264 [==============================] - 6s 23ms/step - loss: 0.0285 - accuracy: 0.9871 - val_loss: 1.2911 - val_accuracy: 0.8116\n",
      "Epoch 266/500\n",
      "264/264 [==============================] - ETA: 0s - loss: 0.0284 - accuracy: 0.9873\n",
      "Epoch 00266: val_accuracy did not improve from 0.82900\n",
      "264/264 [==============================] - 6s 23ms/step - loss: 0.0284 - accuracy: 0.9873 - val_loss: 1.2568 - val_accuracy: 0.8123\n",
      "Epoch 267/500\n",
      "264/264 [==============================] - ETA: 0s - loss: 0.0282 - accuracy: 0.9872\n",
      "Epoch 00267: val_accuracy did not improve from 0.82900\n",
      "264/264 [==============================] - 6s 23ms/step - loss: 0.0282 - accuracy: 0.9872 - val_loss: 1.2091 - val_accuracy: 0.8108\n",
      "Epoch 268/500\n",
      "264/264 [==============================] - ETA: 0s - loss: 0.0290 - accuracy: 0.9871\n",
      "Epoch 00268: val_accuracy did not improve from 0.82900\n",
      "264/264 [==============================] - 6s 22ms/step - loss: 0.0290 - accuracy: 0.9871 - val_loss: 1.1724 - val_accuracy: 0.8103\n",
      "Epoch 269/500\n",
      "262/264 [============================>.] - ETA: 0s - loss: 0.0285 - accuracy: 0.9876\n",
      "Epoch 00269: val_accuracy did not improve from 0.82900\n",
      "264/264 [==============================] - 6s 22ms/step - loss: 0.0285 - accuracy: 0.9876 - val_loss: 1.2024 - val_accuracy: 0.8135\n",
      "Epoch 270/500\n",
      "263/264 [============================>.] - ETA: 0s - loss: 0.0285 - accuracy: 0.9873\n",
      "Epoch 00270: val_accuracy did not improve from 0.82900\n",
      "264/264 [==============================] - 6s 23ms/step - loss: 0.0285 - accuracy: 0.9873 - val_loss: 1.2295 - val_accuracy: 0.8083\n",
      "Epoch 271/500\n",
      "264/264 [==============================] - ETA: 0s - loss: 0.0284 - accuracy: 0.9875\n",
      "Epoch 00271: val_accuracy did not improve from 0.82900\n",
      "264/264 [==============================] - 6s 23ms/step - loss: 0.0284 - accuracy: 0.9875 - val_loss: 1.2578 - val_accuracy: 0.8112\n",
      "Epoch 272/500\n",
      "263/264 [============================>.] - ETA: 0s - loss: 0.0282 - accuracy: 0.9875\n",
      "Epoch 00272: val_accuracy did not improve from 0.82900\n",
      "264/264 [==============================] - 6s 22ms/step - loss: 0.0282 - accuracy: 0.9876 - val_loss: 1.1646 - val_accuracy: 0.8124\n",
      "Epoch 273/500\n",
      "263/264 [============================>.] - ETA: 0s - loss: 0.0271 - accuracy: 0.9879\n",
      "Epoch 00273: val_accuracy did not improve from 0.82900\n",
      "264/264 [==============================] - 6s 22ms/step - loss: 0.0271 - accuracy: 0.9879 - val_loss: 1.2353 - val_accuracy: 0.8093\n",
      "Epoch 274/500\n",
      "263/264 [============================>.] - ETA: 0s - loss: 0.0278 - accuracy: 0.9879\n",
      "Epoch 00274: val_accuracy did not improve from 0.82900\n",
      "264/264 [==============================] - 6s 22ms/step - loss: 0.0277 - accuracy: 0.9879 - val_loss: 1.2036 - val_accuracy: 0.8119\n",
      "Epoch 275/500\n",
      "263/264 [============================>.] - ETA: 0s - loss: 0.0286 - accuracy: 0.9874\n",
      "Epoch 00275: val_accuracy did not improve from 0.82900\n",
      "264/264 [==============================] - 6s 22ms/step - loss: 0.0286 - accuracy: 0.9874 - val_loss: 1.2125 - val_accuracy: 0.8097\n",
      "Epoch 276/500\n",
      "263/264 [============================>.] - ETA: 0s - loss: 0.0289 - accuracy: 0.9871\n",
      "Epoch 00276: val_accuracy did not improve from 0.82900\n",
      "264/264 [==============================] - 6s 23ms/step - loss: 0.0290 - accuracy: 0.9871 - val_loss: 1.1763 - val_accuracy: 0.8105\n",
      "Epoch 277/500\n",
      "264/264 [==============================] - ETA: 0s - loss: 0.0275 - accuracy: 0.9880\n",
      "Epoch 00277: val_accuracy did not improve from 0.82900\n",
      "264/264 [==============================] - 6s 22ms/step - loss: 0.0275 - accuracy: 0.9880 - val_loss: 1.2565 - val_accuracy: 0.8101\n",
      "Epoch 278/500\n",
      "263/264 [============================>.] - ETA: 0s - loss: 0.0273 - accuracy: 0.9879\n",
      "Epoch 00278: val_accuracy did not improve from 0.82900\n",
      "264/264 [==============================] - 6s 23ms/step - loss: 0.0273 - accuracy: 0.9879 - val_loss: 1.2786 - val_accuracy: 0.8120\n",
      "Epoch 279/500\n",
      "263/264 [============================>.] - ETA: 0s - loss: 0.0274 - accuracy: 0.9880\n",
      "Epoch 00279: val_accuracy did not improve from 0.82900\n",
      "264/264 [==============================] - 6s 22ms/step - loss: 0.0274 - accuracy: 0.9880 - val_loss: 1.2241 - val_accuracy: 0.8105\n",
      "Epoch 280/500\n",
      "264/264 [==============================] - ETA: 0s - loss: 0.0281 - accuracy: 0.9873\n",
      "Epoch 00280: val_accuracy did not improve from 0.82900\n",
      "264/264 [==============================] - 6s 22ms/step - loss: 0.0281 - accuracy: 0.9873 - val_loss: 1.1710 - val_accuracy: 0.8088\n",
      "Epoch 281/500\n",
      "263/264 [============================>.] - ETA: 0s - loss: 0.0272 - accuracy: 0.9880\n",
      "Epoch 00281: val_accuracy did not improve from 0.82900\n",
      "264/264 [==============================] - 6s 22ms/step - loss: 0.0273 - accuracy: 0.9880 - val_loss: 1.2460 - val_accuracy: 0.8116\n",
      "Epoch 282/500\n",
      "262/264 [============================>.] - ETA: 0s - loss: 0.0277 - accuracy: 0.9876\n",
      "Epoch 00282: val_accuracy did not improve from 0.82900\n",
      "264/264 [==============================] - 6s 23ms/step - loss: 0.0277 - accuracy: 0.9875 - val_loss: 1.2244 - val_accuracy: 0.8099\n",
      "Epoch 283/500\n",
      "263/264 [============================>.] - ETA: 0s - loss: 0.0280 - accuracy: 0.9874\n",
      "Epoch 00283: val_accuracy did not improve from 0.82900\n",
      "264/264 [==============================] - 6s 23ms/step - loss: 0.0280 - accuracy: 0.9873 - val_loss: 1.2153 - val_accuracy: 0.8072\n",
      "Epoch 284/500\n",
      "263/264 [============================>.] - ETA: 0s - loss: 0.0277 - accuracy: 0.9878\n",
      "Epoch 00284: val_accuracy did not improve from 0.82900\n",
      "264/264 [==============================] - 6s 23ms/step - loss: 0.0276 - accuracy: 0.9878 - val_loss: 1.2570 - val_accuracy: 0.8129\n",
      "Epoch 285/500\n",
      "262/264 [============================>.] - ETA: 0s - loss: 0.0278 - accuracy: 0.9877\n",
      "Epoch 00285: val_accuracy did not improve from 0.82900\n",
      "264/264 [==============================] - 6s 22ms/step - loss: 0.0278 - accuracy: 0.9877 - val_loss: 1.1788 - val_accuracy: 0.8105\n",
      "Epoch 286/500\n",
      "263/264 [============================>.] - ETA: 0s - loss: 0.0282 - accuracy: 0.9875\n",
      "Epoch 00286: val_accuracy did not improve from 0.82900\n",
      "264/264 [==============================] - 6s 23ms/step - loss: 0.0283 - accuracy: 0.9875 - val_loss: 1.1803 - val_accuracy: 0.8104\n",
      "Epoch 287/500\n",
      "263/264 [============================>.] - ETA: 0s - loss: 0.0275 - accuracy: 0.9876\n",
      "Epoch 00287: val_accuracy did not improve from 0.82900\n",
      "264/264 [==============================] - 6s 22ms/step - loss: 0.0275 - accuracy: 0.9876 - val_loss: 1.2334 - val_accuracy: 0.8116\n",
      "Epoch 288/500\n",
      "262/264 [============================>.] - ETA: 0s - loss: 0.0283 - accuracy: 0.9876\n",
      "Epoch 00288: val_accuracy did not improve from 0.82900\n",
      "264/264 [==============================] - 6s 22ms/step - loss: 0.0283 - accuracy: 0.9876 - val_loss: 1.1823 - val_accuracy: 0.8105\n",
      "Epoch 289/500\n",
      "263/264 [============================>.] - ETA: 0s - loss: 0.0280 - accuracy: 0.9877\n",
      "Epoch 00289: val_accuracy did not improve from 0.82900\n",
      "264/264 [==============================] - 6s 23ms/step - loss: 0.0280 - accuracy: 0.9877 - val_loss: 1.2577 - val_accuracy: 0.8097\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 290/500\n",
      "262/264 [============================>.] - ETA: 0s - loss: 0.0281 - accuracy: 0.9876\n",
      "Epoch 00290: val_accuracy did not improve from 0.82900\n",
      "264/264 [==============================] - 6s 23ms/step - loss: 0.0281 - accuracy: 0.9876 - val_loss: 1.2150 - val_accuracy: 0.8109\n",
      "Epoch 291/500\n",
      "264/264 [==============================] - ETA: 0s - loss: 0.0270 - accuracy: 0.9881\n",
      "Epoch 00291: val_accuracy did not improve from 0.82900\n",
      "264/264 [==============================] - 6s 22ms/step - loss: 0.0270 - accuracy: 0.9881 - val_loss: 1.2973 - val_accuracy: 0.8124\n",
      "Epoch 292/500\n",
      "262/264 [============================>.] - ETA: 0s - loss: 0.0278 - accuracy: 0.9876\n",
      "Epoch 00292: val_accuracy did not improve from 0.82900\n",
      "264/264 [==============================] - 6s 22ms/step - loss: 0.0278 - accuracy: 0.9876 - val_loss: 1.2260 - val_accuracy: 0.8118\n",
      "Epoch 293/500\n",
      "262/264 [============================>.] - ETA: 0s - loss: 0.0284 - accuracy: 0.9876\n",
      "Epoch 00293: val_accuracy did not improve from 0.82900\n",
      "264/264 [==============================] - 6s 23ms/step - loss: 0.0283 - accuracy: 0.9876 - val_loss: 1.2075 - val_accuracy: 0.8101\n",
      "Epoch 294/500\n",
      "264/264 [==============================] - ETA: 0s - loss: 0.0281 - accuracy: 0.9876\n",
      "Epoch 00294: val_accuracy did not improve from 0.82900\n",
      "264/264 [==============================] - 6s 22ms/step - loss: 0.0281 - accuracy: 0.9876 - val_loss: 1.2347 - val_accuracy: 0.8117\n",
      "Epoch 295/500\n",
      "262/264 [============================>.] - ETA: 0s - loss: 0.0280 - accuracy: 0.9878\n",
      "Epoch 00295: val_accuracy did not improve from 0.82900\n",
      "264/264 [==============================] - 6s 22ms/step - loss: 0.0280 - accuracy: 0.9878 - val_loss: 1.2361 - val_accuracy: 0.8101\n",
      "Epoch 296/500\n",
      "263/264 [============================>.] - ETA: 0s - loss: 0.0273 - accuracy: 0.9880\n",
      "Epoch 00296: val_accuracy did not improve from 0.82900\n",
      "264/264 [==============================] - 6s 22ms/step - loss: 0.0273 - accuracy: 0.9880 - val_loss: 1.2235 - val_accuracy: 0.8121\n",
      "Epoch 297/500\n",
      "263/264 [============================>.] - ETA: 0s - loss: 0.0272 - accuracy: 0.9881\n",
      "Epoch 00297: val_accuracy did not improve from 0.82900\n",
      "264/264 [==============================] - 6s 22ms/step - loss: 0.0272 - accuracy: 0.9881 - val_loss: 1.2734 - val_accuracy: 0.8139\n",
      "Epoch 298/500\n",
      "262/264 [============================>.] - ETA: 0s - loss: 0.0272 - accuracy: 0.9876\n",
      "Epoch 00298: val_accuracy did not improve from 0.82900\n",
      "264/264 [==============================] - 6s 23ms/step - loss: 0.0271 - accuracy: 0.9877 - val_loss: 1.1784 - val_accuracy: 0.8113\n",
      "Epoch 299/500\n",
      "263/264 [============================>.] - ETA: 0s - loss: 0.0272 - accuracy: 0.9880\n",
      "Epoch 00299: val_accuracy did not improve from 0.82900\n",
      "264/264 [==============================] - 6s 22ms/step - loss: 0.0272 - accuracy: 0.9880 - val_loss: 1.2062 - val_accuracy: 0.8113\n",
      "Epoch 300/500\n",
      "264/264 [==============================] - ETA: 0s - loss: 0.0268 - accuracy: 0.9882\n",
      "Epoch 00300: val_accuracy did not improve from 0.82900\n",
      "264/264 [==============================] - 6s 23ms/step - loss: 0.0268 - accuracy: 0.9882 - val_loss: 1.2029 - val_accuracy: 0.8083\n",
      "Epoch 301/500\n",
      "264/264 [==============================] - ETA: 0s - loss: 0.0284 - accuracy: 0.9876\n",
      "Epoch 00301: val_accuracy did not improve from 0.82900\n",
      "264/264 [==============================] - 6s 22ms/step - loss: 0.0284 - accuracy: 0.9876 - val_loss: 1.1920 - val_accuracy: 0.8125\n",
      "Epoch 302/500\n",
      "262/264 [============================>.] - ETA: 0s - loss: 0.0272 - accuracy: 0.9880\n",
      "Epoch 00302: val_accuracy did not improve from 0.82900\n",
      "264/264 [==============================] - 6s 21ms/step - loss: 0.0271 - accuracy: 0.9880 - val_loss: 1.2204 - val_accuracy: 0.8116\n",
      "Epoch 303/500\n",
      "263/264 [============================>.] - ETA: 0s - loss: 0.0283 - accuracy: 0.9877\n",
      "Epoch 00303: val_accuracy did not improve from 0.82900\n",
      "264/264 [==============================] - 6s 22ms/step - loss: 0.0284 - accuracy: 0.9877 - val_loss: 1.2294 - val_accuracy: 0.8101\n",
      "Epoch 304/500\n",
      "263/264 [============================>.] - ETA: 0s - loss: 0.0267 - accuracy: 0.9881\n",
      "Epoch 00304: val_accuracy did not improve from 0.82900\n",
      "264/264 [==============================] - 6s 23ms/step - loss: 0.0267 - accuracy: 0.9881 - val_loss: 1.2632 - val_accuracy: 0.8127\n",
      "Epoch 305/500\n",
      "262/264 [============================>.] - ETA: 0s - loss: 0.0274 - accuracy: 0.9883\n",
      "Epoch 00305: val_accuracy did not improve from 0.82900\n",
      "264/264 [==============================] - 6s 22ms/step - loss: 0.0273 - accuracy: 0.9883 - val_loss: 1.1963 - val_accuracy: 0.8113\n",
      "Epoch 306/500\n",
      "264/264 [==============================] - ETA: 0s - loss: 0.0277 - accuracy: 0.9877\n",
      "Epoch 00306: val_accuracy did not improve from 0.82900\n",
      "264/264 [==============================] - 6s 22ms/step - loss: 0.0277 - accuracy: 0.9877 - val_loss: 1.2719 - val_accuracy: 0.8144\n",
      "Epoch 307/500\n",
      "262/264 [============================>.] - ETA: 0s - loss: 0.0269 - accuracy: 0.9879\n",
      "Epoch 00307: val_accuracy did not improve from 0.82900\n",
      "264/264 [==============================] - 6s 22ms/step - loss: 0.0270 - accuracy: 0.9878 - val_loss: 1.2318 - val_accuracy: 0.8116\n",
      "Epoch 308/500\n",
      "264/264 [==============================] - ETA: 0s - loss: 0.0273 - accuracy: 0.9879\n",
      "Epoch 00308: val_accuracy did not improve from 0.82900\n",
      "264/264 [==============================] - 6s 21ms/step - loss: 0.0273 - accuracy: 0.9879 - val_loss: 1.2125 - val_accuracy: 0.8117\n",
      "Epoch 309/500\n",
      "264/264 [==============================] - ETA: 0s - loss: 0.0270 - accuracy: 0.9883\n",
      "Epoch 00309: val_accuracy did not improve from 0.82900\n",
      "264/264 [==============================] - 6s 22ms/step - loss: 0.0270 - accuracy: 0.9883 - val_loss: 1.1846 - val_accuracy: 0.8123\n",
      "Epoch 310/500\n",
      "262/264 [============================>.] - ETA: 0s - loss: 0.0266 - accuracy: 0.9884\n",
      "Epoch 00310: val_accuracy did not improve from 0.82900\n",
      "264/264 [==============================] - 6s 22ms/step - loss: 0.0266 - accuracy: 0.9884 - val_loss: 1.2436 - val_accuracy: 0.8087\n",
      "Epoch 311/500\n",
      "263/264 [============================>.] - ETA: 0s - loss: 0.0273 - accuracy: 0.9879\n",
      "Epoch 00311: val_accuracy did not improve from 0.82900\n",
      "264/264 [==============================] - 6s 22ms/step - loss: 0.0273 - accuracy: 0.9879 - val_loss: 1.2386 - val_accuracy: 0.8106\n",
      "Epoch 312/500\n",
      "263/264 [============================>.] - ETA: 0s - loss: 0.0268 - accuracy: 0.9882\n",
      "Epoch 00312: val_accuracy did not improve from 0.82900\n",
      "264/264 [==============================] - 6s 22ms/step - loss: 0.0269 - accuracy: 0.9882 - val_loss: 1.2480 - val_accuracy: 0.8119\n",
      "Epoch 313/500\n",
      "262/264 [============================>.] - ETA: 0s - loss: 0.0275 - accuracy: 0.9879\n",
      "Epoch 00313: val_accuracy did not improve from 0.82900\n",
      "264/264 [==============================] - 6s 22ms/step - loss: 0.0275 - accuracy: 0.9879 - val_loss: 1.2277 - val_accuracy: 0.8141\n",
      "Epoch 314/500\n",
      "264/264 [==============================] - ETA: 0s - loss: 0.0273 - accuracy: 0.9877\n",
      "Epoch 00314: val_accuracy did not improve from 0.82900\n",
      "264/264 [==============================] - 6s 22ms/step - loss: 0.0273 - accuracy: 0.9877 - val_loss: 1.1841 - val_accuracy: 0.8110\n",
      "Epoch 315/500\n",
      "264/264 [==============================] - ETA: 0s - loss: 0.0272 - accuracy: 0.9879\n",
      "Epoch 00315: val_accuracy did not improve from 0.82900\n",
      "264/264 [==============================] - 6s 22ms/step - loss: 0.0272 - accuracy: 0.9879 - val_loss: 1.2843 - val_accuracy: 0.8128\n",
      "Epoch 316/500\n",
      "264/264 [==============================] - ETA: 0s - loss: 0.0272 - accuracy: 0.9881\n",
      "Epoch 00316: val_accuracy did not improve from 0.82900\n",
      "264/264 [==============================] - 6s 22ms/step - loss: 0.0272 - accuracy: 0.9881 - val_loss: 1.2454 - val_accuracy: 0.8125\n",
      "Epoch 317/500\n",
      "264/264 [==============================] - ETA: 0s - loss: 0.0263 - accuracy: 0.9886\n",
      "Epoch 00317: val_accuracy did not improve from 0.82900\n",
      "264/264 [==============================] - 6s 22ms/step - loss: 0.0263 - accuracy: 0.9886 - val_loss: 1.2859 - val_accuracy: 0.8124\n",
      "Epoch 318/500\n",
      "263/264 [============================>.] - ETA: 0s - loss: 0.0263 - accuracy: 0.9884\n",
      "Epoch 00318: val_accuracy did not improve from 0.82900\n",
      "264/264 [==============================] - 6s 22ms/step - loss: 0.0263 - accuracy: 0.9883 - val_loss: 1.2452 - val_accuracy: 0.8105\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 319/500\n",
      "262/264 [============================>.] - ETA: 0s - loss: 0.0269 - accuracy: 0.9881\n",
      "Epoch 00319: val_accuracy did not improve from 0.82900\n",
      "264/264 [==============================] - 6s 22ms/step - loss: 0.0268 - accuracy: 0.9881 - val_loss: 1.2335 - val_accuracy: 0.8106\n",
      "Epoch 320/500\n",
      "263/264 [============================>.] - ETA: 0s - loss: 0.0266 - accuracy: 0.9880\n",
      "Epoch 00320: val_accuracy did not improve from 0.82900\n",
      "264/264 [==============================] - 6s 22ms/step - loss: 0.0266 - accuracy: 0.9880 - val_loss: 1.2547 - val_accuracy: 0.8079\n",
      "Epoch 321/500\n",
      "264/264 [==============================] - ETA: 0s - loss: 0.0271 - accuracy: 0.9878\n",
      "Epoch 00321: val_accuracy did not improve from 0.82900\n",
      "264/264 [==============================] - 6s 22ms/step - loss: 0.0271 - accuracy: 0.9878 - val_loss: 1.3052 - val_accuracy: 0.8092\n",
      "Epoch 322/500\n",
      "262/264 [============================>.] - ETA: 0s - loss: 0.0268 - accuracy: 0.9882\n",
      "Epoch 00322: val_accuracy did not improve from 0.82900\n",
      "264/264 [==============================] - 6s 22ms/step - loss: 0.0268 - accuracy: 0.9882 - val_loss: 1.1983 - val_accuracy: 0.8109\n",
      "Epoch 323/500\n",
      "264/264 [==============================] - ETA: 0s - loss: 0.0274 - accuracy: 0.9877\n",
      "Epoch 00323: val_accuracy did not improve from 0.82900\n",
      "264/264 [==============================] - 6s 22ms/step - loss: 0.0274 - accuracy: 0.9877 - val_loss: 1.2629 - val_accuracy: 0.8117\n",
      "Epoch 324/500\n",
      "264/264 [==============================] - ETA: 0s - loss: 0.0269 - accuracy: 0.9881\n",
      "Epoch 00324: val_accuracy did not improve from 0.82900\n",
      "264/264 [==============================] - 6s 22ms/step - loss: 0.0269 - accuracy: 0.9881 - val_loss: 1.2798 - val_accuracy: 0.8104\n",
      "Epoch 325/500\n",
      "263/264 [============================>.] - ETA: 0s - loss: 0.0265 - accuracy: 0.9884\n",
      "Epoch 00325: val_accuracy did not improve from 0.82900\n",
      "264/264 [==============================] - 6s 22ms/step - loss: 0.0265 - accuracy: 0.9884 - val_loss: 1.2702 - val_accuracy: 0.8087\n",
      "Epoch 326/500\n",
      "263/264 [============================>.] - ETA: 0s - loss: 0.0266 - accuracy: 0.9883\n",
      "Epoch 00326: val_accuracy did not improve from 0.82900\n",
      "264/264 [==============================] - 6s 21ms/step - loss: 0.0266 - accuracy: 0.9883 - val_loss: 1.2261 - val_accuracy: 0.8097\n",
      "Epoch 327/500\n",
      "263/264 [============================>.] - ETA: 0s - loss: 0.0267 - accuracy: 0.9881\n",
      "Epoch 00327: val_accuracy did not improve from 0.82900\n",
      "264/264 [==============================] - 6s 22ms/step - loss: 0.0266 - accuracy: 0.9881 - val_loss: 1.2486 - val_accuracy: 0.8091\n",
      "Epoch 328/500\n",
      "262/264 [============================>.] - ETA: 0s - loss: 0.0267 - accuracy: 0.9883\n",
      "Epoch 00328: val_accuracy did not improve from 0.82900\n",
      "264/264 [==============================] - 6s 21ms/step - loss: 0.0267 - accuracy: 0.9883 - val_loss: 1.2237 - val_accuracy: 0.8109\n",
      "Epoch 329/500\n",
      "263/264 [============================>.] - ETA: 0s - loss: 0.0265 - accuracy: 0.9881\n",
      "Epoch 00329: val_accuracy did not improve from 0.82900\n",
      "264/264 [==============================] - 6s 22ms/step - loss: 0.0265 - accuracy: 0.9881 - val_loss: 1.2304 - val_accuracy: 0.8109\n",
      "Epoch 330/500\n",
      "263/264 [============================>.] - ETA: 0s - loss: 0.0270 - accuracy: 0.9881\n",
      "Epoch 00330: val_accuracy did not improve from 0.82900\n",
      "264/264 [==============================] - 6s 22ms/step - loss: 0.0270 - accuracy: 0.9881 - val_loss: 1.2209 - val_accuracy: 0.8131\n",
      "Epoch 331/500\n",
      "264/264 [==============================] - ETA: 0s - loss: 0.0266 - accuracy: 0.9877\n",
      "Epoch 00331: val_accuracy did not improve from 0.82900\n",
      "264/264 [==============================] - 6s 22ms/step - loss: 0.0266 - accuracy: 0.9877 - val_loss: 1.2622 - val_accuracy: 0.8120\n",
      "Epoch 332/500\n",
      "262/264 [============================>.] - ETA: 0s - loss: 0.0257 - accuracy: 0.9885\n",
      "Epoch 00332: val_accuracy did not improve from 0.82900\n",
      "264/264 [==============================] - 6s 22ms/step - loss: 0.0257 - accuracy: 0.9885 - val_loss: 1.2583 - val_accuracy: 0.8117\n",
      "Epoch 333/500\n",
      "264/264 [==============================] - ETA: 0s - loss: 0.0271 - accuracy: 0.9880\n",
      "Epoch 00333: val_accuracy did not improve from 0.82900\n",
      "264/264 [==============================] - 6s 21ms/step - loss: 0.0271 - accuracy: 0.9880 - val_loss: 1.2547 - val_accuracy: 0.8095\n",
      "Epoch 334/500\n",
      "264/264 [==============================] - ETA: 0s - loss: 0.0272 - accuracy: 0.9880\n",
      "Epoch 00334: val_accuracy did not improve from 0.82900\n",
      "264/264 [==============================] - 6s 22ms/step - loss: 0.0272 - accuracy: 0.9880 - val_loss: 1.1764 - val_accuracy: 0.8107\n",
      "Epoch 335/500\n",
      "263/264 [============================>.] - ETA: 0s - loss: 0.0268 - accuracy: 0.9882\n",
      "Epoch 00335: val_accuracy did not improve from 0.82900\n",
      "264/264 [==============================] - 6s 23ms/step - loss: 0.0268 - accuracy: 0.9882 - val_loss: 1.2712 - val_accuracy: 0.8100\n",
      "Epoch 336/500\n",
      "262/264 [============================>.] - ETA: 0s - loss: 0.0262 - accuracy: 0.9883\n",
      "Epoch 00336: val_accuracy did not improve from 0.82900\n",
      "264/264 [==============================] - 6s 21ms/step - loss: 0.0262 - accuracy: 0.9883 - val_loss: 1.2880 - val_accuracy: 0.8133\n",
      "Epoch 337/500\n",
      "264/264 [==============================] - ETA: 0s - loss: 0.0257 - accuracy: 0.9884\n",
      "Epoch 00337: val_accuracy did not improve from 0.82900\n",
      "264/264 [==============================] - 6s 21ms/step - loss: 0.0257 - accuracy: 0.9884 - val_loss: 1.2322 - val_accuracy: 0.8089\n",
      "Epoch 338/500\n",
      "264/264 [==============================] - ETA: 0s - loss: 0.0263 - accuracy: 0.9881\n",
      "Epoch 00338: val_accuracy did not improve from 0.82900\n",
      "264/264 [==============================] - 6s 22ms/step - loss: 0.0263 - accuracy: 0.9881 - val_loss: 1.2400 - val_accuracy: 0.8113\n",
      "Epoch 339/500\n",
      "262/264 [============================>.] - ETA: 0s - loss: 0.0269 - accuracy: 0.9879\n",
      "Epoch 00339: val_accuracy did not improve from 0.82900\n",
      "264/264 [==============================] - 6s 22ms/step - loss: 0.0268 - accuracy: 0.9879 - val_loss: 1.2618 - val_accuracy: 0.8139\n",
      "Epoch 340/500\n",
      "263/264 [============================>.] - ETA: 0s - loss: 0.0265 - accuracy: 0.9882\n",
      "Epoch 00340: val_accuracy did not improve from 0.82900\n",
      "264/264 [==============================] - 6s 22ms/step - loss: 0.0265 - accuracy: 0.9881 - val_loss: 1.3022 - val_accuracy: 0.8143\n",
      "Epoch 341/500\n",
      "263/264 [============================>.] - ETA: 0s - loss: 0.0264 - accuracy: 0.9883\n",
      "Epoch 00341: val_accuracy did not improve from 0.82900\n",
      "264/264 [==============================] - 6s 22ms/step - loss: 0.0264 - accuracy: 0.9882 - val_loss: 1.2685 - val_accuracy: 0.8130\n",
      "Epoch 342/500\n",
      "264/264 [==============================] - ETA: 0s - loss: 0.0263 - accuracy: 0.9883\n",
      "Epoch 00342: val_accuracy did not improve from 0.82900\n",
      "264/264 [==============================] - 6s 22ms/step - loss: 0.0263 - accuracy: 0.9883 - val_loss: 1.2584 - val_accuracy: 0.8103\n",
      "Epoch 343/500\n",
      "262/264 [============================>.] - ETA: 0s - loss: 0.0260 - accuracy: 0.9884\n",
      "Epoch 00343: val_accuracy did not improve from 0.82900\n",
      "264/264 [==============================] - 6s 22ms/step - loss: 0.0260 - accuracy: 0.9884 - val_loss: 1.2303 - val_accuracy: 0.8110\n",
      "Epoch 344/500\n",
      "263/264 [============================>.] - ETA: 0s - loss: 0.0275 - accuracy: 0.9879\n",
      "Epoch 00344: val_accuracy did not improve from 0.82900\n",
      "264/264 [==============================] - 6s 22ms/step - loss: 0.0274 - accuracy: 0.9879 - val_loss: 1.2581 - val_accuracy: 0.8111\n",
      "Epoch 345/500\n",
      "262/264 [============================>.] - ETA: 0s - loss: 0.0261 - accuracy: 0.9885\n",
      "Epoch 00345: val_accuracy did not improve from 0.82900\n",
      "264/264 [==============================] - 6s 22ms/step - loss: 0.0261 - accuracy: 0.9885 - val_loss: 1.2844 - val_accuracy: 0.8131\n",
      "Epoch 346/500\n",
      "262/264 [============================>.] - ETA: 0s - loss: 0.0261 - accuracy: 0.9884\n",
      "Epoch 00346: val_accuracy did not improve from 0.82900\n",
      "264/264 [==============================] - 6s 22ms/step - loss: 0.0261 - accuracy: 0.9883 - val_loss: 1.2506 - val_accuracy: 0.8124\n",
      "Epoch 347/500\n",
      "262/264 [============================>.] - ETA: 0s - loss: 0.0261 - accuracy: 0.9882\n",
      "Epoch 00347: val_accuracy did not improve from 0.82900\n",
      "264/264 [==============================] - 6s 22ms/step - loss: 0.0262 - accuracy: 0.9882 - val_loss: 1.2386 - val_accuracy: 0.8129\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 348/500\n",
      "264/264 [==============================] - ETA: 0s - loss: 0.0258 - accuracy: 0.9884\n",
      "Epoch 00348: val_accuracy did not improve from 0.82900\n",
      "264/264 [==============================] - 6s 22ms/step - loss: 0.0258 - accuracy: 0.9884 - val_loss: 1.2913 - val_accuracy: 0.8129\n",
      "Epoch 349/500\n",
      "262/264 [============================>.] - ETA: 0s - loss: 0.0267 - accuracy: 0.9882\n",
      "Epoch 00349: val_accuracy did not improve from 0.82900\n",
      "264/264 [==============================] - 6s 21ms/step - loss: 0.0267 - accuracy: 0.9882 - val_loss: 1.2644 - val_accuracy: 0.8111\n",
      "Epoch 350/500\n",
      "262/264 [============================>.] - ETA: 0s - loss: 0.0257 - accuracy: 0.9885\n",
      "Epoch 00350: val_accuracy did not improve from 0.82900\n",
      "264/264 [==============================] - 6s 21ms/step - loss: 0.0256 - accuracy: 0.9885 - val_loss: 1.2706 - val_accuracy: 0.8102\n",
      "Epoch 351/500\n",
      "262/264 [============================>.] - ETA: 0s - loss: 0.0259 - accuracy: 0.9884\n",
      "Epoch 00351: val_accuracy did not improve from 0.82900\n",
      "264/264 [==============================] - 6s 22ms/step - loss: 0.0259 - accuracy: 0.9883 - val_loss: 1.2802 - val_accuracy: 0.8095\n",
      "Epoch 352/500\n",
      "263/264 [============================>.] - ETA: 0s - loss: 0.0267 - accuracy: 0.9879\n",
      "Epoch 00352: val_accuracy did not improve from 0.82900\n",
      "264/264 [==============================] - 6s 22ms/step - loss: 0.0267 - accuracy: 0.9879 - val_loss: 1.2887 - val_accuracy: 0.8107\n",
      "Epoch 353/500\n",
      "263/264 [============================>.] - ETA: 0s - loss: 0.0263 - accuracy: 0.9882\n",
      "Epoch 00353: val_accuracy did not improve from 0.82900\n",
      "264/264 [==============================] - 6s 22ms/step - loss: 0.0262 - accuracy: 0.9882 - val_loss: 1.2451 - val_accuracy: 0.8099\n",
      "Epoch 354/500\n",
      "262/264 [============================>.] - ETA: 0s - loss: 0.0269 - accuracy: 0.9882\n",
      "Epoch 00354: val_accuracy did not improve from 0.82900\n",
      "264/264 [==============================] - 6s 22ms/step - loss: 0.0269 - accuracy: 0.9882 - val_loss: 1.1993 - val_accuracy: 0.8093\n",
      "Epoch 355/500\n",
      "264/264 [==============================] - ETA: 0s - loss: 0.0263 - accuracy: 0.9881\n",
      "Epoch 00355: val_accuracy did not improve from 0.82900\n",
      "264/264 [==============================] - 6s 21ms/step - loss: 0.0263 - accuracy: 0.9881 - val_loss: 1.2804 - val_accuracy: 0.8109\n",
      "Epoch 356/500\n",
      "263/264 [============================>.] - ETA: 0s - loss: 0.0257 - accuracy: 0.9887\n",
      "Epoch 00356: val_accuracy did not improve from 0.82900\n",
      "264/264 [==============================] - 6s 21ms/step - loss: 0.0257 - accuracy: 0.9887 - val_loss: 1.2480 - val_accuracy: 0.8118\n",
      "Epoch 357/500\n",
      "264/264 [==============================] - ETA: 0s - loss: 0.0258 - accuracy: 0.9885\n",
      "Epoch 00357: val_accuracy did not improve from 0.82900\n",
      "264/264 [==============================] - 6s 22ms/step - loss: 0.0258 - accuracy: 0.9885 - val_loss: 1.2730 - val_accuracy: 0.8114\n",
      "Epoch 358/500\n",
      "263/264 [============================>.] - ETA: 0s - loss: 0.0263 - accuracy: 0.9884\n",
      "Epoch 00358: val_accuracy did not improve from 0.82900\n",
      "264/264 [==============================] - 6s 21ms/step - loss: 0.0263 - accuracy: 0.9883 - val_loss: 1.2464 - val_accuracy: 0.8101\n",
      "Epoch 359/500\n",
      "264/264 [==============================] - ETA: 0s - loss: 0.0262 - accuracy: 0.9886\n",
      "Epoch 00359: val_accuracy did not improve from 0.82900\n",
      "264/264 [==============================] - 6s 21ms/step - loss: 0.0262 - accuracy: 0.9886 - val_loss: 1.2412 - val_accuracy: 0.8123\n",
      "Epoch 360/500\n",
      "263/264 [============================>.] - ETA: 0s - loss: 0.0258 - accuracy: 0.9885\n",
      "Epoch 00360: val_accuracy did not improve from 0.82900\n",
      "264/264 [==============================] - 6s 22ms/step - loss: 0.0258 - accuracy: 0.9886 - val_loss: 1.2041 - val_accuracy: 0.8097\n",
      "Epoch 361/500\n",
      "263/264 [============================>.] - ETA: 0s - loss: 0.0259 - accuracy: 0.9885\n",
      "Epoch 00361: val_accuracy did not improve from 0.82900\n",
      "264/264 [==============================] - 6s 22ms/step - loss: 0.0259 - accuracy: 0.9885 - val_loss: 1.2275 - val_accuracy: 0.8099\n",
      "Epoch 362/500\n",
      "263/264 [============================>.] - ETA: 0s - loss: 0.0260 - accuracy: 0.9881\n",
      "Epoch 00362: val_accuracy did not improve from 0.82900\n",
      "264/264 [==============================] - 6s 22ms/step - loss: 0.0260 - accuracy: 0.9882 - val_loss: 1.2474 - val_accuracy: 0.8134\n",
      "Epoch 363/500\n",
      "263/264 [============================>.] - ETA: 0s - loss: 0.0259 - accuracy: 0.9887\n",
      "Epoch 00363: val_accuracy did not improve from 0.82900\n",
      "264/264 [==============================] - 6s 22ms/step - loss: 0.0259 - accuracy: 0.9887 - val_loss: 1.2829 - val_accuracy: 0.8128\n",
      "Epoch 364/500\n",
      "264/264 [==============================] - ETA: 0s - loss: 0.0269 - accuracy: 0.9880\n",
      "Epoch 00364: val_accuracy did not improve from 0.82900\n",
      "264/264 [==============================] - 6s 22ms/step - loss: 0.0269 - accuracy: 0.9880 - val_loss: 1.2576 - val_accuracy: 0.8120\n",
      "Epoch 365/500\n",
      "262/264 [============================>.] - ETA: 0s - loss: 0.0263 - accuracy: 0.9880\n",
      "Epoch 00365: val_accuracy did not improve from 0.82900\n",
      "264/264 [==============================] - 6s 22ms/step - loss: 0.0263 - accuracy: 0.9880 - val_loss: 1.3165 - val_accuracy: 0.8113\n",
      "Epoch 366/500\n",
      "264/264 [==============================] - ETA: 0s - loss: 0.0257 - accuracy: 0.9884\n",
      "Epoch 00366: val_accuracy did not improve from 0.82900\n",
      "264/264 [==============================] - 6s 22ms/step - loss: 0.0257 - accuracy: 0.9884 - val_loss: 1.2737 - val_accuracy: 0.8128\n",
      "Epoch 367/500\n",
      "264/264 [==============================] - ETA: 0s - loss: 0.0256 - accuracy: 0.9885\n",
      "Epoch 00367: val_accuracy did not improve from 0.82900\n",
      "264/264 [==============================] - 6s 22ms/step - loss: 0.0256 - accuracy: 0.9885 - val_loss: 1.2456 - val_accuracy: 0.8128\n",
      "Epoch 368/500\n",
      "263/264 [============================>.] - ETA: 0s - loss: 0.0260 - accuracy: 0.9886\n",
      "Epoch 00368: val_accuracy did not improve from 0.82900\n",
      "264/264 [==============================] - 6s 22ms/step - loss: 0.0260 - accuracy: 0.9886 - val_loss: 1.2954 - val_accuracy: 0.8123\n",
      "Epoch 369/500\n",
      "262/264 [============================>.] - ETA: 0s - loss: 0.0258 - accuracy: 0.9882\n",
      "Epoch 00369: val_accuracy did not improve from 0.82900\n",
      "264/264 [==============================] - 6s 22ms/step - loss: 0.0258 - accuracy: 0.9882 - val_loss: 1.3197 - val_accuracy: 0.8150\n",
      "Epoch 370/500\n",
      "263/264 [============================>.] - ETA: 0s - loss: 0.0251 - accuracy: 0.9889\n",
      "Epoch 00370: val_accuracy did not improve from 0.82900\n",
      "264/264 [==============================] - 6s 22ms/step - loss: 0.0251 - accuracy: 0.9889 - val_loss: 1.2847 - val_accuracy: 0.8122\n",
      "Epoch 371/500\n",
      "262/264 [============================>.] - ETA: 0s - loss: 0.0259 - accuracy: 0.9885\n",
      "Epoch 00371: val_accuracy did not improve from 0.82900\n",
      "264/264 [==============================] - 6s 23ms/step - loss: 0.0259 - accuracy: 0.9885 - val_loss: 1.2936 - val_accuracy: 0.8111\n",
      "Epoch 372/500\n",
      "264/264 [==============================] - ETA: 0s - loss: 0.0256 - accuracy: 0.9884\n",
      "Epoch 00372: val_accuracy did not improve from 0.82900\n",
      "264/264 [==============================] - 6s 22ms/step - loss: 0.0256 - accuracy: 0.9884 - val_loss: 1.2725 - val_accuracy: 0.8143\n",
      "Epoch 373/500\n",
      "262/264 [============================>.] - ETA: 0s - loss: 0.0263 - accuracy: 0.9885\n",
      "Epoch 00373: val_accuracy did not improve from 0.82900\n",
      "264/264 [==============================] - 6s 22ms/step - loss: 0.0262 - accuracy: 0.9885 - val_loss: 1.2497 - val_accuracy: 0.8123\n",
      "Epoch 374/500\n",
      "262/264 [============================>.] - ETA: 0s - loss: 0.0254 - accuracy: 0.9884\n",
      "Epoch 00374: val_accuracy did not improve from 0.82900\n",
      "264/264 [==============================] - 6s 22ms/step - loss: 0.0254 - accuracy: 0.9884 - val_loss: 1.2823 - val_accuracy: 0.8147\n",
      "Epoch 375/500\n",
      "262/264 [============================>.] - ETA: 0s - loss: 0.0262 - accuracy: 0.9881\n",
      "Epoch 00375: val_accuracy did not improve from 0.82900\n",
      "264/264 [==============================] - 6s 23ms/step - loss: 0.0262 - accuracy: 0.9881 - val_loss: 1.2389 - val_accuracy: 0.8138\n",
      "Epoch 376/500\n",
      "262/264 [============================>.] - ETA: 0s - loss: 0.0259 - accuracy: 0.9885\n",
      "Epoch 00376: val_accuracy did not improve from 0.82900\n",
      "264/264 [==============================] - 6s 22ms/step - loss: 0.0259 - accuracy: 0.9885 - val_loss: 1.3178 - val_accuracy: 0.8130\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 377/500\n",
      "264/264 [==============================] - ETA: 0s - loss: 0.0258 - accuracy: 0.9884\n",
      "Epoch 00377: val_accuracy did not improve from 0.82900\n",
      "264/264 [==============================] - 6s 22ms/step - loss: 0.0258 - accuracy: 0.9884 - val_loss: 1.2793 - val_accuracy: 0.8126\n",
      "Epoch 378/500\n",
      "264/264 [==============================] - ETA: 0s - loss: 0.0255 - accuracy: 0.9886\n",
      "Epoch 00378: val_accuracy did not improve from 0.82900\n",
      "264/264 [==============================] - 6s 22ms/step - loss: 0.0255 - accuracy: 0.9886 - val_loss: 1.3189 - val_accuracy: 0.8131\n",
      "Epoch 379/500\n",
      "262/264 [============================>.] - ETA: 0s - loss: 0.0254 - accuracy: 0.9885\n",
      "Epoch 00379: val_accuracy did not improve from 0.82900\n",
      "264/264 [==============================] - 6s 22ms/step - loss: 0.0254 - accuracy: 0.9885 - val_loss: 1.2824 - val_accuracy: 0.8141\n",
      "Epoch 380/500\n",
      "262/264 [============================>.] - ETA: 0s - loss: 0.0254 - accuracy: 0.9888\n",
      "Epoch 00380: val_accuracy did not improve from 0.82900\n",
      "264/264 [==============================] - 6s 21ms/step - loss: 0.0254 - accuracy: 0.9888 - val_loss: 1.3231 - val_accuracy: 0.8112\n",
      "Epoch 381/500\n",
      "263/264 [============================>.] - ETA: 0s - loss: 0.0257 - accuracy: 0.9884\n",
      "Epoch 00381: val_accuracy did not improve from 0.82900\n",
      "264/264 [==============================] - 6s 22ms/step - loss: 0.0257 - accuracy: 0.9884 - val_loss: 1.2731 - val_accuracy: 0.8113\n",
      "Epoch 382/500\n",
      "262/264 [============================>.] - ETA: 0s - loss: 0.0258 - accuracy: 0.9883\n",
      "Epoch 00382: val_accuracy did not improve from 0.82900\n",
      "264/264 [==============================] - 6s 22ms/step - loss: 0.0259 - accuracy: 0.9882 - val_loss: 1.2134 - val_accuracy: 0.8102\n",
      "Epoch 383/500\n",
      "264/264 [==============================] - ETA: 0s - loss: 0.0249 - accuracy: 0.9887\n",
      "Epoch 00383: val_accuracy did not improve from 0.82900\n",
      "264/264 [==============================] - 6s 22ms/step - loss: 0.0249 - accuracy: 0.9887 - val_loss: 1.3076 - val_accuracy: 0.8125\n",
      "Epoch 384/500\n",
      "263/264 [============================>.] - ETA: 0s - loss: 0.0252 - accuracy: 0.9888\n",
      "Epoch 00384: val_accuracy did not improve from 0.82900\n",
      "264/264 [==============================] - 6s 21ms/step - loss: 0.0253 - accuracy: 0.9888 - val_loss: 1.2476 - val_accuracy: 0.8121\n",
      "Epoch 385/500\n",
      "264/264 [==============================] - ETA: 0s - loss: 0.0257 - accuracy: 0.9883\n",
      "Epoch 00385: val_accuracy did not improve from 0.82900\n",
      "264/264 [==============================] - 6s 21ms/step - loss: 0.0257 - accuracy: 0.9883 - val_loss: 1.2974 - val_accuracy: 0.8109\n",
      "Epoch 386/500\n",
      "262/264 [============================>.] - ETA: 0s - loss: 0.0252 - accuracy: 0.9886\n",
      "Epoch 00386: val_accuracy did not improve from 0.82900\n",
      "264/264 [==============================] - 6s 22ms/step - loss: 0.0252 - accuracy: 0.9886 - val_loss: 1.2904 - val_accuracy: 0.8106\n",
      "Epoch 387/500\n",
      "264/264 [==============================] - ETA: 0s - loss: 0.0257 - accuracy: 0.9883\n",
      "Epoch 00387: val_accuracy did not improve from 0.82900\n",
      "264/264 [==============================] - 6s 22ms/step - loss: 0.0257 - accuracy: 0.9883 - val_loss: 1.2800 - val_accuracy: 0.8113\n",
      "Epoch 388/500\n",
      "264/264 [==============================] - ETA: 0s - loss: 0.0254 - accuracy: 0.9885\n",
      "Epoch 00388: val_accuracy did not improve from 0.82900\n",
      "264/264 [==============================] - 6s 22ms/step - loss: 0.0254 - accuracy: 0.9885 - val_loss: 1.2426 - val_accuracy: 0.8138\n",
      "Epoch 389/500\n",
      "262/264 [============================>.] - ETA: 0s - loss: 0.0253 - accuracy: 0.9887\n",
      "Epoch 00389: val_accuracy did not improve from 0.82900\n",
      "264/264 [==============================] - 6s 22ms/step - loss: 0.0253 - accuracy: 0.9887 - val_loss: 1.2756 - val_accuracy: 0.8117\n",
      "Epoch 390/500\n",
      "264/264 [==============================] - ETA: 0s - loss: 0.0251 - accuracy: 0.9885\n",
      "Epoch 00390: val_accuracy did not improve from 0.82900\n",
      "264/264 [==============================] - 6s 23ms/step - loss: 0.0251 - accuracy: 0.9885 - val_loss: 1.2478 - val_accuracy: 0.8139\n",
      "Epoch 391/500\n",
      "263/264 [============================>.] - ETA: 0s - loss: 0.0261 - accuracy: 0.9883\n",
      "Epoch 00391: val_accuracy did not improve from 0.82900\n",
      "264/264 [==============================] - 6s 22ms/step - loss: 0.0261 - accuracy: 0.9883 - val_loss: 1.2540 - val_accuracy: 0.8105\n",
      "Epoch 392/500\n",
      "262/264 [============================>.] - ETA: 0s - loss: 0.0251 - accuracy: 0.9888\n",
      "Epoch 00392: val_accuracy did not improve from 0.82900\n",
      "264/264 [==============================] - 6s 22ms/step - loss: 0.0251 - accuracy: 0.9888 - val_loss: 1.2849 - val_accuracy: 0.8115\n",
      "Epoch 393/500\n",
      "263/264 [============================>.] - ETA: 0s - loss: 0.0247 - accuracy: 0.9888\n",
      "Epoch 00393: val_accuracy did not improve from 0.82900\n",
      "264/264 [==============================] - 6s 22ms/step - loss: 0.0248 - accuracy: 0.9887 - val_loss: 1.3056 - val_accuracy: 0.8107\n",
      "Epoch 394/500\n",
      "262/264 [============================>.] - ETA: 0s - loss: 0.0253 - accuracy: 0.9887\n",
      "Epoch 00394: val_accuracy did not improve from 0.82900\n",
      "264/264 [==============================] - 6s 22ms/step - loss: 0.0253 - accuracy: 0.9887 - val_loss: 1.2586 - val_accuracy: 0.8123\n",
      "Epoch 395/500\n",
      "262/264 [============================>.] - ETA: 0s - loss: 0.0249 - accuracy: 0.9888\n",
      "Epoch 00395: val_accuracy did not improve from 0.82900\n",
      "264/264 [==============================] - 6s 22ms/step - loss: 0.0249 - accuracy: 0.9888 - val_loss: 1.2636 - val_accuracy: 0.8151\n",
      "Epoch 396/500\n",
      "264/264 [==============================] - ETA: 0s - loss: 0.0254 - accuracy: 0.9888\n",
      "Epoch 00396: val_accuracy did not improve from 0.82900\n",
      "264/264 [==============================] - 6s 22ms/step - loss: 0.0254 - accuracy: 0.9888 - val_loss: 1.2637 - val_accuracy: 0.8120\n",
      "Epoch 397/500\n",
      "262/264 [============================>.] - ETA: 0s - loss: 0.0251 - accuracy: 0.9887\n",
      "Epoch 00397: val_accuracy did not improve from 0.82900\n",
      "264/264 [==============================] - 6s 22ms/step - loss: 0.0251 - accuracy: 0.9888 - val_loss: 1.2666 - val_accuracy: 0.8145\n",
      "Epoch 398/500\n",
      "262/264 [============================>.] - ETA: 0s - loss: 0.0252 - accuracy: 0.9888\n",
      "Epoch 00398: val_accuracy did not improve from 0.82900\n",
      "264/264 [==============================] - 6s 22ms/step - loss: 0.0253 - accuracy: 0.9887 - val_loss: 1.3000 - val_accuracy: 0.8125\n",
      "Epoch 399/500\n",
      "262/264 [============================>.] - ETA: 0s - loss: 0.0248 - accuracy: 0.9890\n",
      "Epoch 00399: val_accuracy did not improve from 0.82900\n",
      "264/264 [==============================] - 6s 22ms/step - loss: 0.0249 - accuracy: 0.9889 - val_loss: 1.3644 - val_accuracy: 0.8144\n",
      "Epoch 400/500\n",
      "264/264 [==============================] - ETA: 0s - loss: 0.0258 - accuracy: 0.9883\n",
      "Epoch 00400: val_accuracy did not improve from 0.82900\n",
      "264/264 [==============================] - 6s 22ms/step - loss: 0.0258 - accuracy: 0.9883 - val_loss: 1.2658 - val_accuracy: 0.8129\n",
      "Epoch 401/500\n",
      "263/264 [============================>.] - ETA: 0s - loss: 0.0257 - accuracy: 0.9887\n",
      "Epoch 00401: val_accuracy did not improve from 0.82900\n",
      "264/264 [==============================] - 6s 23ms/step - loss: 0.0257 - accuracy: 0.9887 - val_loss: 1.2630 - val_accuracy: 0.8101\n",
      "Epoch 402/500\n",
      "264/264 [==============================] - ETA: 0s - loss: 0.0249 - accuracy: 0.9886\n",
      "Epoch 00402: val_accuracy did not improve from 0.82900\n",
      "264/264 [==============================] - 6s 22ms/step - loss: 0.0249 - accuracy: 0.9886 - val_loss: 1.3148 - val_accuracy: 0.8118\n",
      "Epoch 403/500\n",
      "264/264 [==============================] - ETA: 0s - loss: 0.0259 - accuracy: 0.9887\n",
      "Epoch 00403: val_accuracy did not improve from 0.82900\n",
      "264/264 [==============================] - 6s 22ms/step - loss: 0.0259 - accuracy: 0.9887 - val_loss: 1.3006 - val_accuracy: 0.8114\n",
      "Epoch 404/500\n",
      "262/264 [============================>.] - ETA: 0s - loss: 0.0251 - accuracy: 0.9886\n",
      "Epoch 00404: val_accuracy did not improve from 0.82900\n",
      "264/264 [==============================] - 6s 22ms/step - loss: 0.0251 - accuracy: 0.9886 - val_loss: 1.2747 - val_accuracy: 0.8106\n",
      "Epoch 405/500\n",
      "264/264 [==============================] - ETA: 0s - loss: 0.0251 - accuracy: 0.9887\n",
      "Epoch 00405: val_accuracy did not improve from 0.82900\n",
      "264/264 [==============================] - 6s 23ms/step - loss: 0.0251 - accuracy: 0.9887 - val_loss: 1.3203 - val_accuracy: 0.8127\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 406/500\n",
      "263/264 [============================>.] - ETA: 0s - loss: 0.0252 - accuracy: 0.9889\n",
      "Epoch 00406: val_accuracy did not improve from 0.82900\n",
      "264/264 [==============================] - 6s 23ms/step - loss: 0.0252 - accuracy: 0.9889 - val_loss: 1.2173 - val_accuracy: 0.8103\n",
      "Epoch 407/500\n",
      "263/264 [============================>.] - ETA: 0s - loss: 0.0248 - accuracy: 0.9889\n",
      "Epoch 00407: val_accuracy did not improve from 0.82900\n",
      "264/264 [==============================] - 6s 22ms/step - loss: 0.0248 - accuracy: 0.9889 - val_loss: 1.3171 - val_accuracy: 0.8133\n",
      "Epoch 408/500\n",
      "262/264 [============================>.] - ETA: 0s - loss: 0.0256 - accuracy: 0.9887\n",
      "Epoch 00408: val_accuracy did not improve from 0.82900\n",
      "264/264 [==============================] - 6s 23ms/step - loss: 0.0257 - accuracy: 0.9887 - val_loss: 1.2577 - val_accuracy: 0.8134\n",
      "Epoch 409/500\n",
      "263/264 [============================>.] - ETA: 0s - loss: 0.0249 - accuracy: 0.9889\n",
      "Epoch 00409: val_accuracy did not improve from 0.82900\n",
      "264/264 [==============================] - 6s 22ms/step - loss: 0.0249 - accuracy: 0.9889 - val_loss: 1.2698 - val_accuracy: 0.8126\n",
      "Epoch 410/500\n",
      "264/264 [==============================] - ETA: 0s - loss: 0.0246 - accuracy: 0.9888\n",
      "Epoch 00410: val_accuracy did not improve from 0.82900\n",
      "264/264 [==============================] - 6s 23ms/step - loss: 0.0246 - accuracy: 0.9888 - val_loss: 1.2874 - val_accuracy: 0.8115\n",
      "Epoch 411/500\n",
      "264/264 [==============================] - ETA: 0s - loss: 0.0255 - accuracy: 0.9883\n",
      "Epoch 00411: val_accuracy did not improve from 0.82900\n",
      "264/264 [==============================] - 6s 22ms/step - loss: 0.0255 - accuracy: 0.9883 - val_loss: 1.2393 - val_accuracy: 0.8107\n",
      "Epoch 412/500\n",
      "264/264 [==============================] - ETA: 0s - loss: 0.0250 - accuracy: 0.9888\n",
      "Epoch 00412: val_accuracy did not improve from 0.82900\n",
      "264/264 [==============================] - 6s 23ms/step - loss: 0.0250 - accuracy: 0.9888 - val_loss: 1.2688 - val_accuracy: 0.8113\n",
      "Epoch 413/500\n",
      "262/264 [============================>.] - ETA: 0s - loss: 0.0247 - accuracy: 0.9889\n",
      "Epoch 00413: val_accuracy did not improve from 0.82900\n",
      "264/264 [==============================] - 6s 22ms/step - loss: 0.0246 - accuracy: 0.9889 - val_loss: 1.4000 - val_accuracy: 0.8131\n",
      "Epoch 414/500\n",
      "264/264 [==============================] - ETA: 0s - loss: 0.0250 - accuracy: 0.9887\n",
      "Epoch 00414: val_accuracy did not improve from 0.82900\n",
      "264/264 [==============================] - 6s 22ms/step - loss: 0.0250 - accuracy: 0.9887 - val_loss: 1.2395 - val_accuracy: 0.8106\n",
      "Epoch 415/500\n",
      "264/264 [==============================] - ETA: 0s - loss: 0.0256 - accuracy: 0.9885\n",
      "Epoch 00415: val_accuracy did not improve from 0.82900\n",
      "264/264 [==============================] - 6s 22ms/step - loss: 0.0256 - accuracy: 0.9885 - val_loss: 1.2031 - val_accuracy: 0.8119\n",
      "Epoch 416/500\n",
      "262/264 [============================>.] - ETA: 0s - loss: 0.0252 - accuracy: 0.9888\n",
      "Epoch 00416: val_accuracy did not improve from 0.82900\n",
      "264/264 [==============================] - 6s 22ms/step - loss: 0.0251 - accuracy: 0.9888 - val_loss: 1.2828 - val_accuracy: 0.8124\n",
      "Epoch 417/500\n",
      "262/264 [============================>.] - ETA: 0s - loss: 0.0250 - accuracy: 0.9885\n",
      "Epoch 00417: val_accuracy did not improve from 0.82900\n",
      "264/264 [==============================] - 6s 22ms/step - loss: 0.0250 - accuracy: 0.9885 - val_loss: 1.3482 - val_accuracy: 0.8103\n",
      "Epoch 418/500\n",
      "264/264 [==============================] - ETA: 0s - loss: 0.0249 - accuracy: 0.9889\n",
      "Epoch 00418: val_accuracy did not improve from 0.82900\n",
      "264/264 [==============================] - 6s 22ms/step - loss: 0.0249 - accuracy: 0.9889 - val_loss: 1.3462 - val_accuracy: 0.8140\n",
      "Epoch 419/500\n",
      "263/264 [============================>.] - ETA: 0s - loss: 0.0259 - accuracy: 0.9886\n",
      "Epoch 00419: val_accuracy did not improve from 0.82900\n",
      "264/264 [==============================] - 6s 22ms/step - loss: 0.0258 - accuracy: 0.9886 - val_loss: 1.2221 - val_accuracy: 0.8147\n",
      "Epoch 420/500\n",
      "264/264 [==============================] - ETA: 0s - loss: 0.0251 - accuracy: 0.9885\n",
      "Epoch 00420: val_accuracy did not improve from 0.82900\n",
      "264/264 [==============================] - 6s 22ms/step - loss: 0.0251 - accuracy: 0.9885 - val_loss: 1.3451 - val_accuracy: 0.8131\n",
      "Epoch 421/500\n",
      "263/264 [============================>.] - ETA: 0s - loss: 0.0241 - accuracy: 0.9891\n",
      "Epoch 00421: val_accuracy did not improve from 0.82900\n",
      "264/264 [==============================] - 6s 22ms/step - loss: 0.0242 - accuracy: 0.9891 - val_loss: 1.3244 - val_accuracy: 0.8131\n",
      "Epoch 422/500\n",
      "263/264 [============================>.] - ETA: 0s - loss: 0.0246 - accuracy: 0.9888\n",
      "Epoch 00422: val_accuracy did not improve from 0.82900\n",
      "264/264 [==============================] - 6s 22ms/step - loss: 0.0246 - accuracy: 0.9888 - val_loss: 1.3303 - val_accuracy: 0.8142\n",
      "Epoch 423/500\n",
      "264/264 [==============================] - ETA: 0s - loss: 0.0243 - accuracy: 0.9889\n",
      "Epoch 00423: val_accuracy did not improve from 0.82900\n",
      "264/264 [==============================] - 6s 22ms/step - loss: 0.0243 - accuracy: 0.9889 - val_loss: 1.3405 - val_accuracy: 0.8131\n",
      "Epoch 424/500\n",
      "262/264 [============================>.] - ETA: 0s - loss: 0.0248 - accuracy: 0.9889\n",
      "Epoch 00424: val_accuracy did not improve from 0.82900\n",
      "264/264 [==============================] - 6s 22ms/step - loss: 0.0247 - accuracy: 0.9889 - val_loss: 1.2936 - val_accuracy: 0.8117\n",
      "Epoch 425/500\n",
      "263/264 [============================>.] - ETA: 0s - loss: 0.0250 - accuracy: 0.9888\n",
      "Epoch 00425: val_accuracy did not improve from 0.82900\n",
      "264/264 [==============================] - 6s 22ms/step - loss: 0.0250 - accuracy: 0.9888 - val_loss: 1.2923 - val_accuracy: 0.8144\n",
      "Epoch 426/500\n",
      "263/264 [============================>.] - ETA: 0s - loss: 0.0245 - accuracy: 0.9888\n",
      "Epoch 00426: val_accuracy did not improve from 0.82900\n",
      "264/264 [==============================] - 6s 22ms/step - loss: 0.0245 - accuracy: 0.9888 - val_loss: 1.3276 - val_accuracy: 0.8149\n",
      "Epoch 427/500\n",
      "264/264 [==============================] - ETA: 0s - loss: 0.0248 - accuracy: 0.9891\n",
      "Epoch 00427: val_accuracy did not improve from 0.82900\n",
      "264/264 [==============================] - 6s 22ms/step - loss: 0.0248 - accuracy: 0.9891 - val_loss: 1.2926 - val_accuracy: 0.8072\n",
      "Epoch 428/500\n",
      "262/264 [============================>.] - ETA: 0s - loss: 0.0243 - accuracy: 0.9888\n",
      "Epoch 00428: val_accuracy did not improve from 0.82900\n",
      "264/264 [==============================] - 6s 22ms/step - loss: 0.0243 - accuracy: 0.9888 - val_loss: 1.3091 - val_accuracy: 0.8126\n",
      "Epoch 429/500\n",
      "262/264 [============================>.] - ETA: 0s - loss: 0.0246 - accuracy: 0.9889\n",
      "Epoch 00429: val_accuracy did not improve from 0.82900\n",
      "264/264 [==============================] - 6s 22ms/step - loss: 0.0246 - accuracy: 0.9889 - val_loss: 1.3238 - val_accuracy: 0.8115\n",
      "Epoch 430/500\n",
      "263/264 [============================>.] - ETA: 0s - loss: 0.0248 - accuracy: 0.9888\n",
      "Epoch 00430: val_accuracy did not improve from 0.82900\n",
      "264/264 [==============================] - 6s 22ms/step - loss: 0.0247 - accuracy: 0.9888 - val_loss: 1.3258 - val_accuracy: 0.8140\n",
      "Epoch 431/500\n",
      "263/264 [============================>.] - ETA: 0s - loss: 0.0247 - accuracy: 0.9891\n",
      "Epoch 00431: val_accuracy did not improve from 0.82900\n",
      "264/264 [==============================] - 6s 22ms/step - loss: 0.0247 - accuracy: 0.9890 - val_loss: 1.2964 - val_accuracy: 0.8129\n",
      "Epoch 432/500\n",
      "263/264 [============================>.] - ETA: 0s - loss: 0.0245 - accuracy: 0.9888\n",
      "Epoch 00432: val_accuracy did not improve from 0.82900\n",
      "264/264 [==============================] - 6s 22ms/step - loss: 0.0245 - accuracy: 0.9888 - val_loss: 1.3287 - val_accuracy: 0.8123\n",
      "Epoch 433/500\n",
      "262/264 [============================>.] - ETA: 0s - loss: 0.0245 - accuracy: 0.9887\n",
      "Epoch 00433: val_accuracy did not improve from 0.82900\n",
      "264/264 [==============================] - 6s 22ms/step - loss: 0.0245 - accuracy: 0.9888 - val_loss: 1.3239 - val_accuracy: 0.8100\n",
      "Epoch 434/500\n",
      "263/264 [============================>.] - ETA: 0s - loss: 0.0245 - accuracy: 0.9890\n",
      "Epoch 00434: val_accuracy did not improve from 0.82900\n",
      "264/264 [==============================] - 6s 22ms/step - loss: 0.0245 - accuracy: 0.9891 - val_loss: 1.3629 - val_accuracy: 0.8157\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 435/500\n",
      "263/264 [============================>.] - ETA: 0s - loss: 0.0257 - accuracy: 0.9885\n",
      "Epoch 00435: val_accuracy did not improve from 0.82900\n",
      "264/264 [==============================] - 6s 22ms/step - loss: 0.0257 - accuracy: 0.9885 - val_loss: 1.2454 - val_accuracy: 0.8095\n",
      "Epoch 436/500\n",
      "263/264 [============================>.] - ETA: 0s - loss: 0.0244 - accuracy: 0.9890\n",
      "Epoch 00436: val_accuracy did not improve from 0.82900\n",
      "264/264 [==============================] - 6s 22ms/step - loss: 0.0244 - accuracy: 0.9891 - val_loss: 1.3201 - val_accuracy: 0.8159\n",
      "Epoch 437/500\n",
      "263/264 [============================>.] - ETA: 0s - loss: 0.0246 - accuracy: 0.9889\n",
      "Epoch 00437: val_accuracy did not improve from 0.82900\n",
      "264/264 [==============================] - 6s 22ms/step - loss: 0.0246 - accuracy: 0.9889 - val_loss: 1.3151 - val_accuracy: 0.8127\n",
      "Epoch 438/500\n",
      "263/264 [============================>.] - ETA: 0s - loss: 0.0239 - accuracy: 0.9891\n",
      "Epoch 00438: val_accuracy did not improve from 0.82900\n",
      "264/264 [==============================] - 6s 22ms/step - loss: 0.0239 - accuracy: 0.9891 - val_loss: 1.3588 - val_accuracy: 0.8153\n",
      "Epoch 439/500\n",
      "263/264 [============================>.] - ETA: 0s - loss: 0.0249 - accuracy: 0.9887\n",
      "Epoch 00439: val_accuracy did not improve from 0.82900\n",
      "264/264 [==============================] - 6s 22ms/step - loss: 0.0249 - accuracy: 0.9887 - val_loss: 1.2833 - val_accuracy: 0.8086\n",
      "Epoch 440/500\n",
      "262/264 [============================>.] - ETA: 0s - loss: 0.0240 - accuracy: 0.9893\n",
      "Epoch 00440: val_accuracy did not improve from 0.82900\n",
      "264/264 [==============================] - 6s 22ms/step - loss: 0.0240 - accuracy: 0.9893 - val_loss: 1.3569 - val_accuracy: 0.8130\n",
      "Epoch 441/500\n",
      "263/264 [============================>.] - ETA: 0s - loss: 0.0251 - accuracy: 0.9886\n",
      "Epoch 00441: val_accuracy did not improve from 0.82900\n",
      "264/264 [==============================] - 6s 22ms/step - loss: 0.0251 - accuracy: 0.9887 - val_loss: 1.3122 - val_accuracy: 0.8151\n",
      "Epoch 442/500\n",
      "262/264 [============================>.] - ETA: 0s - loss: 0.0246 - accuracy: 0.9888\n",
      "Epoch 00442: val_accuracy did not improve from 0.82900\n",
      "264/264 [==============================] - 6s 23ms/step - loss: 0.0246 - accuracy: 0.9889 - val_loss: 1.3045 - val_accuracy: 0.8133\n",
      "Epoch 443/500\n",
      "262/264 [============================>.] - ETA: 0s - loss: 0.0249 - accuracy: 0.9888\n",
      "Epoch 00443: val_accuracy did not improve from 0.82900\n",
      "264/264 [==============================] - 6s 23ms/step - loss: 0.0250 - accuracy: 0.9888 - val_loss: 1.2829 - val_accuracy: 0.8136\n",
      "Epoch 444/500\n",
      "263/264 [============================>.] - ETA: 0s - loss: 0.0248 - accuracy: 0.9888\n",
      "Epoch 00444: val_accuracy did not improve from 0.82900\n",
      "264/264 [==============================] - 6s 22ms/step - loss: 0.0248 - accuracy: 0.9888 - val_loss: 1.3134 - val_accuracy: 0.8107\n",
      "Epoch 445/500\n",
      "262/264 [============================>.] - ETA: 0s - loss: 0.0241 - accuracy: 0.9891\n",
      "Epoch 00445: val_accuracy did not improve from 0.82900\n",
      "264/264 [==============================] - 6s 21ms/step - loss: 0.0241 - accuracy: 0.9891 - val_loss: 1.2910 - val_accuracy: 0.8092\n",
      "Epoch 446/500\n",
      "262/264 [============================>.] - ETA: 0s - loss: 0.0240 - accuracy: 0.9893\n",
      "Epoch 00446: val_accuracy did not improve from 0.82900\n",
      "264/264 [==============================] - 6s 22ms/step - loss: 0.0240 - accuracy: 0.9893 - val_loss: 1.3854 - val_accuracy: 0.8126\n",
      "Epoch 447/500\n",
      "264/264 [==============================] - ETA: 0s - loss: 0.0239 - accuracy: 0.9892\n",
      "Epoch 00447: val_accuracy did not improve from 0.82900\n",
      "264/264 [==============================] - 6s 22ms/step - loss: 0.0239 - accuracy: 0.9892 - val_loss: 1.3181 - val_accuracy: 0.8119\n",
      "Epoch 448/500\n",
      "263/264 [============================>.] - ETA: 0s - loss: 0.0246 - accuracy: 0.9890\n",
      "Epoch 00448: val_accuracy did not improve from 0.82900\n",
      "264/264 [==============================] - 6s 23ms/step - loss: 0.0245 - accuracy: 0.9890 - val_loss: 1.3036 - val_accuracy: 0.8121\n",
      "Epoch 449/500\n",
      "263/264 [============================>.] - ETA: 0s - loss: 0.0252 - accuracy: 0.9887\n",
      "Epoch 00449: val_accuracy did not improve from 0.82900\n",
      "264/264 [==============================] - 6s 23ms/step - loss: 0.0252 - accuracy: 0.9887 - val_loss: 1.3002 - val_accuracy: 0.8105\n",
      "Epoch 450/500\n",
      "262/264 [============================>.] - ETA: 0s - loss: 0.0245 - accuracy: 0.9889\n",
      "Epoch 00450: val_accuracy did not improve from 0.82900\n",
      "264/264 [==============================] - 6s 23ms/step - loss: 0.0245 - accuracy: 0.9889 - val_loss: 1.2841 - val_accuracy: 0.8138\n",
      "Epoch 451/500\n",
      "263/264 [============================>.] - ETA: 0s - loss: 0.0252 - accuracy: 0.9887\n",
      "Epoch 00451: val_accuracy did not improve from 0.82900\n",
      "264/264 [==============================] - 6s 22ms/step - loss: 0.0252 - accuracy: 0.9887 - val_loss: 1.3049 - val_accuracy: 0.8132\n",
      "Epoch 452/500\n",
      "262/264 [============================>.] - ETA: 0s - loss: 0.0250 - accuracy: 0.9886\n",
      "Epoch 00452: val_accuracy did not improve from 0.82900\n",
      "264/264 [==============================] - 6s 22ms/step - loss: 0.0251 - accuracy: 0.9886 - val_loss: 1.3633 - val_accuracy: 0.8149\n",
      "Epoch 453/500\n",
      "262/264 [============================>.] - ETA: 0s - loss: 0.0246 - accuracy: 0.9888\n",
      "Epoch 00453: val_accuracy did not improve from 0.82900\n",
      "264/264 [==============================] - 6s 22ms/step - loss: 0.0245 - accuracy: 0.9888 - val_loss: 1.3057 - val_accuracy: 0.8130\n",
      "Epoch 454/500\n",
      "262/264 [============================>.] - ETA: 0s - loss: 0.0244 - accuracy: 0.9890\n",
      "Epoch 00454: val_accuracy did not improve from 0.82900\n",
      "264/264 [==============================] - 6s 22ms/step - loss: 0.0245 - accuracy: 0.9890 - val_loss: 1.3262 - val_accuracy: 0.8118\n",
      "Epoch 455/500\n",
      "262/264 [============================>.] - ETA: 0s - loss: 0.0239 - accuracy: 0.9891\n",
      "Epoch 00455: val_accuracy did not improve from 0.82900\n",
      "264/264 [==============================] - 6s 22ms/step - loss: 0.0239 - accuracy: 0.9890 - val_loss: 1.3466 - val_accuracy: 0.8128\n",
      "Epoch 456/500\n",
      "263/264 [============================>.] - ETA: 0s - loss: 0.0248 - accuracy: 0.9887\n",
      "Epoch 00456: val_accuracy did not improve from 0.82900\n",
      "264/264 [==============================] - 6s 21ms/step - loss: 0.0249 - accuracy: 0.9887 - val_loss: 1.3060 - val_accuracy: 0.8106\n",
      "Epoch 457/500\n",
      "263/264 [============================>.] - ETA: 0s - loss: 0.0238 - accuracy: 0.9890\n",
      "Epoch 00457: val_accuracy did not improve from 0.82900\n",
      "264/264 [==============================] - 6s 22ms/step - loss: 0.0238 - accuracy: 0.9890 - val_loss: 1.2989 - val_accuracy: 0.8106\n",
      "Epoch 458/500\n",
      "264/264 [==============================] - ETA: 0s - loss: 0.0237 - accuracy: 0.9890\n",
      "Epoch 00458: val_accuracy did not improve from 0.82900\n",
      "264/264 [==============================] - 6s 22ms/step - loss: 0.0237 - accuracy: 0.9890 - val_loss: 1.3675 - val_accuracy: 0.8143\n",
      "Epoch 459/500\n",
      "262/264 [============================>.] - ETA: 0s - loss: 0.0239 - accuracy: 0.9890\n",
      "Epoch 00459: val_accuracy did not improve from 0.82900\n",
      "264/264 [==============================] - 6s 22ms/step - loss: 0.0239 - accuracy: 0.9890 - val_loss: 1.3375 - val_accuracy: 0.8125\n",
      "Epoch 460/500\n",
      "263/264 [============================>.] - ETA: 0s - loss: 0.0245 - accuracy: 0.9888\n",
      "Epoch 00460: val_accuracy did not improve from 0.82900\n",
      "264/264 [==============================] - 6s 22ms/step - loss: 0.0244 - accuracy: 0.9888 - val_loss: 1.2804 - val_accuracy: 0.8115\n",
      "Epoch 461/500\n",
      "262/264 [============================>.] - ETA: 0s - loss: 0.0242 - accuracy: 0.9891\n",
      "Epoch 00461: val_accuracy did not improve from 0.82900\n",
      "264/264 [==============================] - 6s 22ms/step - loss: 0.0242 - accuracy: 0.9891 - val_loss: 1.2847 - val_accuracy: 0.8107\n",
      "Epoch 462/500\n",
      "264/264 [==============================] - ETA: 0s - loss: 0.0242 - accuracy: 0.9890\n",
      "Epoch 00462: val_accuracy did not improve from 0.82900\n",
      "264/264 [==============================] - 6s 22ms/step - loss: 0.0242 - accuracy: 0.9890 - val_loss: 1.3197 - val_accuracy: 0.8131\n",
      "Epoch 463/500\n",
      "263/264 [============================>.] - ETA: 0s - loss: 0.0245 - accuracy: 0.9888\n",
      "Epoch 00463: val_accuracy did not improve from 0.82900\n",
      "264/264 [==============================] - 6s 23ms/step - loss: 0.0245 - accuracy: 0.9888 - val_loss: 1.2739 - val_accuracy: 0.8041\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 464/500\n",
      "264/264 [==============================] - ETA: 0s - loss: 0.0247 - accuracy: 0.9889\n",
      "Epoch 00464: val_accuracy did not improve from 0.82900\n",
      "264/264 [==============================] - 6s 22ms/step - loss: 0.0247 - accuracy: 0.9889 - val_loss: 1.3858 - val_accuracy: 0.8141\n",
      "Epoch 465/500\n",
      "264/264 [==============================] - ETA: 0s - loss: 0.0240 - accuracy: 0.9893\n",
      "Epoch 00465: val_accuracy did not improve from 0.82900\n",
      "264/264 [==============================] - 6s 22ms/step - loss: 0.0240 - accuracy: 0.9893 - val_loss: 1.3512 - val_accuracy: 0.8107\n",
      "Epoch 466/500\n",
      "263/264 [============================>.] - ETA: 0s - loss: 0.0241 - accuracy: 0.9890\n",
      "Epoch 00466: val_accuracy did not improve from 0.82900\n",
      "264/264 [==============================] - 6s 22ms/step - loss: 0.0240 - accuracy: 0.9890 - val_loss: 1.3210 - val_accuracy: 0.8123\n",
      "Epoch 467/500\n",
      "263/264 [============================>.] - ETA: 0s - loss: 0.0242 - accuracy: 0.9890\n",
      "Epoch 00467: val_accuracy did not improve from 0.82900\n",
      "264/264 [==============================] - 6s 22ms/step - loss: 0.0242 - accuracy: 0.9890 - val_loss: 1.3364 - val_accuracy: 0.8123\n",
      "Epoch 468/500\n",
      "262/264 [============================>.] - ETA: 0s - loss: 0.0247 - accuracy: 0.9889\n",
      "Epoch 00468: val_accuracy did not improve from 0.82900\n",
      "264/264 [==============================] - 6s 22ms/step - loss: 0.0247 - accuracy: 0.9889 - val_loss: 1.3321 - val_accuracy: 0.8133\n",
      "Epoch 469/500\n",
      "263/264 [============================>.] - ETA: 0s - loss: 0.0241 - accuracy: 0.9890\n",
      "Epoch 00469: val_accuracy did not improve from 0.82900\n",
      "264/264 [==============================] - 6s 22ms/step - loss: 0.0241 - accuracy: 0.9890 - val_loss: 1.3022 - val_accuracy: 0.8119\n",
      "Epoch 470/500\n",
      "262/264 [============================>.] - ETA: 0s - loss: 0.0241 - accuracy: 0.9891\n",
      "Epoch 00470: val_accuracy did not improve from 0.82900\n",
      "264/264 [==============================] - 6s 23ms/step - loss: 0.0241 - accuracy: 0.9891 - val_loss: 1.3454 - val_accuracy: 0.8105\n",
      "Epoch 471/500\n",
      "263/264 [============================>.] - ETA: 0s - loss: 0.0238 - accuracy: 0.9891\n",
      "Epoch 00471: val_accuracy did not improve from 0.82900\n",
      "264/264 [==============================] - 6s 23ms/step - loss: 0.0238 - accuracy: 0.9891 - val_loss: 1.3654 - val_accuracy: 0.8132\n",
      "Epoch 472/500\n",
      "264/264 [==============================] - ETA: 0s - loss: 0.0239 - accuracy: 0.9892\n",
      "Epoch 00472: val_accuracy did not improve from 0.82900\n",
      "264/264 [==============================] - 6s 23ms/step - loss: 0.0239 - accuracy: 0.9892 - val_loss: 1.3523 - val_accuracy: 0.8095\n",
      "Epoch 473/500\n",
      "264/264 [==============================] - ETA: 0s - loss: 0.0245 - accuracy: 0.9889\n",
      "Epoch 00473: val_accuracy did not improve from 0.82900\n",
      "264/264 [==============================] - 6s 23ms/step - loss: 0.0245 - accuracy: 0.9889 - val_loss: 1.3329 - val_accuracy: 0.8113\n",
      "Epoch 474/500\n",
      "264/264 [==============================] - ETA: 0s - loss: 0.0240 - accuracy: 0.9890\n",
      "Epoch 00474: val_accuracy did not improve from 0.82900\n",
      "264/264 [==============================] - 6s 22ms/step - loss: 0.0240 - accuracy: 0.9890 - val_loss: 1.2538 - val_accuracy: 0.8090\n",
      "Epoch 475/500\n",
      "264/264 [==============================] - ETA: 0s - loss: 0.0241 - accuracy: 0.9888\n",
      "Epoch 00475: val_accuracy did not improve from 0.82900\n",
      "264/264 [==============================] - 6s 22ms/step - loss: 0.0241 - accuracy: 0.9888 - val_loss: 1.2964 - val_accuracy: 0.8073\n",
      "Epoch 476/500\n",
      "263/264 [============================>.] - ETA: 0s - loss: 0.0241 - accuracy: 0.9891\n",
      "Epoch 00476: val_accuracy did not improve from 0.82900\n",
      "264/264 [==============================] - 6s 23ms/step - loss: 0.0241 - accuracy: 0.9891 - val_loss: 1.3670 - val_accuracy: 0.8130\n",
      "Epoch 477/500\n",
      "262/264 [============================>.] - ETA: 0s - loss: 0.0242 - accuracy: 0.9892\n",
      "Epoch 00477: val_accuracy did not improve from 0.82900\n",
      "264/264 [==============================] - 6s 23ms/step - loss: 0.0242 - accuracy: 0.9891 - val_loss: 1.2721 - val_accuracy: 0.8077\n",
      "Epoch 478/500\n",
      "264/264 [==============================] - ETA: 0s - loss: 0.0233 - accuracy: 0.9892\n",
      "Epoch 00478: val_accuracy did not improve from 0.82900\n",
      "264/264 [==============================] - 6s 22ms/step - loss: 0.0233 - accuracy: 0.9892 - val_loss: 1.3094 - val_accuracy: 0.8105\n",
      "Epoch 479/500\n",
      "262/264 [============================>.] - ETA: 0s - loss: 0.0241 - accuracy: 0.9891\n",
      "Epoch 00479: val_accuracy did not improve from 0.82900\n",
      "264/264 [==============================] - 6s 23ms/step - loss: 0.0240 - accuracy: 0.9892 - val_loss: 1.2975 - val_accuracy: 0.8106\n",
      "Epoch 480/500\n",
      "263/264 [============================>.] - ETA: 0s - loss: 0.0240 - accuracy: 0.9891\n",
      "Epoch 00480: val_accuracy did not improve from 0.82900\n",
      "264/264 [==============================] - 6s 22ms/step - loss: 0.0241 - accuracy: 0.9891 - val_loss: 1.3194 - val_accuracy: 0.8099\n",
      "Epoch 481/500\n",
      "264/264 [==============================] - ETA: 0s - loss: 0.0240 - accuracy: 0.9891\n",
      "Epoch 00481: val_accuracy did not improve from 0.82900\n",
      "264/264 [==============================] - 6s 23ms/step - loss: 0.0240 - accuracy: 0.9891 - val_loss: 1.3082 - val_accuracy: 0.8095\n",
      "Epoch 482/500\n",
      "263/264 [============================>.] - ETA: 0s - loss: 0.0238 - accuracy: 0.9893\n",
      "Epoch 00482: val_accuracy did not improve from 0.82900\n",
      "264/264 [==============================] - 6s 23ms/step - loss: 0.0238 - accuracy: 0.9892 - val_loss: 1.2764 - val_accuracy: 0.8081\n",
      "Epoch 483/500\n",
      "264/264 [==============================] - ETA: 0s - loss: 0.0239 - accuracy: 0.9890\n",
      "Epoch 00483: val_accuracy did not improve from 0.82900\n",
      "264/264 [==============================] - 6s 23ms/step - loss: 0.0239 - accuracy: 0.9890 - val_loss: 1.3976 - val_accuracy: 0.8110\n",
      "Epoch 484/500\n",
      "264/264 [==============================] - ETA: 0s - loss: 0.0235 - accuracy: 0.9891\n",
      "Epoch 00484: val_accuracy did not improve from 0.82900\n",
      "264/264 [==============================] - 6s 23ms/step - loss: 0.0235 - accuracy: 0.9891 - val_loss: 1.3785 - val_accuracy: 0.8102\n",
      "Epoch 485/500\n",
      "262/264 [============================>.] - ETA: 0s - loss: 0.0239 - accuracy: 0.9891\n",
      "Epoch 00485: val_accuracy did not improve from 0.82900\n",
      "264/264 [==============================] - 6s 23ms/step - loss: 0.0240 - accuracy: 0.9891 - val_loss: 1.2984 - val_accuracy: 0.8110\n",
      "Epoch 486/500\n",
      "263/264 [============================>.] - ETA: 0s - loss: 0.0238 - accuracy: 0.9895\n",
      "Epoch 00486: val_accuracy did not improve from 0.82900\n",
      "264/264 [==============================] - 6s 22ms/step - loss: 0.0238 - accuracy: 0.9895 - val_loss: 1.3313 - val_accuracy: 0.8115\n",
      "Epoch 487/500\n",
      "262/264 [============================>.] - ETA: 0s - loss: 0.0243 - accuracy: 0.9887\n",
      "Epoch 00487: val_accuracy did not improve from 0.82900\n",
      "264/264 [==============================] - 6s 22ms/step - loss: 0.0243 - accuracy: 0.9887 - val_loss: 1.3162 - val_accuracy: 0.8099\n",
      "Epoch 488/500\n",
      "262/264 [============================>.] - ETA: 0s - loss: 0.0244 - accuracy: 0.9889\n",
      "Epoch 00488: val_accuracy did not improve from 0.82900\n",
      "264/264 [==============================] - 6s 23ms/step - loss: 0.0244 - accuracy: 0.9889 - val_loss: 1.3302 - val_accuracy: 0.8131\n",
      "Epoch 489/500\n",
      "262/264 [============================>.] - ETA: 0s - loss: 0.0239 - accuracy: 0.9889\n",
      "Epoch 00489: val_accuracy did not improve from 0.82900\n",
      "264/264 [==============================] - 6s 22ms/step - loss: 0.0240 - accuracy: 0.9889 - val_loss: 1.3624 - val_accuracy: 0.8116\n",
      "Epoch 490/500\n",
      "262/264 [============================>.] - ETA: 0s - loss: 0.0245 - accuracy: 0.9889\n",
      "Epoch 00490: val_accuracy did not improve from 0.82900\n",
      "264/264 [==============================] - 6s 22ms/step - loss: 0.0244 - accuracy: 0.9889 - val_loss: 1.2466 - val_accuracy: 0.8119\n",
      "Epoch 491/500\n",
      "262/264 [============================>.] - ETA: 0s - loss: 0.0232 - accuracy: 0.9894\n",
      "Epoch 00491: val_accuracy did not improve from 0.82900\n",
      "264/264 [==============================] - 6s 22ms/step - loss: 0.0232 - accuracy: 0.9894 - val_loss: 1.3481 - val_accuracy: 0.8105\n",
      "Epoch 492/500\n",
      "262/264 [============================>.] - ETA: 0s - loss: 0.0238 - accuracy: 0.9889\n",
      "Epoch 00492: val_accuracy did not improve from 0.82900\n",
      "264/264 [==============================] - 6s 22ms/step - loss: 0.0238 - accuracy: 0.9889 - val_loss: 1.4052 - val_accuracy: 0.8133\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 493/500\n",
      "263/264 [============================>.] - ETA: 0s - loss: 0.0239 - accuracy: 0.9893\n",
      "Epoch 00493: val_accuracy did not improve from 0.82900\n",
      "264/264 [==============================] - 6s 23ms/step - loss: 0.0239 - accuracy: 0.9893 - val_loss: 1.2857 - val_accuracy: 0.8111\n",
      "Epoch 494/500\n",
      "263/264 [============================>.] - ETA: 0s - loss: 0.0239 - accuracy: 0.9890\n",
      "Epoch 00494: val_accuracy did not improve from 0.82900\n",
      "264/264 [==============================] - 6s 22ms/step - loss: 0.0240 - accuracy: 0.9890 - val_loss: 1.3219 - val_accuracy: 0.8117\n",
      "Epoch 495/500\n",
      "263/264 [============================>.] - ETA: 0s - loss: 0.0240 - accuracy: 0.9891\n",
      "Epoch 00495: val_accuracy did not improve from 0.82900\n",
      "264/264 [==============================] - 6s 22ms/step - loss: 0.0240 - accuracy: 0.9891 - val_loss: 1.3248 - val_accuracy: 0.8115\n",
      "Epoch 496/500\n",
      "263/264 [============================>.] - ETA: 0s - loss: 0.0237 - accuracy: 0.9893\n",
      "Epoch 00496: val_accuracy did not improve from 0.82900\n",
      "264/264 [==============================] - 6s 22ms/step - loss: 0.0237 - accuracy: 0.9893 - val_loss: 1.3686 - val_accuracy: 0.8139\n",
      "Epoch 497/500\n",
      "262/264 [============================>.] - ETA: 0s - loss: 0.0241 - accuracy: 0.9893\n",
      "Epoch 00497: val_accuracy did not improve from 0.82900\n",
      "264/264 [==============================] - 6s 23ms/step - loss: 0.0240 - accuracy: 0.9894 - val_loss: 1.2659 - val_accuracy: 0.8119\n",
      "Epoch 498/500\n",
      "264/264 [==============================] - ETA: 0s - loss: 0.0237 - accuracy: 0.9893\n",
      "Epoch 00498: val_accuracy did not improve from 0.82900\n",
      "264/264 [==============================] - 6s 22ms/step - loss: 0.0237 - accuracy: 0.9893 - val_loss: 1.3208 - val_accuracy: 0.8117\n",
      "Epoch 499/500\n",
      "264/264 [==============================] - ETA: 0s - loss: 0.0242 - accuracy: 0.9890\n",
      "Epoch 00499: val_accuracy did not improve from 0.82900\n",
      "264/264 [==============================] - 6s 22ms/step - loss: 0.0242 - accuracy: 0.9890 - val_loss: 1.3194 - val_accuracy: 0.8123\n",
      "Epoch 500/500\n",
      "262/264 [============================>.] - ETA: 0s - loss: 0.0245 - accuracy: 0.9890\n",
      "Epoch 00500: val_accuracy did not improve from 0.82900\n",
      "264/264 [==============================] - 6s 22ms/step - loss: 0.0245 - accuracy: 0.9890 - val_loss: 1.3089 - val_accuracy: 0.8125\n",
      "INFO:tensorflow:Assets written to: ./Model_Folder/assets\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import save_model\n",
    "\n",
    "model = CNNClassifier(**kargs)\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(),\n",
    "              loss = tf.keras.losses.BinaryCrossentropy(),\n",
    "              metrics = [tf.keras.metrics.BinaryAccuracy(name='accuracy')])\n",
    "\n",
    "#검증 정확도를 통한 EarlyStopping 기능 및 모델 저장 방식 지정\n",
    "#earlystop_callback = EarlyStopping(monitor='val_accuracy', min_delta=0.0001, patience=2)\n",
    "earlystop_callback = EarlyStopping(monitor='val_accuracy', min_delta=0.0001, patience=500)\n",
    "checkpoint_path = DATA_OUT + model_name +'weights.h5'\n",
    "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
    "\n",
    "if os.path.exists(checkpoint_dir):\n",
    "    print(\"{} -- Folder already exists \\n\".format(checkpoint_dir))\n",
    "else:\n",
    "    os.makedirs(checkpoint_dir, exist_ok=True)\n",
    "    print(\"{} -- Folder create complete \\n\".format(checkpoint_dir))\n",
    "\n",
    "cp_callback = ModelCheckpoint(\n",
    "    checkpoint_path, monitor = 'val_accuracy', verbose=1, save_best_only = True,\n",
    "    save_weights_only=True\n",
    ")\n",
    "\n",
    "history = model.fit(train_input, train_label, batch_size=BATCH_SIZE, epochs = NUM_EPOCHS,\n",
    "                    validation_split=VALID_SPLIT, callbacks=[earlystop_callback, cp_callback])\n",
    "# 모델 저장하기\n",
    "save_model(model,'./Model_Folder/')\n",
    "#save_model(model,'모델 저장할 폴더 경로')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1563/1563 [==============================] - 4s 2ms/step - loss: 0.3823 - accuracy: 0.8263\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.38228777050971985, 0.8263000249862671]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 평가하기\n",
    "\n",
    "INPUT_TEST_DATA = 'nsmc_test_input.npy'\n",
    "LABEL_TEST_DATA = 'nsmc_test_label.npy'\n",
    "SAVE_FILE_NM = 'weights.h5'\n",
    "\n",
    "test_input = np.load(open(DATA_PATH+INPUT_TEST_DATA,'rb'))\n",
    "test_input = pad_sequences(test_input,maxlen=test_input.shape[1])\n",
    "test_label_data = np.load(open(DATA_PATH + LABEL_TEST_DATA, 'rb'))\n",
    "\n",
    "model.load_weights('DATA_OUT/cnn_classifier_kr/weights.h5') # model.load_weights('모델저장위치/weights.h5')\n",
    "model.evaluate(test_input, test_label_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 긍정 부정 예측"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "감성분석할 문장을 입력해 주세요.: 최태민과 내연관계라는 사실이 보고서로 올라갔고 최태민과의 추문이 사건의 발단인데 거기엔 입 다무는게 위대한 침묵이냐? 누가 들으면 나라라도 지키다가 탄핵 당한 줄 알겠는데? 심지어 친미국가는 아무도 참석 안한 중국 전승절에 참석하는 역대급 친중행위를 해 놓고 뭘 잘했다고 이럴까? 이딴 인간이 대통령까지 해 먹었다는 사실이 수치스러울 정도다\n",
      "55.43% 확률로 긍정 리뷰입니다.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import json\n",
    "from konlpy.tag import Okt\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "okt = Okt()\n",
    "tokenizer  = Tokenizer()\n",
    "\n",
    "DATA_CONFIGS = 'data_configs.json'\n",
    "prepro_configs = json.load(open('./CLEAN_DATA/'+DATA_CONFIGS,'r', encoding='utf-8'))\n",
    "prepro_configs['vocab'] = word_vocab\n",
    "\n",
    "tokenizer.fit_on_texts(word_vocab)\n",
    "\n",
    "MAX_LENGTH = 10 #문장최대길이\n",
    "\n",
    "sentence = input('감성분석할 문장을 입력해 주세요.: ')\n",
    "sentence = re.sub(r'[^ㄱ-ㅎㅏ-ㅣ가-힣\\\\s ]','', sentence)\n",
    "stopwords = ['은','는','이','가','하','아','것','들','의','있','되','수','보','주','등','한'] # 불용어 추가할 것이 있으면 이곳에 추가\n",
    "sentence = okt.morphs(sentence, stem=True) # 토큰화\n",
    "sentence = [word for word in sentence if not word in stopwords] # 불용어 제거\n",
    "vector  = tokenizer.texts_to_sequences(sentence)\n",
    "pad_new = pad_sequences(vector, maxlen = MAX_LENGTH) # 패딩\n",
    "\n",
    "#model = tf.saved_model.load('DATA_OUT/cnn_classifier_kr/')\n",
    "#model.load_weights('/content/sample_data/DATA_OUT/cnn_classifier_kr\\weights.h5') #모델 불러오기\n",
    "model.load_weights('DATA_OUT/cnn_classifier_kr/weights.h5') #모델 불러오기\n",
    "predictions = model.predict(pad_new)\n",
    "predictions = float(predictions.squeeze(-1)[1])\n",
    "\n",
    "if(predictions > 0.5):\n",
    "    print(\"{:.2f}% 확률로 긍정 리뷰입니다.\\n\".format(predictions * 100))\n",
    "else:\n",
    "    print(\"{:.2f}% 확률로 부정 리뷰입니다.\\n\".format((1 - predictions) * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
